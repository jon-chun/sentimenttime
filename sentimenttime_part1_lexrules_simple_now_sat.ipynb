{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "sentimenttime_part1_lexrules_simple_now_sat.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "yXwKR4gA8Ouk",
        "PVCkjat0vffd",
        "YFC8GTnw6HrG",
        "j2tIua7tTSRz",
        "QZjqwTvU76AR",
        "NA3dWsnF78mi",
        "SkNZVk128jV9",
        "dUcANLM_8mtT",
        "Cn4KQYpH3glK",
        "jRTjCPLb8cbB",
        "gAEiglIPDfFI",
        "iCN4c-G48e7-",
        "G2blGfVlKb_s",
        "wsaziON_Z263",
        "AIGQgWvyOtg6"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jon-chun/sentimenttime/blob/main/sentimenttime_part1_lexrules_simple_now_sat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibHFmIWoU3Vx"
      },
      "source": [
        "# **An Analytic Methodology to Extract Narratives from Text: Using Sentiment Analysis to find the Arcs and Crux Points in Novels, Social Media and Chat Transcripts**\n",
        "\n",
        "By: Jon Chun\n",
        "12 Jun 2021\n",
        "\n",
        "References:\n",
        "\n",
        "* Coming...\n",
        "\n",
        "TODO:\n",
        "* Demo datafiles\n",
        "* Error detection around Crux points context (out of bounds)\n",
        "* lex_discrete2continous (research binary->gaussian transformation fn)\n",
        "* Text Preprocessing hints/tips/flowchart\n",
        "* Clearly document workflow and partition across notebooks/libraries\n",
        "* Code review and extraction to libraries\n",
        "* Corpus ingestion for any format\n",
        "* XAI (mlm false peak 1717SyuzhetR/1732SentimentR/1797robertalg15 adam watches war argument at dinner) \n",
        "* Centralize and Standardize Model name lists\n",
        "* Normalize model SA Series lengths\n",
        "* Standardize all SA Series with the same method\n",
        "* Seamless report generation/file saving\n",
        "* Get raw text from SentimentR\n",
        "* Filter out non-printable characters\n",
        "* Roll-over Crux-Points (SentNo+Sent/Parag) (plotly)\n",
        "* Label/Roll-over Chapter/Sect No at Boundries\n",
        "* Generate Report PDF/csv\n",
        "* Option to select raw or discrete2continous transformation (Bing)\n",
        "* Annotation functionality + Share/Collaboration of findings/reseearch\n",
        "* clusters, centroids = kmeans1d.cluster(np.array(corpus_sentimentr_df['jockers_rinker']), k)\n",
        "* plotly prefered library to save dynamic images: kaleido\n",
        "* Correlation heatmaps: Justify choice of Spearman, Pearson, or other algo\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X05awke6vYdu"
      },
      "source": [
        "# Test\n",
        "\n",
        "# !pip install kmeans1d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBWhXS9bxrtd"
      },
      "source": [
        "\"\"\"\n",
        "import kmeans1d\n",
        "\n",
        "k = corpus_sentimentr_df.shape[0]//500  \n",
        "\n",
        "clusters, centroids = kmeans1d.cluster(np.array(corpus_sentimentr_df['jockers_rinker']), k)\n",
        "type(clusters)\n",
        "\n",
        "[[x,clusters.count(x)] for x in set(clusters)]\n",
        "centroids\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u932nJxdh0Ac"
      },
      "source": [
        "# Configuration (Auto)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_a9eQyBiiTG"
      },
      "source": [
        "**Global Configuration Constants**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT2MyyjpihFj"
      },
      "source": [
        "# Hardcoded Sentiment Analysis Models\n",
        "\n",
        "CORPUS_ENCODING = 'utf-8' # Default character/text encoding scheme (others: 'utf-8', but often 'iso-8859-1', 'windows-1252', 'cp1252', or 'ascii')\n",
        "\n",
        "MODELS_LS = ['vader','textblob','stanza','afinn','bing','sentimentr','syuzhet','pattern','sentiword','senticnet','nrc']\n",
        "            \n",
        "# Minimum lengths for Sentences and Paragraphs\n",
        "#   (Shorter Sents/Parags will be deleted)\n",
        "\n",
        "MIN_CHAP_LEN = 50\n",
        "MIN_SECT_LEN = 25  # Minimum char length to be included in section DataFrame\n",
        "MIN_PARAG_LEN = 2\n",
        "MIN_SENT_LEN = 2\n",
        "\n",
        "# Simple Moving Average/Rolling Mean \n",
        "roll_str = \"roll10\" # Default 10% Rolling Mean Window \n",
        "\n",
        "# Min/Max statistics on each lexicon's sentiment values applied to corpus\n",
        "corpus_lexicons_stats_dt = {}\n",
        "corpus_cruxes_dt = {}\n",
        "\n",
        "# Crux Points Dict key:model, value:list of crux point tuples (x,y)\n",
        "corpus_cruxes_all_dt = {}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiapgHzZdm4x"
      },
      "source": [
        "groups_ls = ['models_baseline_ls',\n",
        "                'models_sentimentr_ls',\n",
        "                'models_syuzhetr_ls',\n",
        "                'models_transformer_ls']\n",
        "\n",
        "models_baseline_ls = ['sentimentr',\n",
        "                      'syuzhet',\n",
        "                      'bing',\n",
        "                      'sentiword',\n",
        "                      'senticnet',\n",
        "                      'nrc',\n",
        "                      'afinn',\n",
        "                      'vader',\n",
        "                      'textblob',\n",
        "                      'flair',\n",
        "                      'pattern',\n",
        "                      'stanza']\n",
        "\n",
        "models_sentimentr_ls = ['jockers_rinker',\n",
        "                        'jockers',\n",
        "                        'huliu',\n",
        "                        'senticnet',\n",
        "                        'sentiword',\n",
        "                        'nrc',\n",
        "                        'lmcd']\n",
        "\n",
        "models_syuzhetr_ls = ['syuzhet',\n",
        "                      'bing',\n",
        "                      'afinn',\n",
        "                      'nrc']\n",
        "\n",
        "models_transformer_ls = ['roberta15lg', \n",
        "                         'nlptown', \n",
        "                         'yelp', \n",
        "                         'hinglish',\n",
        "                         'imdb2way', \n",
        "                         'huggingface', \n",
        "                         't5imdb50k', \n",
        "                         'robertaxml8lang']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOPa6HH-OjZp"
      },
      "source": [
        "**Install Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drpZJilASHUN"
      },
      "source": [
        "# fast detection of character set encoding for text/files\n",
        "\n",
        "!pip install cchardet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA7Nw-SA_si1"
      },
      "source": [
        "!pip install pysbd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEjSzsusOOJ-"
      },
      "source": [
        "# common ML code\n",
        "\n",
        "!pip install sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZ0UVdasuTTS"
      },
      "source": [
        "%pip install contractions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmtqmvu6OlR9"
      },
      "source": [
        "**Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7bf4lfgwMEz"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import io\n",
        "import glob\n",
        "import json\n",
        "import contextlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOmyq4h7OOFi"
      },
      "source": [
        "# IMPORT LIBRARIES\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OslLdEsvOuFU"
      },
      "source": [
        "import re\n",
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YelenXz5BcmE"
      },
      "source": [
        "from itertools import cycle  # For plotly\n",
        "\n",
        "import collections\n",
        "from collections import OrderedDict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Suximbjnw8D"
      },
      "source": [
        "# Import libraries for logging\n",
        "\n",
        "import logging\n",
        "from datetime import datetime\n",
        "import time                     # (TODO: check no dependencies and delete)\n",
        "from time import gmtime, strftime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPZmScjVDYyw"
      },
      "source": [
        "import nltk\n",
        "\n",
        "# Download for sentence tokenization\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Download for nltk/VADER sentiment analysis\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u34kPKO0_xF_"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm') # Load the English Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMl2mfF8Haw8"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler   # To normalize time series\n",
        "from sklearn.preprocessing import StandardScaler # To Standardize time series: center(sub mean) and rescale within 1 SD (only for well-behaved guassian distributions)\n",
        "from sklearn.preprocessing import RobustScaler   # To Standardize time series: center(sub median) and rescale within 25%-75% (1st-3rd) IQR (better for noisy, outliers distributions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nckwluDXwa1c"
      },
      "source": [
        "mean_std_scaler = StandardScaler()\n",
        "median_iqr_scaler = RobustScaler()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U589lvKXmFV-"
      },
      "source": [
        "# Zoom interpolates new datapoints between existing datapoints to expand a time series \n",
        "\n",
        "from scipy.ndimage.interpolation import zoom"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wcZfSOuBlW7"
      },
      "source": [
        "from scipy import interpolate\n",
        "from scipy.interpolate import CubicSpline\n",
        "from scipy import signal\n",
        "from scipy.signal import argrelextrema"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY3UyvYjAvDN"
      },
      "source": [
        "from statsmodels.nonparametric.smoothers_lowess import lowess as sm_lowess\n",
        "from statsmodels import robust"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02LJQlYpgQGs"
      },
      "source": [
        "corpus_sects_df = pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcSc4jsggSy2"
      },
      "source": [
        "**Define Library-Dependent Objects**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjGN2sN3uRpN"
      },
      "source": [
        "import contractions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AllIwMngDGC3"
      },
      "source": [
        "# Necessary to define before defining Utility Functions using these DataFrames\n",
        "\n",
        "corpus_sents_df = pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kwl0MBDyOwtX"
      },
      "source": [
        "**Configure Jupyter Notebook**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APCau-T26XQ3"
      },
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def my_css():\n",
        "   display(HTML(\"\"\"<style>table.dataframe td{white-space: nowrap;}</style>\"\"\"))\n",
        "\n",
        "get_ipython().events.register('pre_run_cell', my_css)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nD1cyqWsfjxA"
      },
      "source": [
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzfybE5kfmE-"
      },
      "source": [
        "# Configure matplotlib and seaborn\n",
        "\n",
        "# Plotting pretty figures and avoid blurry images\n",
        "# %config InlineBackend.figure_format = 'retina'\n",
        "# Larger scale for plots in notebooks\n",
        "# sns.set_context('talk')\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = [16, 8]\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "plt.rc('figure', facecolor='white')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIIjSbyeP2fg"
      },
      "source": [
        "# Configure Jupyter\n",
        "\n",
        "# Enable multiple outputs from one code cell\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "from IPython.display import display\n",
        "from ipywidgets import widgets, interactive\n",
        "\n",
        "# Configure Google Colab\n",
        "\n",
        "%load_ext google.colab.data_table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS_El2PiQlyP"
      },
      "source": [
        "# Text wrap\n",
        "\n",
        "from IPython.display import HTML\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuM_qnOHUil5"
      },
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import plotly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dLkfn4KFmDf"
      },
      "source": [
        "**Configuration Details Snapshot**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FNPovQBFZky"
      },
      "source": [
        "# Snap Shot of Time, Machine, Data and Library/Version Blueprint\n",
        "# TODO:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wiSBHxoOGZz"
      },
      "source": [
        "# Pick ONE Method (a) or (b) to Get Corpus Textfile\n",
        "\n",
        "**Choose either (a) OR (b), not both**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KRfiXXQOZcq"
      },
      "source": [
        "## **Option (a): Connect to Google gDrive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G64etjAUOOSm"
      },
      "source": [
        "# Connect to Google gDrive\n",
        "\n",
        "# Flag to indicate first run through code \n",
        "flag_first_run = True\n",
        "\n",
        "from google.colab import drive, files\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0fvFZq-eFaw"
      },
      "source": [
        "# Select the Corpus subdirectory on your Google gDrive\n",
        "\n",
        "# Done\n",
        "# gdrive_subdir = \"./research/2021/sa_book_code/books_sa/imcewan_machineslikeme\" #@param {type:\"string\"}\n",
        "gdrive_subdir = \"./research/2021/sa_book_code/books_sa/vwoolf_tothelighthouse\" #@param {type:\"string\"}\n",
        "# gdrive_subdir = \"./research/2021/sa_book_code/books_sa/ddefoe_robinsoncrusoe\" #@param {type:\"string\"}\n",
        "# gdrive_subdir = \"./research/2021/sa_book_code/books_sa/staugustine_confessions\" #@param {type:\"string\"}\n",
        "# gdrive_subdir = \"./research/2021/sa_book_code/books_sa/fdouglass_narrativelifeslave\" #@param {type:\"string\"}\n",
        "\n",
        "# Current\n",
        "# gdrive_subdir = \"./research/2021/sa_book_code/books_sa/homer_odyssey\" #@param {type:\"string\"}\n",
        "\n",
        "# To do\n",
        "# gdrive_subdir = \"./research/2021/sa_book_code/books_sa/geliot_middlemarch\" #@param {type:\"string\"}\n",
        "\n",
        "CORPUS_SUBDIR = gdrive_subdir\n",
        "corpus_filename = CORPUS_SUBDIR\n",
        "\n",
        "# Change to working subdirectory\n",
        "if flag_first_run == True:\n",
        "  full_path_str = gdrive_subdir\n",
        "  flag_first_run = False\n",
        "else:\n",
        "  full_path_str = f'/gdrive/MyDrive{gdrive_subdir[1:]}'\n",
        "\n",
        "%cd $full_path_str\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKV1uMBEO8TR"
      },
      "source": [
        "## **Option (b): Upload Corpus Textfile**\n",
        "\n",
        "***Only do this if your Google subdirectory doesn't already contain a plain text file of your Corpus or you wish to overwrite it and use a newer version***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH6dlB2fO6Ln"
      },
      "source": [
        "# Execute this code cell to upload plain text file of corpus\n",
        "#   Should be *.txt format with paragraphs separated by at least 2 newlines\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3LORQ4fRGBW"
      },
      "source": [
        "# Verify file was uploaded\n",
        "\n",
        "# Get uploaded filename\n",
        "corpus_filename = list(uploaded.keys())[0]\n",
        "print(f'Uploaded Corpus filename is: {corpus_filename}')\n",
        "CORPUS_FILENAME = corpus_filename\n",
        "\n",
        "!ls -al $corpus_filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bsm8awD4AZ8O"
      },
      "source": [
        "# **Configuration (Manual)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfilGg6Mkxnd"
      },
      "source": [
        "# Verify subdirectory change\n",
        "\n",
        "!pwd\n",
        "!ls -altr *\n",
        "\n",
        "# TODO: Intelligently automate the filling of form based upon directory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP3WLEv_g5aq"
      },
      "source": [
        "# CORPUS_TITLE = 'Robinson Crusoe' #@param {type:\"string\"}\n",
        "# CORPUS_AUTHOR = \"Daniel Defoe\" #@param {type:\"string\"}\n",
        "# CORPUS_FILENAME = \"ddefoe_robinsoncrusoe_final_hand.txt\" #@param {type:\"string\"}\n",
        "# CORPUS_SUBDIR = \"./research/2021/sa_book_code/books_sa/ddefoe_robinsoncrusoe\" #@param {type:\"string\"}\n",
        "\n",
        "# CORPUS_TITLE = 'The Odyssey' #@param {type:\"string\"}\n",
        "# CORPUS_AUTHOR = \"Homer SButler\" #@param {type:\"string\"}\n",
        "# CORPUS_FILENAME = \"sbutler_odyssey.txt\" #@param {type:\"string\"}\n",
        "# CORPUS_SUBDIR = \"./research/2021/sa_book_code/books_sa/sbutler_odyssey\"  #@param {type:\"string\"}\n",
        "\n",
        "# CORPUS_TITLE = 'Middlemarch' #@param {type:\"string\"}\n",
        "# CORPUS_AUTHOR = \"George Eliot\" #@param {type:\"string\"}\n",
        "# CORPUS_FILENAME = \"geliot_middlemarch_wprelude.txt\" #@param {type:\"string\"}\n",
        "# CORPUS_SUBDIR = \"./research/2021/sa_book_code/books_sa/geliot_middlemarch\"  #@param {type:\"string\"}\n",
        "\n",
        "# CORPUS_TITLE = 'Narrative Life of an American Slave' #@param {type:\"string\"}\n",
        "# CORPUS_AUTHOR = \"Frederick Douglass\" #@param {type:\"string\"}\n",
        "# CORPUS_FILENAME = \"fdouglass_narrativelifeslave.txt\" #@param {type:\"string\"}\n",
        "# CORPUS_SUBDIR = \"./research/2021/sa_book_code/books_sa/fdouglass_narrativelifeslave\"  #@param {type:\"string\"}\n",
        "\n",
        "CORPUS_TITLE = 'To The Lighthouse' #@param {type:\"string\"}\n",
        "CORPUS_AUTHOR = \"Virginia Woolf\" #@param {type:\"string\"}\n",
        "CORPUS_FILENAME = \"vwoolf_tothelighthouse.txt\" #@param {type:\"string\"}\n",
        "CORPUS_SUBDIR = \"./research/2021/sa_book_code/books_sa/vwoolf_tothelighthouse\" #@param {type:\"string\"}\n",
        "\n",
        "# CORPUS_TITLE = 'To The Lighthouse' #@param {type:\"string\"}\n",
        "# CORPUS_AUTHOR = \"Virginia Woolf\" #@param {type:\"string\"}\n",
        "# CORPUS_FILENAME = \"ttl_final_hand.txt\" #@param {type:\"string\"}\n",
        "# CORPUS_SUBDIR = \"./research/2021/sa_book_code/books_sa/vwoolf_tothelighthouse\" #@param {type:\"string\"}\n",
        "\n",
        "CHAPTER_HEADINGS = \"CHAPTER\" #@param [\"CHAPTER\", \"BOOK\"]\n",
        "CHAPTER_NUMBERING = \"Arabic (1,2,...)\" #@param [\"Arabic (1,2,...)\", \"Roman (I,II,...)\"]\n",
        "SECTION_HEADINGS = \"SECTION (ArabicNo)\" #@param [\"SECTION (ArabicNo)\", \"SECTION (RomanNo)\", \"----- (Hyphens)\", \"None\"]\n",
        "\n",
        "LEXICONS_SUBDIR = \"./research/2021/sa_book_code/books_sa/lexicons\" #@param {type:\"string\"}\n",
        "\n",
        "CORPUS_FULL = f'{CORPUS_TITLE} by: {CORPUS_AUTHOR}'\n",
        "\n",
        "PLOT_OUTPUT = \"Major\" #@param [\"None\", \"Major\", \"All\"]\n",
        "\n",
        "FILE_OUTPUT = \"Major\" #@param [\"None\", \"Major\", \"All\"]\n",
        "\n",
        "\n",
        "gdrive_subdir = CORPUS_SUBDIR\n",
        "corpus_filename = CORPUS_FILENAME\n",
        "author_str = ''.join(CORPUS_AUTHOR.split()).lower()\n",
        "author_abbr_str = (CORPUS_AUTHOR.split(' ')[0][0]+CORPUS_AUTHOR.split(' ')[1]).lower()\n",
        "title_str = ''.join(CORPUS_TITLE.split()).lower()\n",
        "\n",
        "print(f'\\nWorking Corpus Datafile: ------------------------------ \\n\\n    {CORPUS_SUBDIR}')\n",
        "print(f'\\nFull Corpus Title/Author: ------------------------------ \\n\\n    {CORPUS_FULL}')\n",
        "\n",
        "\n",
        "if CHAPTER_HEADINGS == 'CHAPTER':\n",
        "  if CHAPTER_NUMBERING == \"Arabic (1,2,...)\":\n",
        "    pattern_chap = r'CHAPTER [0123456789]{1,2}[.]?[^\\n]*'\n",
        "  elif CHAPTER_NUMBERING == \"Roman (I,II,...)\":\n",
        "    pattern_chap = r'CHAPTER [IVXL]{0,10}[.:]?[^\\n]*'\n",
        "  else:\n",
        "    print(f'ERROR: Illegal CHAPTER_NUMBERING value = {CHAPTER_NUMBERING}')\n",
        "\n",
        "elif CHAPTER_HEADINGS == 'BOOK':\n",
        "  if CHAPTER_NUMBERING == \"Arabic (1,2,...)\":\n",
        "    pattern_chap = r'BOOK [0123456789]{1,2}[.]?[^\\n]*'\n",
        "  elif CHAPTER_NUMBERING == \"Roman (I,II,...)\":\n",
        "    pattern_chap = r'[\\s]*BOOK [IVXL]{1,10}[.:]?[\\s]*[^\\n]*[\\n]{0,1}[^\\n]*' # [^\\n]*' # Problems with embedded 'Book'\n",
        "  else:\n",
        "    print(f'ERROR: Illegal CHAPTER_NUMBERING value = {CHAPTER_NUMBERING}')\n",
        "\n",
        "else:\n",
        "  print(f'ERROR: Illegal CHAPTER_HEADINGS value = {CHAPTER_HEADINGS}')\n",
        "\n",
        "# Default Section RegEx Pattern\n",
        "pattern_sect = 'SECTION [0123456789]{1,2}[^\\n]*'\n",
        "\n",
        "if SECTION_HEADINGS == 'SECTION (ArabicNo)':\n",
        "  # pattern_sect = r'SECTION [0-9]{1,2} [^\\n]*'\n",
        "  # TODO: [^\\n] gets parsed into [^\\\\n] causing problems, so simplify\n",
        "  pattern_sect = r'SECTION [0123456789]{1,2}[.:]?[^\\n]*'\n",
        "elif SECTION_HEADINGS == 'SECTION (RomanNo)':\n",
        "  pattern_sect = r'SECTION [IVX]{,10}[.:]?{^\\n]*' # } [A-Z \\.-:—;-’\\'\"]*[\\n]*'\n",
        "elif SECTION_HEADINGS == '----- (Hyphens)':\n",
        "  pattern_sect = r'^[- ]{3,}[^\\n]*'\n",
        "elif SECTION_HEADINGS == 'None':\n",
        "  pass\n",
        "else:\n",
        "  print(f'ERROR: Illegal SECTION_HEADING value = {SECTION_HEADINGS}')\n",
        "\n",
        "print(f'\\nCHAPTER Headings: ------------------------------ \\n\\n    {CHAPTER_HEADINGS}')\n",
        "\n",
        "print(f'\\nSECTION Headings: ------------------------------ \\n\\n    {SECTION_HEADINGS}')\n",
        "\n",
        "\n",
        "print(f'\\nCorpus file information: ------------------------------ \\n')\n",
        "!ls -al $CORPUS_FILENAME\n",
        "\n",
        "# Verify contents of Corpus File is Correctly Formatted\n",
        "#   \n",
        "# TODO: ./utils/verify_format.py\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8owpM75RILKn"
      },
      "source": [
        "# **Utility Functions (Auto)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMLbyx6gIPqj"
      },
      "source": [
        "## **Files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBOvvP-BSIiC"
      },
      "source": [
        "# https://dev.to/bowmanjd/character-encodings-and-detection-with-python-chardet-and-cchardet-4hj7\n",
        "\n",
        "import cchardet as chardet\n",
        "\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "def get_file_encoding(filename):\n",
        "    \"\"\"Detect encoding and return decoded text, encoding, and confidence level.\"\"\"\n",
        "    filepath = Path(filename)\n",
        "\n",
        "    # We must read as binary (bytes) because we don't yet know encoding\n",
        "    blob = filepath.read_bytes()\n",
        "\n",
        "    detection = chardet.detect(blob)\n",
        "    encoding = detection[\"encoding\"]\n",
        "    confidence = detection[\"confidence\"]\n",
        "    text = blob.decode(encoding)\n",
        "\n",
        "    return text, encoding, confidence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2ZKrOg_8Pcz"
      },
      "source": [
        "def corpus2chapsect(corpus_filename):\n",
        "  '''\n",
        "  Given a corpus_filename (assuming already %cd into correct subdir)\n",
        "  Return a list of min preprocessed raw CHAPTERs (corpus_parags_raw_temp_ls)\n",
        "  '''\n",
        "\n",
        "  with open(corpus_filename, \"r\", encoding=CORPUS_ENCODING) as infp:\n",
        "    corpus_raw_str = infp.read()\n",
        "\n",
        "  # Strip out non-printing characters\n",
        "  corpus_clean_str = re.sub(f'[^{re.escape(string.printable)}]', ' ', corpus_raw_str)\n",
        "\n",
        "  print(f'BEFORE stripping out headings len: {len(corpus_raw_str)}')\n",
        "\n",
        "  print(f'Using RegEx pattern_chap: {pattern_chap}')\n",
        "  # print(f'len(corpus_raw_str) = {len(corpus_raw_str)}')\n",
        "  # corpus_chaps_ls = re.split(rf'{pattern_chap}', corpus_raw_str, flags=re.I) # , flags=re.I)\n",
        "  # corpus_chaps_ls = re.split(r'CHAPTER [IVX]{,6}[.]* [A-Z \\.-:—;-’\\'\"]*[\\n]*', corpus_raw_str, flags=re.I) # , flags=re.I)\n",
        "  # corpus_chaps_ls = re.split(r'CHAPTER [\\d]{1,2}[.]* [A-Z \\.-:—;-’\\'\"]*[\\n]*', corpus_raw_str, flags=re.I) # , flags=re.I)\n",
        "  corpus_chaps_raw_ls = re.split(rf'{pattern_chap}', corpus_clean_str, flags=re.I) # , flags=re.I)\n",
        "  print(f'len(corpus_chaps_raw_ls): {len(corpus_chaps_raw_ls)}')\n",
        "\n",
        "  # Strip off whitespace\n",
        "  corpus_chaps_raw_ls = [x.strip() for x in corpus_chaps_raw_ls]\n",
        "\n",
        "  # Filter out chapters that are empty or shorter than MIN_PARAG_LEN\n",
        "  corpus_chaps_raw_ls = [x for x in corpus_chaps_raw_ls if not (len(x.strip()) <= MIN_CHAP_LEN)]\n",
        "\n",
        "  # Filter out SECTION lines (could be embedded or leading)\n",
        "  corpus_chaps_clean_nosect_ls = []\n",
        "  for i, achap_raw in enumerate(corpus_chaps_raw_ls):\n",
        "    if bool(re.match(rf\"{pattern_sect}\", achap_raw)):\n",
        "      achap_raw_temp_str = re.sub(rf'{pattern_sect}', '', achap_raw).strip() # , flags=re.I)[1].strip()\n",
        "    else:\n",
        "      achap_raw_temp_str = achap_raw\n",
        "    corpus_chaps_clean_nosect_ls.append(achap_raw_temp_str)\n",
        "  print(f'In Chapters, filtered Sections with {len(corpus_chaps_clean_nosect_ls)} Chapters left')\n",
        "  corpus_chaps_clean_ls = [x for x in corpus_chaps_clean_nosect_ls]\n",
        "\n",
        "  # Start creating a clean version of Chapters\n",
        "  corpus_chaps_clean_ls = [clean_text(x) for x in corpus_chaps_clean_ls]\n",
        "\n",
        "  # Collapse multiple whitespaces down to one\n",
        "  corpus_chaps_clean_ls = [' '.join(x.split()).strip() for x in corpus_chaps_clean_ls]\n",
        "\n",
        "  # Filter out Chapters that are empty or shorter than MIN_CHAP_LEN\n",
        "  corpus_chaps_clean_ls = [x for x in corpus_chaps_clean_ls if not (len(x.strip()) <= MIN_CHAP_LEN)]\n",
        "\n",
        "  # Check for mismatch\n",
        "  if (len(corpus_chaps_clean_ls) != len(corpus_chaps_raw_ls)):\n",
        "    print('\\n')\n",
        "    print(f'ERROR: Cleaned Chapter lengths does not match original raw Chapter length:\\n')\n",
        "    print(f'DIFFERENCE:\\n\\n   list(set(corpus_chaps_clean_ls).difference(set(corpus_chaps_raw_ls)))')\n",
        "    print('\\n\\n\\n   RESOLUTION: Edit the original corpus file to clean this/these lines of text')\n",
        "    return [-99], [-99], [-99], [-99], [-99], '-99' # Return with ERROR condition\n",
        "\n",
        "  # Create list of Chapter Numbers\n",
        "  corpus_chapno_ls = list(range(len(corpus_chaps_raw_ls)))\n",
        "\n",
        "\n",
        "  sect_chapno_ls = []\n",
        "  if SECTION_HEADINGS == \"None\":\n",
        "    # No Sections, create pseudo-Sections by copying Chapters\n",
        "    corpus_sects_raw_ls = [x for x in corpus_chaps_raw_ls]\n",
        "    corpus_sects_clean_ls = [x for x in corpus_chaps_clean_ls]\n",
        "    # Create list of Chapter Numbers for each Section\n",
        "    sect_chapno_ls = [x for x in corpus_chapno_ls]\n",
        "\n",
        "  else:\n",
        "    # Sections need to be broken out separately\n",
        "\n",
        "    corpus_sects_all_raw_ls = []\n",
        "    corpus_sects_all_clean_ls = []\n",
        "    for achap_no,achap_str in enumerate(corpus_chaps_raw_ls):\n",
        "\n",
        "      corpus_sects_raw_ls = re.split(rf'{pattern_sect}', achap_str, flags=re.I) # , flags=re.I)\n",
        "\n",
        "      # Strip off whitespace\n",
        "      corpus_sects_raw_ls = [x.strip() for x in corpus_sects_raw_ls]\n",
        "\n",
        "      # Filter out Sections that are empty or shorter than MIN_SECT_LEN\n",
        "      corpus_sects_raw_ls = [x for x in corpus_sects_raw_ls if not (len(x.strip()) <= MIN_SECT_LEN)]\n",
        "\n",
        "      # Filter out the Section separator 'SECTION ' lines\n",
        "      corpus_sects_raw_ls = [x for x in corpus_sects_raw_ls if not (x.strip().startswith('SECTION '))]\n",
        "\n",
        "      # Filter out the Section separator '-----' lines\n",
        "      corpus_sects_raw_ls = [x for x in corpus_sects_raw_ls if not (re.match(r'^[ ]*[-]{1,20}[ ]*$',x))]\n",
        "\n",
        "      print('\\n')\n",
        "      print(f'Chapter #{achap_no} Ch Length: {len(achap_str)}')\n",
        "      print(f'             Sections:  {len(corpus_sects_raw_ls)}')\n",
        "      print('\\n')\n",
        "      print(f'        First section:\\n    {corpus_sects_raw_ls[0][:500]}\\n')\n",
        "      print(f'       Second section:\\n    {corpus_sects_raw_ls[1][:500]}')\n",
        "      print('\\n')\n",
        "      print(f'  Second-Last section:\\n    {corpus_sects_raw_ls[-2][:500]}\\n')\n",
        "      print(f'         Last section:\\n    {corpus_sects_raw_ls[-1][:500]}')\n",
        "      print('\\n')\n",
        "\n",
        "      corpus_sects_all_raw_ls += corpus_sects_raw_ls\n",
        "\n",
        "      # Start creating a clean version of Sections\n",
        "      # Filter out SECTION lines (could be embedded or leading)\n",
        "      corpus_sects_clean_ls = [clean_text(x) for x in corpus_sects_raw_ls]\n",
        "\n",
        "      # Filter out Sections that are empty or shorter than MIN_SECT_LEN\n",
        "      corpus_sects_clean_ls = [x for x in corpus_sects_clean_ls if not (len(x.strip()) <= MIN_CHAP_LEN)]\n",
        "\n",
        "      corpus_sects_all_clean_ls += corpus_sects_clean_ls\n",
        "\n",
        "      achap_sect_ct = len(corpus_sects_clean_ls)\n",
        "      for asect_no in (range(achap_sect_ct)):\n",
        "        print(f'appending Section #{asect_no} to Chapter #{achap_no}')\n",
        "        sect_chapno_ls.append(achap_no) \n",
        "\n",
        "    # Check for mismatch\n",
        "    if (len(corpus_sects_all_clean_ls) != len(corpus_sects_all_raw_ls)):\n",
        "      print('\\n')\n",
        "      print(f'     ERROR: Cleaned Section lengths does not match original raw Section length:\\n')\n",
        "      print(f'DIFFERENCE:\\n\\n   Raw length: {len(corpus_sects_all_raw_ls)} vs Clean length: {len(corpus_sects_all_clean_ls)}')\n",
        "      # print(f'DIFFERENCE:\\n\\n   {list(set(corpus_sects_clean_ls).difference(set(corpus_sects_raw_ls)))}')\n",
        "      print(f'RESOLUTION: Edit the original corpus file to clean this/these lines of text')\n",
        "      return [-99], [-99], [-99], [-99], [-99], '-99' # Return with ERROR condition\n",
        "\n",
        "\n",
        "  return corpus_chaps_raw_ls, corpus_chaps_clean_ls, corpus_sects_all_raw_ls, corpus_sects_all_clean_ls, sect_chapno_ls, corpus_raw_str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_nBxtq6-J8l"
      },
      "source": [
        "def filter_nonprintable(text):\n",
        "    import itertools\n",
        "    # Use characters of control category\n",
        "    nonprintable = itertools.chain(range(0x00,0x20),range(0x7f,0xa0))\n",
        "    # Use translate to remove all non-printable characters\n",
        "    return text.translate({character:None for character in nonprintable})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB3OrR5g8VYQ"
      },
      "source": [
        "import sys\n",
        "\n",
        "# build a table mapping all non-printable characters to None\n",
        "NOPRINT_TRANS_TABLE = {\n",
        "    i: None for i in range(0, sys.maxunicode + 1) if not chr(i).isprintable()\n",
        "}\n",
        "\n",
        "def make_printable(s):\n",
        "    \"\"\"Replace non-printable characters in a string.\"\"\"\n",
        "\n",
        "    # the translate method on str removes characters\n",
        "    # that map to None from the string\n",
        "    return s.translate(NOPRINT_TRANS_TABLE)\n",
        "\n",
        "\n",
        "assert make_printable('Café') == 'Café'\n",
        "assert make_printable('\\x00\\x11Hello') == 'Hello'\n",
        "assert make_printable('') == ''\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woDWvRZHjU2E"
      },
      "source": [
        "\"\"\"\n",
        "def corpus2chunks(corpus_filename, sent_tok='pysbd'):\n",
        "  '''\n",
        "  Given a corpus filename (assuming already %cd into correct subdir) \n",
        "    and a sentence tokeniziation method in ['pysbd'(default)|'both'|'nltk']\n",
        "  Return 6 lists and a string of the raw corpus:\n",
        "    4 Paragraph length lists -----\n",
        "    parag_raw_ls : list of raw text for each paragraph\n",
        "    parag_clean_ls : list of clean text for each sentence\n",
        "\n",
        "    parag_sentno_start_ls : list of the Sentence Number at the start of every Paragraph\n",
        "    parag_sentno_end_ls : list of the Sentence Number at the end of every Paragraph\n",
        "\n",
        "    2 Sentence length lists -----\n",
        "    sent_raw_ls : list of raw text for each sentence\n",
        "    sent_clean_ls : list of clean text for each sentence\n",
        "  '''\n",
        "\n",
        "  # Load PySBD if necessary\n",
        "  if (sent_tok == 'pysbd') | (sent_tok == 'both'):\n",
        "    from pysbd.utils import PySBDFactory\n",
        "    nlp = spacy.blank('en')\n",
        "    # explicitly adding component to pipeline\n",
        "    # (recommended - makes it more readable to tell what's going on)\n",
        "    nlp.add_pipe(PySBDFactory(nlp))\n",
        "    # pysbd = nlp.create_pipe('pysbd')\n",
        "    # nlp.add_pipe(pysbd)\n",
        "    # doc = nlp('My name is Jonas E. Smith. Please turn to p. 55.')\n",
        "    # print(list(doc.sents))\n",
        "\n",
        "  # Read file into raw text string\n",
        "  with open(corpus_filename, \"r\", encoding=CORPUS_ENCODING) as infp:\n",
        "    corpus_raw_str = infp.read()\n",
        "\n",
        "  # Split into Raw Paragraphs\n",
        "  print(f'BEFORE stripping out headings len: {len(corpus_raw_str)}')\n",
        "  corpus_parags_raw_ls = re.split(r'[\\n]{2,}', corpus_raw_str)\n",
        "  print(f'Corpus Paragraph Raw Count: {len(corpus_parags_ls)}')\n",
        "\n",
        "\n",
        "  # Copy/Clean Paragraphs into new list\n",
        "  # Filter out numbers(often footnotes) from Paragraphs\n",
        "  corpus_parags_ls = [re.sub(r'[0-9]','',x) for x in corpus_parags_raw_ls]\n",
        "\n",
        "  # Filter out empty lines Paragraphs\n",
        "  corpus_parags_ls = [x for x in corpus_parags_ls if (len(x.strip()) >= MIN_PARAG_LEN)]\n",
        "\n",
        "  # Strip out non-printing characters\n",
        "  corpus_parags_ls = [re.sub(f'[^{re.escape(string.printable)}]', '', x) for x in corpus_parags_ls]\n",
        "\n",
        "  print(f'   Parag count before processing sents: {len(corpus_parags_ls)}')\n",
        "  # FIRST PASS at Sentence Tokenization with PySBD\n",
        "  corpus_sents_all_ls = []\n",
        "  for i, aparag in enumerate(corpus_parags_ls):\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMA-040nIypX"
      },
      "source": [
        "def corpus2lines(corpus_filename, pysbd_only=False):\n",
        "  '''\n",
        "  Given a corpus_filename (assuming already %cd into correct subdir)\n",
        "  Return a list of every line defined by puncutation/NLTK.sent_tokenize or newlines [\\n]{2,}\n",
        "  '''\n",
        "\n",
        "  from pysbd.utils import PySBDFactory\n",
        "  nlp = spacy.blank('en')\n",
        "  # explicitly adding component to pipeline\n",
        "  # (recommended - makes it more readable to tell what's going on)\n",
        "  nlp.add_pipe(PySBDFactory(nlp))\n",
        "  # pysbd = nlp.create_pipe('pysbd')\n",
        "  # nlp.add_pipe(pysbd)\n",
        "  # doc = nlp('My name is Jonas E. Smith. Please turn to p. 55.')\n",
        "  # print(list(doc.sents))\n",
        "\n",
        "  with open(corpus_filename, \"r\", encoding=CORPUS_ENCODING) as infp:\n",
        "    corpus_raw_str = infp.read()\n",
        "\n",
        "  print(f'BEFORE stripping out headings len: {len(corpus_raw_str)}')\n",
        "\n",
        "  corpus_parags_ls = re.split(r'[\\n]{2,}', corpus_raw_str)\n",
        "  print(f'Corpus Paragraph Raw Count: {len(corpus_parags_ls)}')\n",
        "\n",
        "  # Strip off whitespace from Paragraphs\n",
        "  corpus_parags_ls = [x.strip() for x in corpus_parags_ls]\n",
        "\n",
        "  # Filter out numbers(often footnotes) from Paragraphs\n",
        "  corpus_parags_ls = [re.sub(r'[0-9]','',x) for x in corpus_parags_ls]\n",
        "\n",
        "  # Filter out empty lines Paragraphs\n",
        "  corpus_parags_ls = [x for x in corpus_parags_ls if (len(x.strip()) >= MIN_PARAG_LEN)]\n",
        "\n",
        "  # Strip out non-printing characters\n",
        "  corpus_parags_ls = [re.sub(f'[^{re.escape(string.printable)}]', '', x) for x in corpus_parags_ls]\n",
        "\n",
        "  print(f'   Parag count before processing sents: {len(corpus_parags_ls)}')\n",
        "  # FIRST PASS at Sentence Tokenization with PySBD\n",
        "  corpus_sents_all_ls = []\n",
        "  for i, aparag in enumerate(corpus_parags_ls):\n",
        "\n",
        "    # Generally PySBD outperforms NLTK and SpaCy, \n",
        "    #   but for Samuel Butler's 1900 translation of Homer's Odyssey\n",
        "    #   it failed in many cases so we combine/stack PySBD with NLTK\n",
        "    #   (exception to rule: NLTK > SpaCy for SentTokenization circa 2020\n",
        "    #    https://www.kaggle.com/questions-and-answers/130344)\n",
        "\n",
        "    # NLTK Sentence Tokenization\n",
        "    # 3605 lines with 'To the Lighthouse' by V.Woolf\n",
        "    # aparag_sents_ls = (sent_tokenize(aparag))\n",
        "    \n",
        "    # SpaCy Sentence Tokenization\n",
        "    # TODO: Speed up my specializaing pipe\n",
        "    # 3968 lines for 'To the Lighthouse' by V.Woolf\n",
        "    # doc = nlp(aparag)   \n",
        "    # aparag_sents_ls = [sent for sent in doc.sents]\n",
        "    # aparag_sents_ls = [x for x in doc]\n",
        "\n",
        "    # FIRST, tokenize with PySBD\n",
        "    # PySBD Sentence Tokenization\n",
        "    # 3457 lines for 'To the Lighthouse' by V.Woolf\n",
        "    # using pysbd and SpaCy\n",
        "    # or you can use it implicitly with keyword\n",
        "    \n",
        "\n",
        "    aparag_nonl = re.sub('[\\n]{1,}', ' ', aparag)\n",
        "    doc = nlp(aparag_nonl)\n",
        "    aparag_sents_first_ls = list(doc.sents)\n",
        "    print(f'pysbd found {len(aparag_sents_first_ls)} Sentences in Paragraph #{i}')\n",
        "\n",
        "    # Strip off whitespace from Sentences\n",
        "    aparag_sents_first_ls = [str(x).strip() for x in aparag_sents_first_ls]\n",
        "\n",
        "    # Filter out empty line Sentences\n",
        "    aparag_sents_first_ls = [x for x in aparag_sents_first_ls if (len(x.strip()) > MIN_SENT_LEN)]\n",
        "\n",
        "    print(f'      {len(aparag_sents_first_ls)} Sentences remain after cleaning')\n",
        "\n",
        "    corpus_sents_all_ls += aparag_sents_first_ls\n",
        "\n",
        "  # (OPTIONAL) SECOND PASS as Sentence Tokenization with NLTK\n",
        "  if pysbd_only == True:\n",
        "    # Only do one pass at Sentence tokenization with PySBD above\n",
        "    corpus_sents_all_ls = aparag_sents_first_ls\n",
        "  else:\n",
        "    # Do second pass, tokenize again with NLTK to catch any Sentence tokenization missed by PySBD\n",
        "    corpus_sents_all_second_ls = []\n",
        "    aparag_sents_second_ls = []\n",
        "    for asent_first in corpus_sents_all_ls:\n",
        "      aparag_sents_second_ls = sent_tokenize(asent_first)\n",
        "\n",
        "      # Strip off whitespace from Sentences\n",
        "      aparag_sents_second_ls = [str(x).strip() for x in aparag_sents_second_ls]\n",
        "\n",
        "      # Filter out empty line Sentences\n",
        "      aparag_sents_second_ls = [x for x in aparag_sents_second_ls if (len(x.strip()) > MIN_SENT_LEN)]\n",
        "\n",
        "      corpus_sents_all_second_ls += aparag_sents_second_ls\n",
        "\n",
        "    corpus_sents_all_ls = corpus_sents_all_second_ls\n",
        "\n",
        "  # Filter out lines containing only punctuation (e.g. '\"', '.', '...', etc)\n",
        "  # parag_before_punctstrip_ct = len(corpus_parags_ls)\n",
        "  # corpus_parags_ls = [x for x in corpus_parags_ls if len((re.sub(r'[^\\w\\s]','',x)).strip()) > MIN_PARAG_LEN]\n",
        "  # print(f'Punctuation only Paragraph Count: {len(corpus_parags_ls) - parag_before_punctstrip_ct}')\n",
        "\n",
        "  # Filter out the Section separator '-----' lines\n",
        "  # corpus_parags_ls = [x for x in corpus_parags_ls if not (x.strip().startswith('----- '))]\n",
        "\n",
        "  # Filter out the Section separator 'SECTION ' lines\n",
        "  # for i,temp_str in enumerate(corpus_parags_ls):\n",
        "  #   if temp_str.startswith('SECTION '):\n",
        "  #     print(f'Parag #{i}: {temp_str}')\n",
        "  # corpus_parags_ls = [x for x in corpus_parags_ls if not (x.startswith('SECTION '))]\n",
        "\n",
        "  # Filter out any possible embedded 'SECTION ' lines\n",
        "  # for i,temp_str in enumerate(corpus_parags_ls):\n",
        "  #   if 'SECTION' in temp_str:   # .contains('SECTION '):\n",
        "  #     print(f'Parag #{i}: {temp_str}')\n",
        "  # corpus_parags_ls = del_substrs_list(corpus_parags_ls, pattern_sect) # [re.sub(rf'{pattern_sect}', '', x) for x in corpus_parags_ls]\n",
        "\n",
        "  # Filter out the Chapter separator 'CHAPTER ' lines\n",
        "  # for i,temp_str in enumerate(corpus_parags_ls):\n",
        "  #   if temp_str.startswith('CHAPTER '):\n",
        "  #     print(f'Parag #{i}: {temp_str}')\n",
        "  # corpus_parags_ls = [x for x in corpus_parags_ls if not (x.startswith('CHAPTER '))]\n",
        "\n",
        "  print(f'About to return corpus_sents_all_ls with len = {len(corpus_sents_all_ls)}')\n",
        "  return corpus_sents_all_ls, corpus_raw_str\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5nrHLut8AEl"
      },
      "source": [
        "def corpus2sects(corpus_filename):\n",
        "  '''\n",
        "  Given a corpus_filename (assuming already %cd into correct subdir)\n",
        "  Return a 3 lists: First, the list of Section text strings\n",
        "                    Second, a list of tuples that match (Sentence No, Segment No)\n",
        "                    Third, a list of Sentences that not found in any Section \n",
        "  '''\n",
        "\n",
        "  corpus_sects_ls = []\n",
        "\n",
        "\n",
        "  # encoding = CORPUS_ENCODING,  'windows-1252', 'utf-8', 'cp1252', 'iso-8859-1'\n",
        "  with open(corpus_filename, \"r\", encoding=CORPUS_ENCODING) as infp:\n",
        "    corpus_raw_str = infp.read()\n",
        "\n",
        "  # pattern_sect = 'SECTION [\\d]{1,2}[.]?[^\\n]*'\n",
        "  # pattern_sect = 'SECTION [0123456789]{1,2}[^\\n]*'\n",
        "  # corpus_sects_ls = re.split(r'SECTION [\\d]{1,2}[.]* [A-Z \\.-:—;-’\\'\"]*[\\n]*', corpus_raw_str flags=re.I) # , flags=re.I)\n",
        "  corpus_sects_ls = re.split(rf'{pattern_sect}', corpus_raw_str, flags=re.I) # , flags=re.I)\n",
        "  # corpus_sects_ls = re.split(rf'{pattern_sect}', corpus_raw_str, flags=re.I) # , flags=re.I)\n",
        "  print(f'len(corpus_raw_str: {len(corpus_raw_str)}')\n",
        "  print(f'len(corpus_sects_ls): {len(corpus_sects_ls)}')\n",
        "  print(f'    First section: Length={len(corpus_sects_ls[0])}\\n    {corpus_sects_ls[0][:500]}')\n",
        "  print(f'    Second section: {corpus_sects_ls[1][:500]}')\n",
        "  print('\\n')\n",
        "  print(f'    Second-Last section: {corpus_sects_ls[-2][:500]}')\n",
        "  print(f'    Last section: {corpus_sects_ls[-1][:500]}')\n",
        "\n",
        "\n",
        "\n",
        "  # Strip off whitespace \n",
        "  corpus_sects_ls = [x.strip() for x in corpus_sects_ls]\n",
        "\n",
        "  # Filter out empty lines\n",
        "  corpus_sects_ls = [x for x in corpus_sects_ls if not (len(x.strip()) <= MIN_SECT_LEN)]\n",
        "\n",
        "  # Filter out the Section separator '-----' lines\n",
        "  corpus_sects_ls = [x for x in corpus_sects_ls if not (x.strip().startswith('----- '))]\n",
        "\n",
        "  # Filter out the Section separator 'SECTION ' lines\n",
        "  corpus_sects_ls = [x for x in corpus_sects_ls if not (x.strip().startswith('SECTION '))]\n",
        "\n",
        "  # Filter out any possible embedded 'CHAPTER ' lines\n",
        "  # TODO: Zeroing out corpus_sects_ls\n",
        "  # corpus_sects_ls = del_substrs_list(corpus_sects_ls, pattern_chap) # corpus_sects_ls = [re.sub(rf'{pattern_sect}', '', x) for x in corpus_sects_ls]\n",
        "\n",
        "  # Filter out the Chapter separator 'CHAPTER ' lines\n",
        "  # Keep for now, messy but enables proper SECTION assignments to appropraite CHAPTERs\n",
        "  # corpus_sects_ls = [x for x in corpus_sects_ls if not (x.strip().startswith('CHAPTER '))]\n",
        "\n",
        "\n",
        "  print(f'About to process {len(corpus_sects_ls)} Sections')\n",
        "  # Filter out Sentences in Section that don't have a corresponding Sentence in corpus_sents_df \n",
        "  # Old Strategy: Filter out lines containing embedded SECTION or CHAPTER RegEx patterns \n",
        "\n",
        "  sect_sentences_match_ls = []\n",
        "  sect_sentences_unmatch_ls = []\n",
        "  sect_sentences_unmatch_ct = 0\n",
        "  corpus_sentence_current = 0\n",
        "\n",
        "\n",
        "  for asect_no, asection in enumerate(corpus_sects_ls):\n",
        "    # sect_sentences_ls = []\n",
        "\n",
        "    # NLTK Sentence Tokenization\n",
        "    # 3605 lines with 'To the Lighthouse' by V.Woolf\n",
        "    # asect_sents_ls = (sent_tokenize(asect))\n",
        "    \n",
        "    # SpaCy Sentence Tokenization\n",
        "    # TODO: Speed up my specializaing pipe\n",
        "    # 3968 lines for 'To the Lighthouse' by V.Woolf\n",
        "    # doc = nlp(asect)   \n",
        "    # asect_sents_ls = [sent for sent in doc.sents]\n",
        "    # asect_sents_ls = [x for x in doc]\n",
        "\n",
        "    # PySBD Sentence Tokenization\n",
        "    # 3457 lines for 'To the Lighthouse' by V.Woolf\n",
        "    # using pysbd and SpaCy\n",
        "    from pysbd.utils import PySBDFactory\n",
        "    nlp = spacy.blank('en')\n",
        "    # explicitly adding component to pipeline\n",
        "    # (recommended - makes it more readable to tell what's going on)\n",
        "    nlp.add_pipe(PySBDFactory(nlp))\n",
        "    # or you can use it implicitly with keyword\n",
        "    # pysbd = nlp.create_pipe('pysbd')\n",
        "    # nlp.add_pipe(pysbd)\n",
        "    # doc = nlp('My name is Jonas E. Smith. Please turn to p. 55.')\n",
        "    # print(list(doc.sents))\n",
        "    doc = nlp(asection)\n",
        "    asect_sents_ls = list(doc.sents)\n",
        "\n",
        "    # Create a normalized/no puncutation list of Corpus sentences for clean test comparisions filtered\n",
        "    corpus_sents_nopunct_ls = [re.sub(r'[^A-Za-z0-9]', ' ',x) for x in corpus_sents_ls]\n",
        "    # corpus_sents_nopunct_ls = [x for x in corpus_sents_nopunct_ls if x.isalnum()]\n",
        "    corpus_sents_nopunct_strip_ls = [x.strip() for x in corpus_sents_nopunct_ls]\n",
        "\n",
        "    for j, asection_sentence_raw in enumerate(asect_sents_ls):\n",
        "      asection_sentence_str = str(asection_sentence_raw)\n",
        "      asection_sentence_nopunct_str = re.sub(r'[^A-Za-z0-9]', ' ', asection_sentence_str)\n",
        "      asection_sentence_nopunct_strip_str = asection_sentence_nopunct_str.strip()\n",
        "      # This 'in' test is not sufficient, need to strip out punctuation/normalize\n",
        "      if asection_sentence_nopunct_strip_str in corpus_sents_nopunct_strip_ls:\n",
        "        sect_sentences_match_ls.append((asect_no, asection_sentence_str))\n",
        "        print(f'  Matched Segment Sent')\n",
        "      else:\n",
        "        sect_sentences_unmatch_ct += 1\n",
        "        print(f'  UNMATCHED Corpus Sentence #[{corpus_sentence_current}]\\n           Segment Sentence #{j}: [{asection_sentence_str}]\\n            [{asection_sentence_nopunct_strip_str}]')\n",
        "        sect_sentences_unmatch_ls.append(asection_sentence_str)\n",
        "\n",
        "      corpus_sentence_current += 1\n",
        "\n",
        "    # section_str = ' '.join(sect_sentences_ls)\n",
        "    # sect_sentences_match_ls.append(section_str)\n",
        "\n",
        "    # if re.search(rf'{pattern_chap}', asect):\n",
        "    #   print(f'In Section #{i} removing embedded CHAPTER:\\n\\n    {asect}')\n",
        "    #   asect = re.sub(rf'{pattern_chap}', ' ', asect)\n",
        "\n",
        "  return corpus_sects_ls, sect_sentences_match_ls, sect_sentences_unmatch_ls\n",
        "\n",
        "\n",
        "# return corpus_sects_ls, corpus_raw_str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8z8ZY5n8BRs"
      },
      "source": [
        "def corpus2parags(corpus_filename):\n",
        "  '''\n",
        "  Given a corpus_filename (assuming already %cd into correct subdir)\n",
        "  Return a list of min preprocessed raw paragraphs (corpus_parags_ls)\n",
        "  '''\n",
        "\n",
        "  with open(corpus_filename, \"r\", encoding=CORPUS_ENCODING) as infp:\n",
        "    corpus_raw_str = infp.read()\n",
        "\n",
        "  corpus_parags_ls = re.split(r'[\\n]{2,}', corpus_raw_str)\n",
        "  print(f'Corpus Paragraph Raw Count: {len(corpus_parags_ls)}')\n",
        "\n",
        "  # Strip off whitespace\n",
        "  corpus_parags_ls = [x.strip() for x in corpus_parags_ls]\n",
        "\n",
        "  # Filter out numbers(often footnotes) from Paragraphs\n",
        "  corpus_parags_ls = [re.sub(r'[0-9]',' ',x) for x in corpus_parags_ls]\n",
        "\n",
        "  # Filter out the Section separator '-----' lines\n",
        "  # Redundant, filed by punctuation only filter above\n",
        "  corpus_parags_ls = [x for x in corpus_parags_ls if not (x.strip().startswith('----- '))]\n",
        "\n",
        "  # Filter out the Chapter/Section header lines\n",
        "  corpus_parags_ls = [x for x in corpus_parags_ls if not (x.startswith('CHAPTER '))]\n",
        "  corpus_parags_ls = [x for x in corpus_parags_ls if not (x.startswith('SECTION '))]\n",
        "  corpus_parags_ls = [x for x in corpus_parags_ls if not (x.startswith('BOOK '))]\n",
        "  corpus_parags_ls = [x for x in corpus_parags_ls if not (re.match(r\"^[ ]*[0-9]{1,3}[\\.]?[ ]*$\", x))]\n",
        "  corpus_parags_ls = [x for x in corpus_parags_ls if not (re.match(r\"^[ ]*[IVXLC]{1,10}[\\.]?[ ]*$\", x))]\n",
        "\n",
        "  # Filter out lines containing only punctuation (e.g. '\"', '.', '...', etc)\n",
        "  parag_before_punctstrip_ct = len(corpus_parags_ls)\n",
        "  corpus_parags_ls = [x for x in corpus_parags_ls if len((re.sub(r'[^\\w\\s]','',x)).strip()) > MIN_PARAG_LEN]\n",
        "  print(f'Punctuation only Paragraph Count: {len(corpus_parags_ls) - parag_before_punctstrip_ct}')\n",
        "\n",
        "  # Filter out empty lines Paragraphs\n",
        "  corpus_parags_ls = [x for x in corpus_parags_ls if (len(x.strip()) >= MIN_PARAG_LEN)]\n",
        "\n",
        "  # Made a deepcopy of the original raw paragraphs after simple cleaning while continuing to clean the original\n",
        "  corpus_parags_raw_ls = [x for x in corpus_parags_ls]\n",
        "\n",
        "  # Strip out non-printing characters\n",
        "  corpus_parags_ls = [re.sub(f'[^{re.escape(string.printable)}]', ' ', x) for x in corpus_parags_ls]\n",
        "\n",
        "  # Condense multiple whitespaces down into one\n",
        "  corpus_parags_ls = [' '.join(x.split()).strip() for x in corpus_parags_ls]\n",
        "\n",
        "  # Verify no Chapter/Section header lines remain\n",
        "  for i,temp_str in enumerate(corpus_parags_ls):\n",
        "    if temp_str.startswith('CHAPTER '):\n",
        "      print(f'Parag #{i}: {temp_str}')\n",
        "\n",
        "  return corpus_parags_ls, corpus_parags_raw_ls, corpus_raw_str\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxTYt6xsD5Iq"
      },
      "source": [
        "def sect2parags(sect_str):\n",
        "  '''\n",
        "  Given a Section as a text string\n",
        "  Return a list of raw Paragraphs and a raw Section text string\n",
        "  '''\n",
        "\n",
        "  sect_clean_str = re.sub(f'[^{re.escape(string.printable)}]', ' ', sect_str)\n",
        "  sect_parags_raw_ls = re.split(r'[\\n]{2,}', sect_clean_str)\n",
        "  # print(f'Section Paragraph Raw Count: {len(sect_parags_raw_ls)}')\n",
        "\n",
        "  # Strip off whitespace\n",
        "  sect_parags_raw_ls = [x.strip() for x in sect_parags_raw_ls]\n",
        "\n",
        "  # Filter out numbers(often footnotes) from Paragraphs\n",
        "  sect_parags_raw_ls = [re.sub(r'[0-9]',' ',x) for x in sect_parags_raw_ls]\n",
        "\n",
        "  # Filter out the Section separator '-----' lines\n",
        "  # Redundant, filed by punctuation only filter above\n",
        "  sect_parags_raw_ls = [x for x in sect_parags_raw_ls if not (x.strip().startswith('----- '))]\n",
        "\n",
        "  # Filter out the Chapter/Section header lines\n",
        "  sect_parags_raw_ls = [x for x in sect_parags_raw_ls if not (x.startswith('CHAPTER '))]\n",
        "  sect_parags_raw_ls = [x for x in sect_parags_raw_ls if not (x.startswith('SECTION '))]\n",
        "  sect_parags_raw_ls = [x for x in sect_parags_raw_ls if not (x.startswith('BOOK '))]\n",
        "  sect_parags_raw_ls = [x for x in sect_parags_raw_ls if not (re.match(r\"^[ ]*[0-9]{1,3}[\\.]?[ ]*$\", x))]\n",
        "  sect_parags_raw_ls = [x for x in sect_parags_raw_ls if not (re.match(r\"^[ ]*[IVXLC]{1,10}[\\.]?[ ]*$\", x))]\n",
        "\n",
        "  # Filter out lines containing only punctuation (e.g. '\"', '.', '...', etc)\n",
        "  parag_before_punctstrip_ct = len(sect_parags_raw_ls)\n",
        "  sect_parags_raw_ls = [x for x in sect_parags_raw_ls if len((re.sub(r'[^\\w\\s]','',x)).strip()) > MIN_PARAG_LEN]\n",
        "  # print(f'Punctuation only Paragraph Count: {len(sect_parags_raw_ls) - parag_before_punctstrip_ct}')\n",
        "\n",
        "  # Filter out Paragraphs that are empty or shorter than MIN_PARAG_LEN\n",
        "  sect_parags_raw_ls = [x for x in sect_parags_raw_ls if (len(x.strip()) >= MIN_PARAG_LEN)]\n",
        "\n",
        "  # Made a clean copy of the original raw paragraphs after simple cleaning while continuing to clean the original\n",
        "  sect_parags_clean_ls = [clean_text(x) for x in sect_parags_raw_ls]\n",
        "\n",
        "  # Verify no Chapter/Section header lines remain\n",
        "  for i,temp_str in enumerate(sect_parags_raw_ls):\n",
        "    if temp_str.startswith('CHAPTER '):\n",
        "      print(f'ERROR: CHAPTERS not filtered\\n    Parag #{i}: {temp_str}')\n",
        "\n",
        "  return sect_parags_raw_ls, sect_clean_str\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWw618b3vQmJ"
      },
      "source": [
        "from pysbd.utils import PySBDFactory\n",
        "nlp = spacy.blank('en')\n",
        "# explicitly adding component to pipeline\n",
        "# (recommended - makes it more readable to tell what's going on)\n",
        "nlp.add_pipe(PySBDFactory(nlp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e0OnfrGJ_GB"
      },
      "source": [
        "def parag2sents(parag_str, sent_tok='pysbd'):\n",
        "  '''\n",
        "  Given a Paragraph as a long string and a Sentence tokenizer engine ['pysbd'(default)|'both'|'nltk']\n",
        "  Return a list of every Sentence within the given Paragraph\n",
        "  '''\n",
        "\n",
        "  # Load PySBD if necessary\n",
        "  \"\"\"\n",
        "  if (sent_tok == 'pysbd') | (sent_tok == 'both'):\n",
        "    from pysbd.utils import PySBDFactory\n",
        "    nlp = spacy.blank('en')\n",
        "    # explicitly adding component to pipeline\n",
        "    # (recommended - makes it more readable to tell what's going on)\n",
        "    nlp.add_pipe(PySBDFactory(nlp))\n",
        "    # pysbd = nlp.create_pipe('pysbd')\n",
        "    # nlp.add_pipe(pysbd)\n",
        "    # doc = nlp('My name is Jonas E. Smith. Please turn to p. 55.')\n",
        "    # print(list(doc.sents))\n",
        "  \"\"\";\n",
        "\n",
        "  # Minimally clean Paragraph string of non-printing characters\n",
        "  parag_clean_str = re.sub(f'[^{re.escape(string.printable)}]', ' ', parag_str).strip()\n",
        "\n",
        "  # Replace embedded \\n with spaces\n",
        "  parag_clean_str = re.sub('[\\n]{1,}', ' ', parag_clean_str)\n",
        "\n",
        "  # Replaces mulitple whitespaces with one space\n",
        "  parag_clean_str = ' '.join(parag_clean_str.split())\n",
        "\n",
        "\n",
        "  # TOKENIZE with 1 of 3 ways\n",
        " \n",
        "  # TODO: Try simple/fast RegEx Tokenizer in lieu of NTLK to complement PyBSD\n",
        "\n",
        "  # ONE: Tokenize with PyBSD and NLTK \n",
        "  if (sent_tok == 'both'):\n",
        "    doc = nlp(parag_clean_str)\n",
        "    parag_sents_first_ls = list(doc.sents)\n",
        "    for asent_temp in parag_sents_first_ls:\n",
        "      asent_tokenized_temp = sent_tokenize(asent_temp)\n",
        "      parag_sents_ls.append(asent_tokenized_temp)\n",
        "    # print(f'  BOTH: {len(parag_sents_ls)} Sentences found in Paragraph')\n",
        "\n",
        "  # TWO: Tokenize with PyBSD\n",
        "  elif (sent_tok == 'pysbd'):\n",
        "    doc = nlp(parag_clean_str)\n",
        "    parag_sents_ls = list(doc.sents)\n",
        "    # print(f' PySBD: {len(parag_sents_ls)} Sentences found in Paragraph')\n",
        "\n",
        "  # THREE: Tokenize with NLTK\n",
        "  elif (sent_tok == 'nltk'):\n",
        "    parag_sents_ls = sent_tokenize(parag_clean_str)\n",
        "    # print(f' NLTK: {len(parag_sents_ls)} Sentences found in Paragraph')\n",
        "\n",
        "  # ERROR\n",
        "  else:\n",
        "    print(f'ERROR: sent_tok={sent_tok} but must be [pysbd(default)|both|nltk]')\n",
        "\n",
        "\n",
        "  # CLEAN Sentences\n",
        "\n",
        "  # Strip off whitespace from Sentences\n",
        "  parag_sents_ls = [str(x).strip() for x in parag_sents_ls]\n",
        "\n",
        "  # Copy/Clean Sentences into new list\n",
        "  # Filter out numbers(often footnotes) from Sentences\n",
        "  parag_sents_ls = [re.sub(r'[0-9]',' ',x) for x in parag_sents_ls]\n",
        "\n",
        "  # Filter out the Chapter/Section header lines\n",
        "  parag_sents_ls = [x for x in parag_sents_ls if not (re.match(r\"^[\\s]*CHAPTER[\\s]*$\", x))]\n",
        "  parag_sents_ls = [x for x in parag_sents_ls if not (re.match(r\"^[\\s]*SECTION[\\s]*$\", x))]\n",
        "  parag_sents_ls = [x for x in parag_sents_ls if not (re.match(r\"^[\\s]BOOK[\\s]*$\", x))]\n",
        "  parag_sents_ls = [x for x in parag_sents_ls if not (re.match(r\"^[\\s]*[0-9]{1,3}[\\.]?[\\s]*$\", x))]\n",
        "  parag_sents_ls = [x for x in parag_sents_ls if not (re.match(r\"^[\\s]*[IVXLC]{1,10}[\\.]?[\\s]*$\", x))]\n",
        "\n",
        "  # Filter out lines containing only punctuation (e.g. '\"', '.', '...', etc)\n",
        "  parag_before_punctstrip_ct = len(parag_sents_ls)\n",
        "  parag_sents_ls = [x for x in parag_sents_ls if len((re.sub(r'[^\\w\\s]','',x)).strip()) > MIN_PARAG_LEN]\n",
        "  # print(f'Punctuation only Paragraph Count: {len(parag_sents_ls) - parag_before_punctstrip_ct}')\n",
        "\n",
        "  # Condense multiple consecutive whitespaces down to one whitespace\n",
        "  parag_sents_ls = [' '.join(x.split()) for x in parag_sents_ls]\n",
        "\n",
        "\n",
        "  # Filter Sentences that are empty or shorter than MIN_SENT_LEN\n",
        "  parag_sents_ls = [x for x in parag_sents_ls if (len(x.strip()) >= MIN_SENT_LEN)]\n",
        "\n",
        "  return parag_sents_ls, parag_clean_str\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX1gjU7S8esY"
      },
      "source": [
        "\"\"\"\n",
        "def parag2sents(parag_str, sent_tok='py'):\n",
        "  '''\n",
        "  Given a Paragraph as a string,\n",
        "  Return a list of raw Sentences and a raw text Paragraph string\n",
        "  '''\n",
        "\n",
        "  parag_clean_str = re.sub(f'[^{re.escape(string.printable)}]', '', parag_str)\n",
        "  parag_parags_raw_ls = re.split(r'[\\n]{2,}', parag_clean_str)\n",
        "  print(f'Section Paragraph Raw Count: {len(parag_parags_raw_ls)}')\n",
        "\n",
        "  # Strip off whitespace\n",
        "  parag_parags_raw_ls = [x.strip() for x in parag_parags_raw_ls]\n",
        "\n",
        "  # Filter out numbers(often footnotes) from Paragraphs\n",
        "  sect_parags_raw_ls = [re.sub(r'[0-9]','',x) for x in sect_parags_raw_ls]\n",
        "\n",
        "  # Filter out the Section separator '-----' lines\n",
        "  # Redundant, filed by punctuation only filter above\n",
        "  sect_parags_raw_ls = [x for x in sect_parags_raw_ls if not (x.strip().startswith('----- '))]\n",
        "\n",
        "  # Filter out the Chapter/Section header lines\n",
        "  sect_parags_raw_ls = [x for x in sect_parags_raw_ls if not (x.startswith('CHAPTER '))]\n",
        "  sect_parags_raw_ls = [x for x in sect_parags_raw_ls if not (x.startswith('SECTION '))]\n",
        "  sect_parags_raw_ls = [x for x in sect_parags_raw_ls if not (x.startswith('BOOK '))]\n",
        "  sect_parags_raw_ls = [x for x in sect_parags_raw_ls if not (re.match(r\"^[ ]*[0-9]{1,3}[\\.]?[ ]*$\", x))]\n",
        "  sect_parags_raw_ls = [x for x in sect_parags_raw_ls if not (re.match(r\"^[ ]*[IVXLC]{1,10}[\\.]?[ ]*$\", x))]\n",
        "\n",
        "\n",
        "  parag_no = 0\n",
        "  # sent_base = 0\n",
        "  corpus_sents_ls = []\n",
        "  for parag_no,aparag in enumerate(corpus_parags_ls):\n",
        "    sents_ls = sent_tokenize(aparag)\n",
        "    # Delete (whitespace only) sentences\n",
        "    sents_ls = [x.strip() for x in sents_ls if len(x.strip()) > MIN_SENT_LEN]\n",
        "    # Delete (punctuation only) sentences\n",
        "    sents_ls = [x for x in sents_ls if len((re.sub(r'[^\\w\\s]','',x)).strip()) > MIN_SENT_LEN]\n",
        "    # Delete numbers (int or float) sentences\n",
        "    sents_ls = [x for x in sents_ls if not (x.strip().isnumeric())]\n",
        "\n",
        "    # Filter out leading SECTION separator 'SECTION ' lines\n",
        "    for i,temp_str in enumerate(sents_ls):\n",
        "      if temp_str.startswith('SECTION '):\n",
        "        print(f'Sentence #{i}: {temp_str}')\n",
        "    sents_ls = [x for x in sents_ls if not (x.startswith('SECTION '))]\n",
        "\n",
        "    # Filter out leading Chapter separator 'CHAPTER ' lines\n",
        "    for i,temp_str in enumerate(sents_ls):\n",
        "      if temp_str.startswith('CHAPTER '):\n",
        "        print(f'Sentence #{i}: {temp_str}')\n",
        "    sents_ls = [x for x in sents_ls if not (x.startswith('CHAPTER '))]\n",
        "    \n",
        "    # Filter out lines containing embedded SECTION or CHAPTER RegEx patterns \n",
        "    for i,temp_str in enumerate(sents_ls):\n",
        "      # TODO: More specific, robust filtering mechnism \n",
        "      if (re.search(rf'{pattern_sect}', temp_str)):\n",
        "        pass\n",
        "      if (re.search(rf'{pattern_chap}', temp_str)):\n",
        "        pass\n",
        "      else:\n",
        "        corpus_sents_ls.append([sent_no, parag_no, temp_str])\n",
        "        sent_no += 1\n",
        "\n",
        "    # print(f'Returning with corpus_sents_ls length = {len(corpus_sents_ls)}')\n",
        "  \n",
        "  return corpus_sents_ls\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRopU4e3IQ2R"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "def parag2sents(corpus_parags_ls):\n",
        "  '''\n",
        "  Given a list of paragraphs,\n",
        "  Return a list of lists of Sentences [sent_no, parag_no, asent(text)]\n",
        "  '''\n",
        "\n",
        "  sent_no = 0\n",
        "  # sent_base = 0\n",
        "  corpus_sents_ls = []\n",
        "  for parag_no,aparag in enumerate(corpus_parags_ls):\n",
        "    sents_ls = sent_tokenize(aparag)\n",
        "    # Delete (whitespace only) sentences\n",
        "    sents_ls = [x.strip() for x in sents_ls if len(x.strip()) > MIN_SENT_LEN]\n",
        "    # Delete (punctuation only) sentences\n",
        "    sents_ls = [x for x in sents_ls if len((re.sub(r'[^\\w\\s]','',x)).strip()) > MIN_SENT_LEN]\n",
        "    # Delete numbers (int or float) sentences\n",
        "    sents_ls = [x for x in sents_ls if not (x.strip().isnumeric())]\n",
        "\n",
        "    # Filter out leading SECTION separator 'SECTION ' lines\n",
        "    for i,temp_str in enumerate(sents_ls):\n",
        "      if temp_str.startswith('SECTION '):\n",
        "        print(f'Sentence #{i}: {temp_str}')\n",
        "    sents_ls = [x for x in sents_ls if not (x.startswith('SECTION '))]\n",
        "\n",
        "    # Filter out leading Chapter separator 'CHAPTER ' lines\n",
        "    for i,temp_str in enumerate(sents_ls):\n",
        "      if temp_str.startswith('CHAPTER '):\n",
        "        print(f'Sentence #{i}: {temp_str}')\n",
        "    sents_ls = [x for x in sents_ls if not (x.startswith('CHAPTER '))]\n",
        "    \n",
        "    # Filter out lines containing embedded SECTION or CHAPTER RegEx patterns \n",
        "    for i,temp_str in enumerate(sents_ls):\n",
        "      # TODO: More specific, robust filtering mechnism \n",
        "      if (re.search(rf'{pattern_sect}', temp_str)):\n",
        "        pass\n",
        "      if (re.search(rf'{pattern_chap}', temp_str)):\n",
        "        pass\n",
        "      else:\n",
        "        corpus_sents_ls.append([sent_no, parag_no, temp_str])\n",
        "        sent_no += 1\n",
        "\n",
        "    # print(f'Returning with corpus_sents_ls length = {len(corpus_sents_ls)}')\n",
        "  \n",
        "  return corpus_sents_ls\n",
        "\n",
        "\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-adBsfM38eo0"
      },
      "source": [
        "# corpus_sents_ls = parag2sents(corpus_parags_ls)\n",
        "# len(corpus_sents_ls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaRD7RL9IOeg"
      },
      "source": [
        "# Generate full path and timestamp for new filepath/filename\n",
        "\n",
        "def gen_pathfiletime(file_str, subdir_str=''):\n",
        "\n",
        "  # Geenreate compressed author and title substrings\n",
        "  author_raw_str = ''.join(CORPUS_AUTHOR.split()).lower()\n",
        "  title_raw_str = ''.join(CORPUS_TITLE.split()).lower()\n",
        "\n",
        "  # Generate current/unique datetime string\n",
        "  datetime_str = str(datetime.now().strftime('%Y%m%d%H%M%S'))\n",
        "\n",
        "  # Built fullpath+filename string\n",
        "  file_base, file_ext = file_str.split('.')\n",
        "\n",
        "  author_str = re.sub('[^A-Za-z0-9]+', '', author_raw_str)\n",
        "  title_str = re.sub('[^A-Za-z0-9]+', '', title_raw_str)\n",
        "\n",
        "  full_filepath_str = f'{subdir_str}{file_base}_{author_str}_{title_str}_{datetime_str}.{file_ext}'\n",
        "\n",
        "  # print(f'Returning from gen_savepath() with full_filepath={full_filepath}')\n",
        "\n",
        "  return full_filepath_str\n",
        "\n",
        "# Test\n",
        "# pathfilename_str = gen_pathfiletime('hist_paraglen.png')\n",
        "# print(pathfilename_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9FDtpQ6QaEJ"
      },
      "source": [
        "#This function converts to lower-case, removes square bracket, removes numbers and punctuation\n",
        " \n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = contractions.fix(text)  # Expand contrations\n",
        "    text = re.sub(\"\\\\'s\", \" own\", text)  # After expanding normal apostrophes, expand possessive apostrophes \"Mary's car\" -> \"Mary own car\"\n",
        "\n",
        "    # TODO: More formally\n",
        "    # https://towardsdatascience.com/nlp-building-text-cleanup-and-preprocessing-pipeline-eba4095245a0\n",
        "    text = re.sub(\"-\\n\", \" \", text)       # Join end of line words split by continuation hyphens\n",
        "    text = re.sub(\"-\\n\\r\", \" \", text)\n",
        "    text = re.sub(\"-\\r\", \" \", text)\n",
        "    text = re.sub(\"\\[.*?\\]\", \" \", text)\n",
        "\n",
        "    text = re.sub(\"-\", \" \", text)  # Special care for hypenated words well-known: choose option (a)\n",
        "                                   # (a) 'well known', (b) 'wellknown' (c) 'well known' and 'wellknown' cf: https://datascience.stackexchange.com/questions/81072/how-to-process-the-hyphenated-english-words-for-any-nlp-problem\n",
        "    text = re.sub(\"/\", \" \", text)  # sociability/conversation/interesting -> sociability conversation interesting                             \n",
        "    text = re.sub(\"[%s]\" % re.escape(string.punctuation), \" \", text)\n",
        "    text = re.sub(\"\\w*\\d\\w*\", \" \", text)\n",
        "    text = re.sub(\"[\\n]\", \" \", text)  # Replace newline with space\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lYUmVuvl2OK"
      },
      "source": [
        "def save_dataframes():\n",
        "  '''\n",
        "  Save all Corpus DataFrames\n",
        "  '''\n",
        "\n",
        "  # Save Preprocessed Corpus Sentences DataFrame\n",
        "\n",
        "  # author_str = ''.join(CORPUS_AUTHOR.split()).lower()\n",
        "  # title_str = ''.join(CORPUS_TITLE.split()).lower()\n",
        "  title_str = ''.join(CORPUS_FILENAME.split('.')[0]).lower()\n",
        "  datetime_now = datetime.utcnow().strftime(\"%Y%m%d_%H%M\")\n",
        "\n",
        "\n",
        "  # Sentences Raw\n",
        "  corpus_sents_filename = f'corpus_text_raw_{title_str}.csv'\n",
        "  print(f'Saving Raw Sentences to file: {corpus_sents_filename}')\n",
        "  corpus_sents_df['sent_raw'].to_csv(corpus_sents_filename)\n",
        "\n",
        "  # Sentences Clean\n",
        "  corpus_sents_filename = f'corpus_text_clean_{title_str}.csv'\n",
        "  print(f'Saving Clean Sentences to file: {corpus_sents_filename}')\n",
        "  corpus_sents_df['sent_clean'].to_csv(corpus_sents_filename)\n",
        "\n",
        "\n",
        "  # Sentence DataFrame\n",
        "  corpus_sents_filename = f'corpus_sents_{title_str}.csv'\n",
        "  print(f'Saving Sentences DataFrame to file: {corpus_sents_filename}')\n",
        "  corpus_sents_df.to_csv(corpus_sents_filename)\n",
        "\n",
        "  # Paragraph DataFrame\n",
        "  corpus_parags_filename = f'corpus_parags_{title_str}.csv'\n",
        "  print(f'Saving Paragraph DataFrame to file: {corpus_parags_filename}')\n",
        "  corpus_parags_df.to_csv(corpus_parags_filename)\n",
        "\n",
        "  # if SECTION_HEADINGS != 'None':  # Even if no Sections, save dummy placeholder\n",
        "  #                                   filled with Chapter data\n",
        "  # Section DataFrame\n",
        "  corpus_sects_filename = f'corpus_sects_{title_str}.csv'\n",
        "  print(f'Saving Section DataFrame to file: {corpus_sects_filename}')\n",
        "  corpus_sects_df.to_csv(corpus_sects_filename)\n",
        "\n",
        "  # Chapter DataFrame\n",
        "  corpus_chaps_filename = f'corpus_chaps_{title_str}.csv'\n",
        "  print(f'Saving Chapter DataFrame to file: {corpus_chaps_filename}')\n",
        "  corpus_chaps_df.to_csv(corpus_chaps_filename)\n",
        "\n",
        "  \"\"\"\n",
        "  if sentiment_df == True:\n",
        "\n",
        "    corpus_sentiment_filename = f'sum_sentiments_baselines_{title_str}.csv' # _{datetime_now}.csv'\n",
        "    print(f'Saving Corpus Sentences to file: {corpus_sentiment_filename}')\n",
        "    corpus_baseline_df.to_csv(corpus_sentiment_filename)\n",
        "\n",
        "    corpus_parags_filename = f'sum_sentiments_parags_baselines_{title_str}.csv' # _{datetime_now}.csv'\n",
        "    print(f'Saving Corpus Paragraphs to file: {corpus_parags_filename}')\n",
        "    corpus_parags_df.to_csv(corpus_parags_filename)\n",
        "\n",
        "    corpus_sects_filename = f'sum_sentiments_sects_baselines_{title_str}.csv' # _{datetime_now}.csv'\n",
        "    print(f'Saving Corpus Sections to file: {corpus_sects_filename}')\n",
        "    corpus_sects_df.to_csv(corpus_sects_filename)\n",
        "\n",
        "    corpus_chaps_filename = f'sum_sentiments_chaps_baselines_{title_str}.csv' # _{datetime_now}.csv'\n",
        "    print(f'Saving Corpus Chapters to file: {corpus_chaps_filename}')\n",
        "    corpus_chaps_df.to_csv(corpus_chaps_filename)\n",
        "  \"\"\";\n",
        "\n",
        "  return\n",
        "\n",
        "# Test\n",
        "# save_dataframes()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUvKJEybUIeP"
      },
      "source": [
        "## **Sentiment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8TwYCrwwUco"
      },
      "source": [
        "# Test to find longest String in Corpus (in terms of #tokens) \n",
        "#      must be <510 tokens for Transformers\n",
        "\n",
        "# corpus_sents_df['sent_raw'].astype(str).apply(lambda x: len(x.split())).max() # split().len()).max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnbQ_2Xmj1uW"
      },
      "source": [
        "# get_sentiments(model_base=model_base, sentiment_fn=sentiment_sentimentr, sentiment_type='lexicon')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtxqQjU0Odos"
      },
      "source": [
        "# corpus_sents_df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0vWzfQ9D4Fr"
      },
      "source": [
        "# corpus_parags_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOsfpOS4uHGX"
      },
      "source": [
        "def list2stdscaler(tseries_ls):\n",
        "  '''\n",
        "  Given a list of floating point number\n",
        "  Return a pd.Series that has been Standardized Scaled\n",
        "  '''\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "\n",
        "  tseries_np = np.array(tseries_ls)\n",
        "  \n",
        "  tseries_np = tseries_np.reshape((len(tseries_np), 1))\n",
        "\n",
        "  scaler = scaler.fit(tseries_np)\n",
        "  print('Mean: %f, StandardDeviation: %f' % (scaler.mean_, np.sqrt(scaler.var_)))\n",
        "  tseries_xform_np = scaler.transform(tseries_np)\n",
        "\n",
        "  return pd.Series(tseries_xform_np.flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La0qTp9BwXQV"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "# Test MedianIQR vs StandarizedScalar \n",
        "\n",
        "corpus_sents_df['sentimentr_medianiqr'].plot(alpha=0.1)\n",
        "corpus_sents_df['sentimentr_stdscore'].plot(alpha=0.3)\n",
        "# corpus_sents_df['sentimentr_meanstd'].plot(alpha=0.3)\n",
        "corpus_sents_df['sentimentr'].plot(alpha=0.2)\n",
        "\n",
        "plt.legend(loc='best')\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z0jQoBlfPir"
      },
      "source": [
        "def standardize_tsls(ts_df, col_ls):\n",
        "  '''\n",
        "  Given a DataFrame and list of Columns in that DataFrame\n",
        "  Create 4 new Standardized Columns for each given Columns\n",
        "  '''\n",
        "\n",
        "  # Create 4 new column names for each column provided\n",
        "  for amodel in col_ls:\n",
        "    # col_meanstd = f'{amodel}_meanstd'\n",
        "    col_medianiqr = f'{amodel}_medianiqr'\n",
        "    col_stdscaler = f'{amodel}_stdscaler'\n",
        "    col_lnorm_meanstd = f'{amodel}_lnorm_meanstd'\n",
        "    col_lnorm_medianiqr = f'{amodel}_lnorm_medianiqr'\n",
        "\n",
        "    # Standardize each column provided using Standard Scaler and  MedianIQRScaling\n",
        "    ts_df[col_stdscaler]  = list2stdscaler(ts_df[amodel])\n",
        "    ts_df[col_medianiqr]  = median_iqr_scaler.fit_transform(np.array(ts_df[amodel]).reshape(-1, 1))\n",
        "    # Normalize the Sentence Sentiment by dividing by Chapter Length\n",
        "    text_len_ls = list(ts_df['token_len'])\n",
        "    text_sentiment_ls = list(ts_df[amodel])\n",
        "    textsentiment_norm_ls = [text_sentiment_ls[i]/text_len_ls[i] for i in range(len(text_len_ls))]\n",
        "    # RobustStandardize Sentence sentiment values\n",
        "    ts_df[col_lnorm_meanstd]  = mean_std_scaler.fit_transform(np.array(pd.Series(text_sentiment_norm_ls)).reshape(-1, 1))\n",
        "    ts_df[col_lnorm_medianiqr]  = median_iqr_scaler.fit_transform(np.array(pd.Series(text_sentiment_norm_ls)).reshape(-1, 1))\n",
        "\n",
        "  return\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLASKwzZF-Lh"
      },
      "source": [
        "def get_sentiments(model_base, sentiment_fn, sentiment_type='lexicon'):\n",
        "  '''\n",
        "  Given a model_base name and sentiment evaluation function\n",
        "  Calculate all the Sentence, Paragraph, Section and Chapter Sentiment Scores and Standardized variants\n",
        "  '''\n",
        "\n",
        "  # Calculate Sentiment Polarities\n",
        "\n",
        "  if sentiment_type == 'lexicon':\n",
        "    print(f'Processing Lexicon Sentiments/Sentences...')\n",
        "    corpus_sents_df[model_base] = corpus_sents_df['sent_raw'].apply(lambda text: sentiment_fn(str(text)))\n",
        "    print(f'Processing Lexicon Sentiments/Paragraphs...')\n",
        "    corpus_parags_df[model_base] = corpus_parags_df['parag_clean'].apply(lambda text: sentiment_fn(str(text)))\n",
        "    print(f'Processing Lexicon Sentiments/Sections...')\n",
        "    corpus_sects_df[model_base] = corpus_sects_df['sect_clean'].apply(lambda text: sentiment_fn(str(text)))\n",
        "    print(f'Processing Lexicon Sentiments/Chapters...')\n",
        "    corpus_chaps_df[model_base] = corpus_chaps_df['chap_clean'].apply(lambda text: sentiment_fn(str(text)))\n",
        "  \n",
        "  elif sentiment_type == 'compound':\n",
        "    # VADER\n",
        "\n",
        "    # Calculate dictionary of {neg/neu/pos/compound} values for sent_clean\n",
        "    print(f'Processing Compound Sentiments/Sentences...')\n",
        "    corpus_sents_df['scores'] = corpus_sents_df['sent_clean'].apply(lambda text: sentiment_fn(str(text)))\n",
        "    print(f'Processing Compound Sentiments/Paragraphs...')\n",
        "    corpus_parags_df['scores'] = corpus_parags_df['parag_clean'].apply(lambda text: sentiment_fn(str(text)))\n",
        "    print(f'Processing Compound Sentiments/Sections...')\n",
        "    corpus_sects_df['scores'] = corpus_sects_df['sect_clean'].apply(lambda text: sentiment_fn(str(text)))\n",
        "    print(f'Processing Compound Sentiments/Chapters...')\n",
        "    corpus_chaps_df['scores'] = corpus_chaps_df['chap_clean'].apply(lambda text: sentiment_fn(str(text)))\n",
        "\n",
        "    # Extract Compound Sentiment\n",
        "    corpus_sents_df[model_base]  = corpus_sents_df['scores'].apply(lambda score_dict: score_dict['compound'])\n",
        "    corpus_parags_df[model_base]  = corpus_parags_df['scores'].apply(lambda score_dict: score_dict['compound'])\n",
        "    corpus_sects_df[model_base]  = corpus_sects_df['scores'].apply(lambda score_dict: score_dict['compound'])\n",
        "    corpus_chaps_df[model_base]  = corpus_chaps_df['scores'].apply(lambda score_dict: score_dict['compound'])\n",
        "\n",
        "  elif sentiment_type == 'function':\n",
        "    # TextBlob\n",
        "\n",
        "    # Calculate dictionary of {neg/neu/pos/compound} values for sent_clean parag_clean\n",
        "    print(f'Processing Function Sentiments/Sentences...')\n",
        "    corpus_sents_df[model_base] = corpus_sents_df['sent_clean'].apply(lambda text: sentiment_fn(str(text)))\n",
        "    print(f'Processing Function Sentiments/Paragraphs...')\n",
        "    corpus_parags_df[model_base] = corpus_parags_df['parag_clean'].apply(lambda text: sentiment_fn(str(text)))\n",
        "    print(f'Processing Function Sentiments/Sections...')\n",
        "    corpus_sects_df[model_base] = corpus_sects_df['sect_clean'].apply(lambda text: sentiment_fn(str(text)))\n",
        "    print(f'Processing Function Sentiments/Chapters...')\n",
        "    corpus_chaps_df[model_base] = corpus_chaps_df['chap_clean'].apply(lambda text: sentiment_fn(str(text)))\n",
        "\n",
        "  else:\n",
        "    print(f'ERROR: sentiment_type={sentiment_type} but must be one of (lexicon, compound, function)')\n",
        "    return\n",
        "\n",
        "  # Create new column names\n",
        "  # col_meanstd = f'{model_base}_meanstd'\n",
        "  col_medianiqr = f'{model_base}_medianiqr'\n",
        "  col_stdscaler = f'{model_base}_stdscaler'\n",
        "  # col_lnorm_meanstd = f'{model_base}_lnorm_meanstd'\n",
        "  col_lnorm_medianiqr = f'{model_base}_lnorm_medianiqr'\n",
        "  col_lnorm_stdscaler = f'{model_base}_lnorm_stdscaler'\n",
        "\n",
        "\n",
        "  print('Standardizing Chapters')\n",
        "  # Get Chapter Robust Standardization with Standard Scaler and  MedianIQRScaling\n",
        "  corpus_chaps_df[col_stdscaler]  = list2stdscaler(corpus_chaps_df[model_base])\n",
        "  corpus_chaps_df[col_medianiqr]  = median_iqr_scaler.fit_transform(np.array(corpus_chaps_df[model_base]).reshape(-1, 1))\n",
        "  # Normalize the Chapter Sentiment by dividing by Chapter Length\n",
        "  chaps_len_ls = list(corpus_chaps_df['token_len'])\n",
        "  chaps_sentiment_ls = list(corpus_chaps_df[model_base])\n",
        "  chaps_sentiment_norm_ls = [chaps_sentiment_ls[i]/chaps_len_ls[i] for i in range(len(chaps_len_ls))]\n",
        "  # RobustStandardize Chapter sentiment values\n",
        "  # corpus_chaps_df[col_lnorm_meanstd]  = mean_std_scaler.fit_transform(np.array(pd.Series(chaps_sentiment_norm_ls)).reshape(-1, 1))\n",
        "  corpus_chaps_df[col_lnorm_stdscaler]  = mean_std_scaler.fit_transform(np.array(pd.Series(chaps_sentiment_norm_ls)).reshape(-1, 1))\n",
        "  corpus_chaps_df[col_lnorm_medianiqr]  = median_iqr_scaler.fit_transform(np.array(pd.Series(chaps_sentiment_norm_ls)).reshape(-1, 1))\n",
        "\n",
        "  print('Standardizing Sections')\n",
        "  # Get Section Robust Standardization with Standard Scaler and  MedianIQRScaling\n",
        "  # corpus_sects_df[col_stdscaler]  = mean_std_scaler.fit_transform(np.array(corpus_sects_df[model_base]).reshape(-1, 1))\n",
        "  corpus_sects_df[col_stdscaler]  = list2stdscaler(corpus_sects_df[model_base])\n",
        "  corpus_sects_df[col_medianiqr]  = median_iqr_scaler.fit_transform(np.array(corpus_sects_df[model_base]).reshape(-1, 1))\n",
        "  # Normalize the Section Sentiment by dividing by Section Length\n",
        "  sects_len_ls = list(corpus_sects_df['token_len'])\n",
        "  sects_sentiment_ls = list(corpus_sects_df[model_base])\n",
        "  sects_sentiment_norm_ls = [sects_sentiment_ls[i]/sects_len_ls[i] for i in range(len(sects_len_ls))]\n",
        "  # RobustStandardize Section sentiment values\n",
        "  # corpus_sects_df[col_lnorm_meanstd]  = mean_std_scaler.fit_transform(np.array(pd.Series(sects_sentiment_norm_ls)).reshape(-1, 1))\n",
        "  corpus_chaps_df[col_lnorm_stdscaler]  = mean_std_scaler.fit_transform(np.array(pd.Series(chaps_sentiment_norm_ls)).reshape(-1, 1))\n",
        "  corpus_sects_df[col_lnorm_medianiqr]  = median_iqr_scaler.fit_transform(np.array(pd.Series(sects_sentiment_norm_ls)).reshape(-1, 1))\n",
        "\n",
        "  print('Standardizing Paragraphs')\n",
        "  # Get Paragraph Robust Standardization with Standard Scaler and  MedianIQRScaling\n",
        "  corpus_parags_df[col_stdscaler]  = list2stdscaler(corpus_parags_df[model_base])\n",
        "  corpus_parags_df[col_medianiqr]  = median_iqr_scaler.fit_transform(np.array(corpus_parags_df[model_base]).reshape(-1, 1))\n",
        "  # Normalize the Paragraph Sentiment by dividing by Chapter Length\n",
        "  parags_len_ls = list(corpus_parags_df['token_len'])\n",
        "  parags_sentiment_ls = list(corpus_parags_df[model_base])\n",
        "  parags_sentiment_norm_ls = [parags_sentiment_ls[i]/parags_len_ls[i] for i in range(len(parags_len_ls))]\n",
        "  # RobustStandardize Paragraph sentiment values\n",
        "  # corpus_parags_df[col_lnorm_meanstd]  = mean_std_scaler.fit_transform(np.array(pd.Series(parags_sentiment_norm_ls)).reshape(-1, 1))\n",
        "  corpus_parags_df[col_lnorm_stdscaler]  = mean_std_scaler.fit_transform(np.array(corpus_parags_df[model_base]).reshape(-1, 1))\n",
        "  corpus_parags_df[col_lnorm_medianiqr]  = median_iqr_scaler.fit_transform(np.array(pd.Series(parags_sentiment_norm_ls)).reshape(-1, 1))\n",
        "\n",
        "  print('Standardizing Sentences')\n",
        "  # Get Sentence Robust Standardization with Standard Scaler and  MedianIQRScaling\n",
        "  corpus_sents_df[col_stdscaler]  = list2stdscaler(corpus_sents_df[model_base])\n",
        "  corpus_sents_df[col_medianiqr]  = median_iqr_scaler.fit_transform(np.array(corpus_sents_df[model_base]).reshape(-1, 1))\n",
        "  # Normalize the Sentence Sentiment by dividing by Chapter Length\n",
        "  sents_len_ls = list(corpus_sents_df['token_len'])\n",
        "  sents_sentiment_ls = list(corpus_sents_df[model_base])\n",
        "  sents_sentiment_norm_ls = [sents_sentiment_ls[i]/sents_len_ls[i] for i in range(len(sents_len_ls))]\n",
        "  # RobustStandardize Sentence sentiment values\n",
        "  # corpus_sents_df[col_lnorm_meanstd]  = mean_std_scaler.fit_transform(np.array(pd.Series(sents_sentiment_norm_ls)).reshape(-1, 1))\n",
        "  # corpus_sents_df[col_lnorm_meanstd]  = mean_std_scaler.fit_transform(np.array(pd.Series(sents_sentiment_norm_ls)).reshape(-1, 1))\n",
        "  corpus_sents_df[col_lnorm_stdscaler]  = mean_std_scaler.fit_transform(np.array(corpus_sents_df[model_base]).reshape(-1, 1))\n",
        "  corpus_sents_df[col_lnorm_medianiqr]  = median_iqr_scaler.fit_transform(np.array(pd.Series(sents_sentiment_norm_ls)).reshape(-1, 1))\n",
        "\n",
        "  return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJNepWBIkVjm"
      },
      "source": [
        "# Read in lexicon at given path into Dict[word]=polarity\n",
        "\n",
        "def get_lexicon(lexicon_name, lexicon_format=2):\n",
        "    \"\"\"\n",
        "    Read sentiment lexicon.csv file at lexicon_path\n",
        "    into appropriate Dict[word]=polarity\n",
        "\n",
        "    1. lexicon_dt[word] = <polarity value>\n",
        "\n",
        "    Args:\n",
        "        sa_lib (str, optional): [description]. Defaults to 'syuzhet'.\n",
        "    \"\"\"\n",
        "    \n",
        "    # global lexicon_df\n",
        "\n",
        "    lexicon_df = pd.DataFrame()\n",
        "    \n",
        "    # print(os.getcwd())\n",
        "\n",
        "    \n",
        "    try:\n",
        "      lexicon_df = pd.read_csv(lexicon_name)\n",
        "      lexicon_df.info()\n",
        "      # lexicon_df = lexicon_tmp_df.copy()\n",
        "      # print(lexicon_df.head())\n",
        "      return lexicon_df\n",
        "    except:\n",
        "      print(f'ERROR: Cannot read lexicon.csv at {lexicon_name}')\n",
        "      return -1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWdzLF0jwI-u"
      },
      "source": [
        "# Sentence to Sentiment Polarity according to passed in Lexicon Dictionary\n",
        "\n",
        "def text2sentiment(text_str, lexicon_dt):\n",
        "  '''\n",
        "  Given a text_str and lexicon_dt, calculate \n",
        "  the sentimety polarity.\n",
        "  '''\n",
        "\n",
        "  # Remove all not alphanumeric and whitespace characters\n",
        "  text_str = re.sub(r'[^\\w\\s]', '', text_str) \n",
        "\n",
        "  text_str = text_str.strip().lower()\n",
        "  if (len(text_str) < 1):\n",
        "      print(f\"ERROR: text2sentiment() given empty/null/invalid string: {text_str}\")\n",
        "\n",
        "  text_ls = text_str.split()\n",
        "  # print(f'text_ls: {text_ls}')\n",
        "\n",
        "  # Accumulated Total Sentiment Polarity for entire Sentence\n",
        "  text_sa_tot = 0.0\n",
        "\n",
        "  for aword in text_ls:\n",
        "      # print(f'getting sa for word: {aword}')\n",
        "      try:\n",
        "          word_sa_fl = float(lexicon_dt[aword])\n",
        "          text_sa_tot += word_sa_fl\n",
        "          # print(f\">>{aword} has a sentiment value of {word_sa_fl}\")\n",
        "      except TypeError: # KeyError:\n",
        "          # aword is not in lexicon so it adds 0 to the sentence sa sum\n",
        "          # print(f\"TypeError: cannot convert {lexicon_dt[aword]} to float\")\n",
        "          continue\n",
        "      except KeyError:\n",
        "          # print(f\"KeyError: missing key {aword} in defaultdict syuzhet_dt\")\n",
        "          continue\n",
        "      except:\n",
        "          e = sys.exc_info()[0]\n",
        "          # print(f\"ERROR {e}: sent2lex_sa() cannot catch aword indexing into syuzhet_dt error\")\n",
        "  \n",
        "  # print(f\"Leaving sent2lex_sa() with sentence sa value = {str(text_sa_tot)}\")\n",
        "  \n",
        "  return text_sa_tot\n",
        "\n",
        "\n",
        "# Test\n",
        "\n",
        "# sent2sentiment('I hate and despise and abhor and dislike and am disgusted by Mondays.', lexicon_jockersrinker_dt)\n",
        "# sent2sentiment('hate Mondays.', lexicon_jockersrinker_dt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6AEBZzvEz4a"
      },
      "source": [
        "def plot_smas(section_view=True, model_name='vader', text_unit='sentence', wins_ls=[20], alpha=0.5, subtitle_str='', y_height=0, save2file=False):\n",
        "  '''\n",
        "  Given a model, text_unit\n",
        "  Plot a SMA using default values and wrapping the function get_smas()\n",
        "  '''\n",
        "\n",
        "  if (section_view == True) and not any(x == text_unit for x in ['sentence', 'paragraph']):\n",
        "    print(f'ERROR: You can only plot SMA within a Section with Sentence or Paragraph text units')\n",
        "    return -99\n",
        "\n",
        "  if text_unit == 'sentence':\n",
        "    if section_view == False:\n",
        "      ts_df = corpus_sents_df\n",
        "    else:\n",
        "      ts_df = section_sents_df\n",
        "    wins_ls = [5,10,20]\n",
        "  elif text_unit == 'paragraph':\n",
        "    if section_view == False:\n",
        "      ts_df = corpus_parags_df\n",
        "    else:\n",
        "      ts_df = section_parags_df\n",
        "    wins_ls = [5,10,20]\n",
        "  elif text_unit == 'section':\n",
        "    ts_df = corpus_sects_df\n",
        "    wins_ls=[20]\n",
        "  else:\n",
        "    print(f'ERROR: {text_unit} must be sentence, paragraph or section')\n",
        "\n",
        "  sectno_loc = ts_df[model_name].min()\n",
        "\n",
        "  if section_view ==False:\n",
        "    # At Section boundries draw blue vertical lines \n",
        "    section_boundries_ls = list(corpus_sects_df['sent_no_start'])\n",
        "    for i, sent_no in enumerate(section_boundries_ls):\n",
        "      plt.text(sent_no, y_height, f'Sec#{i}', alpha=0.2, rotation=90)\n",
        "      plt.axvline(sent_no, color='blue', alpha=0.1)\n",
        "      # 'BigNews1', xy=(sent_no, 0.5), xytext=(-10, 25), textcoords='offset points',                   rotation=90, va='bottom', ha='center', annotation_clip=True)\n",
        "\n",
        "      # plt.text(sent_no, -.5, 'goodbye',rotation=90, zorder=0)\n",
        "\n",
        "    # At Chapter boundaries draw red vertical lines\n",
        "    chapter_boundries_ls = list(corpus_chaps_df['sent_no_start'])\n",
        "    for i, sent_no in enumerate(chapter_boundries_ls):\n",
        "      plt.axvline(sent_no, color='navy', alpha=0.1)\n",
        "      # plt.text(sent_no, .5, 'hello', rotation=90, zorder=0)\n",
        "\n",
        "  get_smas(ts_df, model_name=model_name, text_unit=text_unit, wins_ls=wins_ls, alpha=alpha, subtitle_str=subtitle_str, save2file=save2file)\n",
        "\n",
        "  if (save2file == True):\n",
        "    # Save graph to file.\n",
        "    plot_filename = f'plot_sma_sents_{model_name}.png'\n",
        "    plotpathfilename_str = gen_pathfiletime(plot_filename)\n",
        "    plt.savefig(plotpathfilename_str, format='png', dpi=300)\n",
        "    print(f'Plot saved: {plot_filename}');\n",
        "\n",
        "  return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcAMyjyn8ugj"
      },
      "source": [
        "# SMA 5% Sentiment of Sentence Sentiment\n",
        "\n",
        "def get_smas(ts_df, model_name, text_unit='sentence', wins_ls=[5,10], alpha=0.5, scale_factor=1., subtitle_str='', mean_adj=0., do_plot=True, save2file=False):\n",
        "  '''\n",
        "  Given a model_name and time series DataFrame and list of win_rolls in percentages\n",
        "  Return the rolling means of the time series using the window sizes in win_rolls\n",
        "  '''\n",
        "\n",
        "  temp_roll_df = pd.DataFrame() # TODO: save sma rolling values into temp_df and return this value\n",
        "\n",
        "  win_1per = int(ts_df.shape[0]*0.01)\n",
        "  if text_unit ==  'sentence':\n",
        "    # win_1per = win_s1per\n",
        "    x_idx = 'sent_no'\n",
        "    fname_abbr = 'sents'\n",
        "  elif text_unit == 'paragraph':\n",
        "    # win_1per = win_p1per\n",
        "    x_idx = 'parag_no'\n",
        "    fname_abbr = 'parags'\n",
        "  elif text_unit == 'section':\n",
        "    win_1per = 1\n",
        "    wins_ls = [int(0.1 * corpus_sects_df.shape[0])]  # Edge case to deal with very few Section data points\n",
        "    x_idx = 'sect_no'\n",
        "    fname_abbr = 'sects'\n",
        "  else:\n",
        "    print(f'ERROR: text_unit={text_unit} but must be either sentence, paragraph or section')\n",
        "  \n",
        "  for i, awin_size in enumerate(wins_ls):\n",
        "    if len(str(awin_size)) == 1:\n",
        "      awin_str = '0' + str(awin_size)\n",
        "    else:\n",
        "      awin_str = str(awin_size) \n",
        "    col_roll_str = f'{model_name}_mean_roll{awin_str}'\n",
        "    win_size = awin_size*win_1per\n",
        "    ts_df[col_roll_str] = ts_df[model_name].rolling(window=win_size, center=True).mean()\n",
        "  \n",
        "    if do_plot == True:\n",
        "      alabel = f'{model_name} (win={awin_size})'\n",
        "      ts_df['y_scaled'] = ts_df[col_roll_str]*scale_factor + mean_adj \n",
        "      sns.lineplot(data=ts_df, x=x_idx, y='y_scaled', legend='brief', label=alabel, alpha=alpha)\n",
        "      \n",
        "  plt.title(f'{CORPUS_FULL} (Model: {model_name}: {subtitle_str}) \\nSMA Smoothed {text_unit} Sentiment Plot (windows={wins_ls})')\n",
        "  # plt.legend(loc='best')\n",
        "\n",
        "  if save2file == True:\n",
        "    # Save graph to file.\n",
        "    plot_filename = f'plot_{fname_abbr}_sa_mean_050100sma.png'\n",
        "    plotpathfilename_str = gen_pathfiletime(plot_filename)\n",
        "    plt.savefig(plotpathfilename_str, format='png', dpi=300)\n",
        "    print(f'Plot saved: {plot_filename}');\n",
        "\n",
        "  return temp_roll_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULzfHeDK8udN"
      },
      "source": [
        "def get_lexstats(ts_df, model_name, text_unit='sentence'):\n",
        "  '''\n",
        "  Given a model name\n",
        "  calculate, store and return time series stats\n",
        "  '''\n",
        "  \n",
        "  global corpus_lexicons_stats_dt\n",
        "\n",
        "  temp_dt = {}\n",
        "  \n",
        "  if text_unit == 'sentence':\n",
        "    stat_idx = f'{model_name}_sents'\n",
        "  elif text_unit == 'paragraph':\n",
        "    stat_idx = f'{model_name}_parags'\n",
        "  elif text_unit == 'section':\n",
        "    stat_idx = f'{model_name}_sects'\n",
        "  elif text_unit == 'chapter':\n",
        "    stat_idx = f'{model_name}_chaps'\n",
        "  else:\n",
        "    print(f'ERROR: {text_unit} must either be sentence, paragraph, or section')\n",
        "\n",
        "  sentiment_min = ts_df[model_name].min()\n",
        "  sentiment_max = ts_df[model_name].max()\n",
        "\n",
        "  temp_dt = {'sentiment_min' : sentiment_min,\n",
        "             'sentiment_max' : sentiment_max}\n",
        "\n",
        "  corpus_lexicons_stats_dt[stat_idx] = temp_dt\n",
        "                                     \n",
        "  return \n",
        "\n",
        "# Test\n",
        "# get_lexstats('afinn')\n",
        "# corpus_lexicons_stats_dt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltdJn-7ePNM9"
      },
      "source": [
        "def lex_discrete2continous_sentiment(text, lexicon):\n",
        "  '''\n",
        "  Given a plain text string, give it to\n",
        "    Stanford Stanza (OpenNLP) to calculate sentiment for each word on a 3 point scale 0-2\n",
        "  Return a sentiment value for the entire sentence (sum of word sentiments/log(len of sentence)) \n",
        "    that approximates a normal distribution for all values\n",
        "    In order to get more fine grained measure of overall Sentence sentiment\n",
        "    Sentiment values will be Normalized/Standardized so absolute precision is not required\n",
        "  '''\n",
        "  text_sentiment_tot = 0.\n",
        "  text_ls = text.split()\n",
        "  text_len = len(text_ls)\n",
        "  for aword in text_ls:\n",
        "    word_sentiment = text2sentiment(str(aword), lexicon)\n",
        "    text_sentiment_tot += word_sentiment\n",
        "  text_sentiment_norm = text_sentiment_tot/(np.log(text_len)+0.01)\n",
        "\n",
        "  return text_sentiment_norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6xMI98l8uaH"
      },
      "source": [
        "\"\"\"\n",
        "def clip_outliers(floats_ser):\n",
        "  '''\n",
        "  Given a pd.Series of float values\n",
        "  Return a list with outliers removed, values limited within 3 median absolute deviations from median\n",
        "  '''\n",
        "  # https://www.statsmodels.org/stable/generated/statsmodels.robust.scale.mad.html#statsmodels.robust.scale.mad\n",
        "\n",
        "  # Old mean/std, less robust\n",
        "  # ser_std = floats_ser.std()\n",
        "  # ser_median = floats_ser.mean() # TODO: more robust: asym/outliers -> median/IQR or median/median abs deviation\n",
        "\n",
        "  floats_np = np.array(floats_ser)\n",
        "  ser_median = floats_ser.median()\n",
        "  ser_mad = robust.mad(floats_np)\n",
        "  print(f'ser_median = {ser_median}')\n",
        "  print(f'ser_mad = {ser_mad}')\n",
        "\n",
        "  if ser_mad == 0:\n",
        "    # for TS with small ranges (e.g. -1.0 to +1.0) Median Abs Deviation = 0\n",
        "    #   so pass back the original time series\n",
        "    floats_clip_ls = list(floats_ser)\n",
        "\n",
        "  else:\n",
        "    ser_oldmax = floats_ser.max()\n",
        "    ser_oldmin = floats_ser.min()\n",
        "    print(f'ser_max = {ser_oldmax}')\n",
        "    print(f'ser_min = {ser_oldmin}')\n",
        "\n",
        "    ser_upperlim = ser_median + 2.5*ser_mad\n",
        "    ser_lowerlim = ser_median - 2.5*ser_mad\n",
        "    print(f'ser_upperlim = {ser_upperlim}')\n",
        "    print(f'ser_lowerlim = {ser_lowerlim}')\n",
        "\n",
        "    # Clip outliers to max or min values\n",
        "    floats_clip_ls = np.clip(floats_np, ser_lowerlim, ser_upperlim)\n",
        "    # print(f'max floast_ls {floats_ls.max()}')\n",
        "\n",
        "    # def map2range(value, low, high, new_low, new_high):\n",
        "    #   '''map a value from one range to another'''\n",
        "    #   return value * 1.0 / (high - low + 1) * (new_high - new_low + 1)\n",
        "\n",
        "    # Map all float values to range [-1.0 to 1.0]\n",
        "    # floats_clip_sig_ls = [map2range(i, ser_oldmin, ser_oldmax, ser_upperlim, ser_lowerlim) for i in floats_clip_ls]\n",
        "\n",
        "    # listmax_fl = float(max(floats_ls))\n",
        "    # floats_ls = [i/listmax_fl for i in floats_ls]\n",
        "    #floats_ls = [1/(1+math.exp(-i)) for i in floats_ls]\n",
        "\n",
        "  return floats_clip_ls  # floats_clip_sig_ls\n",
        "\"\"\";\n",
        "\n",
        "# Test\n",
        "# Will not work on first run as corpus_sents_df is not defined yet\n",
        "'''\n",
        "data = np.array([1, 4, 4, 7, 12, 13, 16, 19, 22, 24])\n",
        "test_ls = clip_outliers(corpus_sents_df['vader'])\n",
        "print(f'new min is {min(test_ls)}')\n",
        "print(f'new max is {max(test_ls)}')\n",
        "''';"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXwKR4gA8Ouk"
      },
      "source": [
        "## **Pandas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8Hf8nU98uXI"
      },
      "source": [
        "\"\"\"\n",
        "def rename_cols(ts_df, col_old_ls, suffix_str='_raw'):\n",
        "  '''\n",
        "  Given a DataFrame, list of columns in DataFrame and a suffix,\n",
        "  Return a Dictionary mapping old col names to new col name (orig+suffix)\n",
        "  '''\n",
        "\n",
        "  col_new_ls = []\n",
        "  for acol in col_old_ls:\n",
        "    acol_new = acol + suffix_str\n",
        "    col_new_ls.append(acol_new)\n",
        "\n",
        "  # Create dict for col mapping: keys=old col names, value=new col names\n",
        "  col_rename_dt = dict(zip(col_old_ls, col_new_ls))\n",
        "\n",
        "  # ts_df.rename(columns=col_rename_dt, errors=\"raise\")\n",
        "\n",
        "  return col_rename_dt\n",
        "\n",
        "# test_ls = [col for col in corpus_sents_df.columns if not(renaming_fun(col) is None)]\n",
        "# print(f'test_ls: {test_ls}')\n",
        "\n",
        "# Test\n",
        "# col_rename_dt = rename_cols(corpus_sents_df, sentiment_only_cols_ls)\n",
        "# col_rename_dt\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YJJcvDVnUuT"
      },
      "source": [
        "## **Time Series**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIo6-zGKnZps"
      },
      "source": [
        "\"\"\"\n",
        "def norm2negpos1(data_ser):\n",
        "  '''\n",
        "  Given a series of floating number\n",
        "  Return a a list of same values normed between -1.0 and +1.0\n",
        "  '''\n",
        "  # data_np = np.matrix(data_ser)\n",
        "\n",
        "  scaler=MinMaxScaler(feature_range=(-1.0, 1.0))\n",
        "  temp_ser = scaler.fit_transform(np.matrix(data_ser))\n",
        "  \n",
        "  return temp_ser\n",
        "\"\"\";\n",
        "\n",
        "# Test\n",
        "'''\n",
        "temp_np = norm2negpos1(corpus_all_df[['xlnet_sst5']])\n",
        "print(type(temp_np))\n",
        "temp_np.shape\n",
        "''';"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpVHeYKYnUhU"
      },
      "source": [
        "\"\"\"\n",
        "def standardize_ts(data_ser):\n",
        "  '''\n",
        "  Given a series of floating number\n",
        "  Return a a list of same values normed between -1.0 and +1.0\n",
        "  '''\n",
        "  # data_np = np.matrix(data_ser)\n",
        "\n",
        "  std_scaler = StandardScaler()\n",
        "  df_std = std_scaler.fit_transform(np.array(data_ser))\n",
        "  \n",
        "  return df_std\n",
        "\"\"\";\n",
        "\n",
        "# Test\n",
        "'''\n",
        "temp_np = norm2negpos1(corpus_all_df[['xlnet_sst5']])\n",
        "print(type(temp_np))\n",
        "temp_np.shape\n",
        "temp_np\n",
        "''';"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ylt_kLuEFDrj"
      },
      "source": [
        "# This must be defined AFTER the corpus_sects_df DataFrame is created in the Preprocessing Step below\n",
        "# Raw Plot of Section Sentiments (Adjusted for (x-axis) mid-Section Sentence No and (y-axis) Sentiment weighted by Section length )\n",
        "# corpus_sects_df = pd.DataFrame()  # Create empty early as required by some utility functions\n",
        "\n",
        "def plot_crux_sections(model_names_ls, semantic_type='section', subtitle_str='', label_token_ct=0, title_xpos = 0.8, title_ypos=0.2, sec_y_height=0, save2file=False):\n",
        "  '''\n",
        "  Given a Sections DataFrame, model_name and semantic type,\n",
        "  Return a Plot of the Cruxes\n",
        "  '''\n",
        "\n",
        "  crux_points_dt = {}\n",
        "  model_stand_names_ls = []\n",
        "  section_boundries_ls = []\n",
        "\n",
        "\n",
        "  # print(f'Using model_names: {model_names_ls}')\n",
        "\n",
        "  # sns.lineplot(data=ts_df, x='sent_no_mid', y=amodel_stand, markers=['o'], alpha=0.5, label=amodel_stand); # .set_title(f'{CORPUS_FULL} \\n Plot Section Sentiment (Bing Lexicon)')\n",
        "\n",
        "\n",
        "  # At Section boundries draw blue vertical lines \n",
        "  section_boundries_ls = list(corpus_sects_df['sent_no_start'])\n",
        "  for i, sent_no in enumerate(section_boundries_ls):\n",
        "    plt.text(sent_no, sec_y_height, f'Sec#{i}', alpha=0.2, rotation=90)\n",
        "    plt.axvline(sent_no, color='blue', alpha=0.1);\n",
        "\n",
        "  # At Chapter boundaries draw red vertical lines\n",
        "  chapter_boundries_ls = list(corpus_chaps_df['sent_no_start'])\n",
        "  for i, sent_no in enumerate(chapter_boundries_ls):\n",
        "    plt.axvline(sent_no, color='navy', alpha=0.1);\n",
        "\n",
        "  # Error check and assign DataFrame associated with each semantic_type\n",
        "  if semantic_type == 'section':\n",
        "    # Get midpoints of each Section\n",
        "    ts_df=corpus_sects_df\n",
        "    midpoints_ls = list(corpus_sects_df['sent_no_mid'])\n",
        "  elif semantic_type == 'chapter':\n",
        "    # Get midpoints of each Chapter\n",
        "    ts_df=corpus_chaps_df\n",
        "    midpoints_ls = list(corpus_chaps_df['sent_no_mid'])\n",
        "  else:\n",
        "    print(f\"ERROR: semantic_type={semantic_type} must be either 'section' or 'chapter'\")\n",
        "    return -1\n",
        "\n",
        "  # How many sentiment time series are we plotting?\n",
        "  if len(model_names_ls) == 1:\n",
        "    \n",
        "    # Plotting only one model\n",
        "    model_name_full = str(model_names_ls[0])\n",
        "    model_name_root = model_name_full.split('_')[0]\n",
        "    print(f'model_name_full: {model_name_full} and model_name_root: {model_name_root}')\n",
        "    if model_name_root in MODELS_LS:\n",
        "      # Plot\n",
        "      print(f'about to sns.lineplot model: ') # {ts_df}')\n",
        "      g = sns.lineplot(data=ts_df, x='sent_no_mid', y=model_name_full, markers=['o'], alpha=0.5, label=model_name_full) # .set_title(f'{CORPUS_FULL} \\n Plot Section Sentiment and Cruxes (Model: {models_names_ls[0].capitalize()})')\n",
        "      # g._legend.remove()\n",
        "      # print(f'model_name_full={model_name_full}')\n",
        "      # plt.plot(ts_df.sent_no_mid, ts_df[model_name_full], markers=\"o\", alpha=0.5, label=model_name_full)\n",
        "    else:\n",
        "      print(f'ERROR: model_names_ls[0]={model_name_root} is invalid,\\n    must be one of {MODELS_LS}')\n",
        "      return -1\n",
        "\n",
        "    # If plotting only one model, add labels\n",
        "    midpoints_sentiment_ls = list(ts_df[model_name_full])\n",
        "    sect_ct = 0\n",
        "    for x,y in zip(midpoints_ls, midpoints_sentiment_ls): \n",
        "      label_token_int = int(label_token_ct)\n",
        "      if label_token_int < 0:\n",
        "        label = ''\n",
        "      elif label_token_int == 0:\n",
        "        # if arg label_token_ct == 0, just print sent_no\n",
        "        label = f\"#{x}({sect_ct})\"\n",
        "      else:\n",
        "        # if arg label_token_ct > 0, print the first label_token_ct words of sentence at crux point\n",
        "        label = f\"#{x}({sect_ct}) {' '.join(corpus_sents_df.iloc[x-1]['sent_raw'].split()[:label_token_int])}\"; # \\nPolarity: {y:.2f}'\n",
        "\n",
        "      # Save Crux point in crux_points_dt Dictionary if plotting Cruxes for a single/specific Model\n",
        "      crux_full_str = ' '.join(corpus_sents_df.iloc[x]['sent_raw'].split())\n",
        "      crux_points_dt[x] = [y, crux_full_str]\n",
        "\n",
        "      plt.annotate(label,\n",
        "                   (x,y),\n",
        "                   textcoords='offset points',\n",
        "                   xytext=(0,10),\n",
        "                   ha='center',\n",
        "                   rotation=90)\n",
        "      sect_ct += 1\n",
        "\n",
        "    plt.title(f'{CORPUS_FULL} \\n Plot {semantic_type.capitalize()} Sentiment ({model_name_full.capitalize()})\\n{subtitle_str}', x=title_xpos, y=title_ypos);\n",
        "    # Plot\n",
        "    plt.plot(midpoints_ls, midpoints_sentiment_ls, marker=\"o\", ms=6) # , markevery=[0,1])\n",
        "\n",
        "  else:\n",
        "    # If plotting multiple models\n",
        "    model_names_str = 'Multiple Models'\n",
        "    for i, model_name_full in enumerate(model_names_ls):\n",
        "      # Error check and assign correct model names\n",
        "      model_name_root = model_name_full.split('_')[0]\n",
        "      if model_name_root in MODELS_LS:\n",
        "        # Plot\n",
        "        g = sns.lineplot(data=ts_df, x='sent_no_mid', y=model_name_full, markers=['o'], alpha=0.5, label=model_name_full) # .set_title(f'{CORPUS_FULL} \\n Plot Section Sentiment and Cruxes (Model: {models_names_ls[0].capitalize()})')\n",
        "        # g._legend.remove()\n",
        "        # plt.plot(ts_df.sent_no_mid, ts_df[model_name_full], marker=\"o\", alpha=0.5, label=model_name_full)\n",
        "      else:\n",
        "        print(f'ERROR: model_names_ls[]={model_name_root} is invalid,\\n    must be one of {MODELS_LS}')\n",
        "        return -1\n",
        "\n",
        "      # Plot\n",
        "      g = sns.lineplot(data=ts_df, x='sent_no_mid', y=model_name_full, markers=['o'], alpha=0.5, label=model_name_full) # .set_title(f'{CORPUS_FULL} \\n Plot Section Sentiment and Cruxes (Model: {models_names_ls[0].capitalize()})')\n",
        "      # g._legend.remove()\n",
        "\n",
        "    plt.title(f'{CORPUS_FULL} \\n Plot {semantic_type.capitalize()} Sentiment (Standardized Models)\\n{subtitle_str}', x=title_xpos, y=title_ypos)\n",
        "\n",
        "  # plt.legend(loc='best');\n",
        "\n",
        "  if (save2file == True):\n",
        "    # Save graph to file.\n",
        "    models_names_ls = [x[:2] for x in model_names_ls]\n",
        "    models_names_str = ''.join(models_names_ls)\n",
        "    plot_filename = f'plot_cruxes_{semantic_type}_{models_names_str}_{models_names_str}.png'\n",
        "    plotpathfilename_str = gen_pathfiletime(plot_filename)\n",
        "    plt.savefig(plotpathfilename_str, format='png', dpi=300)\n",
        "    print(f'Plot saved: {plot_filename}');\n",
        "\n",
        "  return crux_points_dt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUNMIlJKHyz3"
      },
      "source": [
        "def plot_histogram(model_name='vader', text_unit='sentence', save2file=False):\n",
        "  '''\n",
        "  Given a model, text_unit\n",
        "  Plot a Histogram using the default DataFrame\n",
        "  '''\n",
        "\n",
        "  if text_unit == 'sentence':\n",
        "    ts_df = corpus_sents_df\n",
        "\n",
        "  elif text_unit == 'paragraph':\n",
        "    ts_df = corpus_parags_df\n",
        "\n",
        "  elif text_unit == 'section':\n",
        "    ts_df = corpus_sects_df\n",
        "\n",
        "  elif text_unit == 'chapter':\n",
        "    ts_df = corpus_chaps_df\n",
        "\n",
        "  else:\n",
        "    print(f'ERROR: {text_unit} must be sentence, paragraph or section')\n",
        "\n",
        "  sns.histplot(ts_df[model_name], kde=True).set_title(f'{CORPUS_FULL} \\n Histogram {text_unit.capitalize()} Sentiment (Model {model_name.capitalize()})')\n",
        "  # get_smas(ts_df, model_name=model_name, text_unit=text_unit, win_ls=wins_def_ls)\n",
        "\n",
        "  if (save2file == True):\n",
        "    # Save graph to file.\n",
        "    plot_filename = f'plot_hist_{text_unit}_{model_name}.png'\n",
        "    plotpathfilename_str = gen_pathfiletime(plot_filename)\n",
        "    plt.savefig(plotpathfilename_str, format='png', dpi=300)\n",
        "    print(f'Plot saved: {plot_filename}');\n",
        "\n",
        "  return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGTkfsSWFCeO"
      },
      "source": [
        "# Raw Plot of Section Sentiments (Not scaled by mid-Section Sentence No to match Sentence/Paragraph x-axes)\n",
        "\n",
        "def plot_raw_sections(ts_df='corpus_sents_df', model_name='vader', semantic_type='sentence', save2file=False):\n",
        "  '''\n",
        "  Given a DataFrame, model_name column, semantic_type \n",
        "  Plot the raw sentiment types\n",
        "  Options to save2file\n",
        "  ''' \n",
        "  \n",
        "  # if (PLOT_OUTPUT == 'All') | (PLOT_OUTPUT == 'Major'):\n",
        "  sns.lineplot(data=ts_df, x='sect_no', y=model_name, alpha=0.5).set_title(f'{CORPUS_FULL} \\n Plot {semantic_type} Sentiment (Raw {model_name.capitalize()})')\n",
        "\n",
        "  if save2file == True:\n",
        "    # Save graph to file.\n",
        "    plot_filename = f'plot_nostand_sects_{model_name}.png'\n",
        "    plotpathfilename_str = gen_pathfiletime(plot_filename)\n",
        "    plt.savefig(plotpathfilename_str, format='png', dpi=300)\n",
        "    print(f'Plot saved: {plot_filename}');\n",
        "\n",
        "  return\n",
        "\n",
        "# Test\n",
        "# plot_raw_sections(ts_df=corpus_sects_df, model_name='pattern', semantic_type='section', save2file=False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmrtifYoIjOT"
      },
      "source": [
        "# Raw Plot of Section Sentiments (Not scaled by mid-Section Sentence No to match Sentence/Paragraph x-axes)\n",
        "\n",
        "def plot_raw_sentiments(model_name='vader', semantic_type='sentence', save2file=False):\n",
        "  '''\n",
        "  Given a DataFrame, model_name column, semantic_type \n",
        "  Plot the raw sentiment types\n",
        "  Options to save2file\n",
        "  ''' \n",
        "  \n",
        "  if semantic_type == 'sentence':\n",
        "    ts_df = corpus_sents_df\n",
        "    x_units = 'sent_no'\n",
        "  elif semantic_type == 'paragraph':\n",
        "    ts_df = corpus_parags_df\n",
        "    x_units = 'parag_no'\n",
        "  elif (semantic_type == 'section') | (semantic_type == 'section_stand'):\n",
        "    ts_df = corpus_sects_df\n",
        "    x_units = 'sect_no'\n",
        "  elif (semantic_type == 'chapter') | (semantic_type == 'chapter_stand'):\n",
        "    ts_df = corpus_chaps_df\n",
        "    x_units = 'chap_no'\n",
        "    \n",
        "  else:\n",
        "    print(f'ERROR: {semantic_type} must be sentence, paragraph or section')\n",
        "\n",
        "\n",
        "  # if (PLOT_OUTPUT == 'All') | (PLOT_OUTPUT == 'Major'):\n",
        "  sns.lineplot(data=ts_df, x=x_units, y=model_name, alpha=0.5, label=model_name).set_title(f'{CORPUS_FULL} \\n Plot {semantic_type} Sentiment (Raw {model_name.capitalize()})')\n",
        "  \n",
        "  plt.legend(loc='best')\n",
        "\n",
        "  if save2file == True:\n",
        "    # Save graph to file.\n",
        "    plot_filename = f'plot_raw_sentiments_{semantic_type}_{model_name}.png'\n",
        "    plotpathfilename_str = gen_pathfiletime(plot_filename)\n",
        "    plt.savefig(plotpathfilename_str, format='png', dpi=300)\n",
        "    print(f'Plot saved: {plot_filename}');\n",
        "\n",
        "  return\n",
        "\n",
        "# Test\n",
        "# plot_raw_sections(ts_df=corpus_sects_df, model_name='pattern', semantic_type='section', save2file=False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB8ibstaeiVd"
      },
      "source": [
        "# TODO: must plot in order to save, cannot save without first plotting\n",
        "\n",
        "def get_lowess(ts_df='corpus_parags_df', models_ls=MODELS_LS, text_unit='paragraph', plot_subtitle='', alabel='', afrac=1./10, ait=5, alpha=0.5, do_plot=True, save2file=False):\n",
        "  '''\n",
        "  Given a DataFrame, list of column to plot, LOWESS params fraction and iterations,\n",
        "  Return a DataFrame with LOWESS values\n",
        "  If 'plot=True', also output plot\n",
        "  '''\n",
        "\n",
        "  # global corpus_all_df\n",
        "\n",
        "  lowess_df = pd.DataFrame()\n",
        "\n",
        "  # Step 1: Calculate LOWESS smoothed values\n",
        "  for i,acol in enumerate(models_ls):\n",
        "    sm_x, sm_y = sm_lowess(endog=ts_df[acol].values, exog=ts_df.index.values, frac=afrac, it=ait, return_sorted = True).T\n",
        "    col_new = f'{acol}_lowess'\n",
        "    lowess_df[col_new] = pd.Series(sm_y)\n",
        "    # Optionally plot LOWESS for all models\n",
        "    if do_plot:\n",
        "      if alabel == '':\n",
        "        alabel == acol\n",
        "      plt.plot(sm_x, sm_y, label=alabel, alpha=alpha, linewidth=2)\n",
        "\n",
        "  lowess_df['median'] = lowess_df.median(axis=1) # sm_y # corpus_all_df[df_cols_ls].median(axis=1)\n",
        "  \n",
        "  # Step 2: Optionally plot LOWESS for median\n",
        "  if do_plot:\n",
        "    # sm_x, sm_y = sm_lowess(endog=lowess_df.median, exog=lowess_df.index.values,  frac=afrac, it=ait, return_sorted = True).T\n",
        "    # plt.plot(sm_x, sm_y, label='median', alpha=0.9, linewidth=2, color='black')\n",
        "    \n",
        "    frac_str = str(round(100*afrac))\n",
        "    plt.title(f'{CORPUS_FULL} \\n {plot_subtitle} {text_unit} Standardized Sentiment Smoothed with LOWESS (frac={frac_str})')\n",
        "    plt.legend(title='Sentiment Model')\n",
        "\n",
        "  # Step 3: Optionally save to file\n",
        "  if save2file:\n",
        "    # Save Plot to file.\n",
        "    plot_filename = f'plot_{text_unit}_lowess_{plot_subtitle.split()[0].lower()}_{author_abbr_str}_{title_str}.png'\n",
        "    # plotpathfilename_str = gen_pathfiletime(plot_filename)\n",
        "    plt.savefig(plot_filename, format='png', dpi=300)\n",
        "    print(f'Plot saved: {plot_filename}');\n",
        "\n",
        "\n",
        "  return lowess_df\n",
        "\n",
        "\n",
        "# Test\n",
        "'''\n",
        "new_lowess_col = f'{sa_model}_lowess'\n",
        "my_frac = 1./10\n",
        "my_frac_per = round(100*my_frac)\n",
        "new_lowess_col = f'{sa_model}_lowess_{my_frac_per}'\n",
        "corpus_all_df[new_lowess_col] = plot_lowess(corpus_all_df, [sa_model], afrac=my_frac)\n",
        "corpus_all_df.head()\n",
        "''';"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cANCC2iz6nwo"
      },
      "source": [
        "def get_sent2dets(sent_no):\n",
        "  '''\n",
        "  Given a Sentence Number\n",
        "  Return the corresponding Paragraph, Section and Chapter Numbers that contain it\n",
        "  '''\n",
        "\n",
        "  # Get Paragraph No containing given Sentence No\n",
        "  sent_parag_no = int(corpus_sents_df[corpus_sents_df['sent_no']==sent_no]['parag_no'])\n",
        "\n",
        "  # Get Section No containing given Sentence No.\n",
        "  corpus_sects_ls = list(corpus_sects_df['sect_no'])\n",
        "  for asect_no in corpus_sects_ls:\n",
        "    if (int(corpus_sects_df[corpus_sects_df['sect_no'] == asect_no]['sent_no_start']) > sent_no):\n",
        "      break\n",
        "    sent_sect_no = asect_no\n",
        "    # print(f'asect={asect_no}')\n",
        "\n",
        "  # Get Chapter No containing given Sentence No.\n",
        "  corpus_chaps_ls = list(corpus_chaps_df['chap_no'])\n",
        "  for achap_no in corpus_chaps_ls:\n",
        "    if (int(corpus_chaps_df[corpus_chaps_df['chap_no'] == achap_no]['sent_no_start']) > sent_no):\n",
        "      break\n",
        "    sent_chap_no = achap_no\n",
        "    # print(f'achap={achap_no}')\n",
        "\n",
        "\n",
        "  return sent_parag_no, sent_sect_no, sent_chap_no\n",
        "\n",
        "# Test\n",
        "# sent_parag_no, sent_sect_no, sent_chap_no = get_sent2dets(1408)\n",
        "# print(f'sent_parag_no={sent_parag_no}\\nsent_sect_no={sent_sect_no}\\nsent_chap_no={sent_chap_no}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6liffwhYtSw"
      },
      "source": [
        "# get_sentnocontext_report(the_sent_no=sent_no, the_n_sideparags=n_sideparags, the_sent_highlight=sentence_highlight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sijR4OknJive"
      },
      "source": [
        "def get_sentnocontext(timeser_df, sent_no=1, n_sideparags=1, sent_highlight=True):\n",
        "  '''\n",
        "  Given a sentence number in the Corpus\n",
        "  Return the containing paragraph and n-paragraphs on either side\n",
        "  (e.g. if n=2, return 2+1+2=5 paragraphs)\n",
        "  '''\n",
        "\n",
        "  # print(f'just entered get_sentnocontext withsent_no: {sent_no} and  timeser_df:\\n\\n    {timeser_df}')\n",
        "  timeser_indx = timeser_df['sent_no'] == sent_no\n",
        "  parag_target_no = int(timeser_df[timeser_df['sent_no'] == sent_no]['parag_no'])\n",
        "  # print(f'parag_target_no = {parag_target_no} and type: {type(parag_target_no)}')\n",
        "\n",
        "  if n_sideparags == 0:\n",
        "    parags_context_ls = list(corpus_parags_df[corpus_parags_df['parag_no'] == parag_target_no]['parag_raw'])\n",
        "\n",
        "  else:\n",
        "    parag_start = parag_target_no - n_sideparags\n",
        "    parag_end = parag_target_no + n_sideparags + 1\n",
        "    parags_context_ls = list(corpus_parags_df.iloc[parag_start:parag_end]['parag_raw'])\n",
        "\n",
        "\n",
        "  if sent_highlight == True:\n",
        "    parag_match_str = str(parags_context_ls[n_sideparags])\n",
        "    # print(f'parag_match_str:\\n  {parag_match_str}') parag_no\n",
        "    sent_idx = sent_no\n",
        "    sent_str = (timeser_df[timeser_df['sent_no']==sent_idx]['sent_raw'].values)[0]\n",
        "    sent_str_up = sent_str.upper()\n",
        "    # print(f'sent_str:\\n  {sent_str}')\n",
        "    # parags_context_ls[n_sideparags] \n",
        "    parags_context_ls[n_sideparags] = parag_match_str.replace(sent_str, sent_str_up)\n",
        "\n",
        "  return parags_context_ls\n",
        "\n",
        "# Te\n",
        "# context_highlighted = get_sentnoparags(sent_no=1051, n_sideparags=1)\n",
        "# print(context_highlighted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM_I8uDfJztH"
      },
      "source": [
        "def get_sentnocontext_report(ts_df = corpus_sents_df, the_sent_no=7, the_n_sideparags=1, the_sent_highlight=True):\n",
        "  '''\n",
        "  Wrapper function around  get_sentnocontext()   Paragraph(s) Context\n",
        "  Prints a nicely formatted context report\n",
        "  '''\n",
        "\n",
        "  context_noparags = the_n_sideparags*2+1\n",
        "  # tsdf\n",
        "  # print('-------------------------------------------------------------')\n",
        "  print(f'The {context_noparags} Paragraph(s) Context around the Sentence #{the_sent_no} Crux Point:')\n",
        "  # print(f'ts_df = {ts_df}')\n",
        "  print('-------------------------------------------------------------')\n",
        "  print(f\"\\nCrux Sentence #{the_sent_no} Raw Text: -------------------------------\\n\\n    {str(ts_df[ts_df['sent_no'] == the_sent_no]['sent_raw'].values[0])}\\n\") # iloc[the_sent_no]['sent_raw']}\")\n",
        "\n",
        "  sent_parag_no, sent_sect_no, sent_chap_no = get_sent2dets(the_sent_no)\n",
        "  print(f\"\\nCrux Sentence #{the_sent_no} is Contained in: ---------------------------\\n\\n    Paragraph #{sent_parag_no}\\n      Section #{sent_sect_no}\\n      Chapter #{sent_chap_no}\\n\")\n",
        "\n",
        "  print(f\"\\n{context_noparags} Paragraph(s) Context: ------------------------------\")\n",
        "  # print('calling get_sentnocontext')\n",
        "  context_parags_ls = get_sentnocontext(timeser_df = ts_df, sent_no=the_sent_no, n_sideparags=the_n_sideparags, sent_highlight=the_sent_highlight)\n",
        "  context_len = len(context_parags_ls)\n",
        "  context_mid = context_len//2\n",
        "  for i, aparag in enumerate(context_parags_ls):\n",
        "    if i==context_mid:\n",
        "      # print(f'\\n>>> Paragraph #{i}: <<< Crux Point Sentence CAPITALIZED within this Paragraph\\n\\n    {aparag}') \n",
        "      print(f'\\n<*> {aparag}')\n",
        "    else:\n",
        "      # print(f'\\n    Paragraph #{i}:\\n\\n    {aparag}')\n",
        "      print(f'\\n    {aparag}')\n",
        "\n",
        "  return\n",
        "\n",
        "# Test\n",
        "# get_sentnocontext_report(sent_no=1051, n_sideparags=1, sent_highlight=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y04GiohGypNX"
      },
      "source": [
        "def get_section_timeseries(sect_no):\n",
        "  '''\n",
        "  Given a Section No in the current Corpus\n",
        "  Return the start,mid and ending Sent No for this Section as well as the Sentiment Time Series between the start/end Sentence for this Section\n",
        "  '''\n",
        "  \n",
        "  section_count = corpus_sects_df.shape[0]\n",
        "\n",
        "  # Compute the start, mid and end Sentence numbers for the selected Section\n",
        "  if Select_Section_No >= section_count:\n",
        "    print(f'ERROR: You picked Section #{Select_Section_No}.\\n  Section for this Corpus must be between 0 and {section_count-1}')\n",
        "    return -1\n",
        "\n",
        "  else:\n",
        "\n",
        "    # Get the starting and middle Sentence No of this Section\n",
        "    sect_sent_start = int(corpus_sects_df[corpus_sects_df['sect_no'] == Select_Section_No]['sent_no_start'].values)\n",
        "    # sect_sent_mid = int(corpus_sects_df[corpus_sects_df['sect_no'] == Select_Section_No]['sent_no_mid'].values)\n",
        "\n",
        "    # Calculate last Sentence No of this Section\n",
        "    if Select_Section_No == (section_count-1):   \n",
        "      print(f'You selected the last Section of this Corpus')\n",
        "      sect_sent_end = corpus_sents_df.shape[0] - 1\n",
        "    else:\n",
        "      sect_sent_end = int(corpus_sects_df[corpus_sects_df['sect_no'] == Select_Section_No+1]['sent_no_start'].values) # - 1\n",
        "      \n",
        "    print(f'Section #{sect_no}:----------')\n",
        "    print(f'\\nsect_sent_start: {sect_sent_start}')\n",
        "    # print(f'sect_sent_mid: {sect_sent_mid}')\n",
        "    print(f'sect_sent_end: {sect_sent_end}')\n",
        "\n",
        "\n",
        "  # Comput the start, and end Paragraph numbers for the selected Section\n",
        "  sect_parag_start = int(corpus_sents_df[corpus_sents_df['sent_no'] == sect_sent_start]['parag_no'].values)\n",
        "  sect_parag_end = int(corpus_sents_df[corpus_sents_df['sent_no'] == sect_sent_end]['parag_no'].values)\n",
        "\n",
        "  print(f'\\nsect_parag_start: {sect_parag_start}')\n",
        "  print(f'sect_parag_end: {sect_parag_end}')\n",
        "\n",
        "\n",
        "  # Extract and Return both a Sentence and Paragraph DataFrame for this Section \n",
        "\n",
        "  section_sents_df = corpus_sents_df.iloc[sect_sent_start:sect_sent_end]\n",
        "\n",
        "  section_parags_df = corpus_parags_df.iloc[sect_parag_start:sect_parag_end]\n",
        "\n",
        "\n",
        "  return section_sents_df, section_parags_df\n",
        "\n",
        "# Test\n",
        "\n",
        "# section_sents_df, section_parags_df = get_section_timeseries(Select_Section_No)\n",
        "\n",
        "# section_sents_df.head()\n",
        "\n",
        "# print(f'\\nsection_sents_df.shape: {section_sents_df.shape}')\n",
        "# print(f'section_parags_df.shape: {section_parags_df.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgFMgdQ3X33F"
      },
      "source": [
        "def get_lowess_cruxes(ts_df, col_series, text_type='sentence', win_lowess=5, sec_y_height=0, subtitle_str=' ', do_plot=True, save2file=False):\n",
        "  '''\n",
        "  Given a DataFrame and a Time Series Column within it and a LOWESS window\n",
        "  Return a list of Min/Max Crux Point (x,y) coordinate tuples for that Column Time Series\n",
        "  '''\n",
        "\n",
        "  crux_ls = []\n",
        "\n",
        "  series_len = ts_df.shape[0]\n",
        "\n",
        "  sent_no_min = ts_df.sent_no.min()\n",
        "  sent_no_max = ts_df.sent_no.max()\n",
        "  # print(f'sent_no_min {sent_no_min}')\n",
        "\n",
        "  sm_x = ts_df.index.values\n",
        "  sm_y = ts_df[col_series].values\n",
        "\n",
        "  half_win = int((win_lowess/100)*series_len)\n",
        "\n",
        "  # Find peaks(max).\n",
        "  # peak_indexes = signal.argrelextrema(sm_y, np.greater, order=half_win, mode='wrap') argrelextrema will not detect flat peaks\n",
        "  peak_indexes = signal.find_peaks(sm_y, distance=half_win) # np.greater, order=half_win, mode='wrap')\n",
        "  # peak_indexes = peak_indexes + sent_no_min\n",
        "  # print(f'peak_indexes[0]: {peak_indexes_np[0]}')\n",
        "  # print(f'peak_indexes type: {type(peak_indexes_np[0])}')\n",
        "  # peak_indexes_np = peak_indexes_np + sent_no_min\n",
        "  peak_indexes = peak_indexes[0]\n",
        "\n",
        "  peak_x_ls = list(peak_indexes)\n",
        "  peak_y_ls = list(sm_y[peak_indexes])\n",
        "\n",
        "  # Find valleys(min).\n",
        "  # valley_indexes = signal.argrelextrema(sm_y, np.less, order=half_win, mode='clip')\n",
        "  valley_indexes = signal.find_peaks(-sm_y, distance=half_win)\n",
        "  valley_indexes = valley_indexes[0]\n",
        "  \n",
        "  valley_x_ls = list(valley_indexes)\n",
        "  valley_y_ls = list(sm_y[valley_indexes])\n",
        "\n",
        "  # Save all peaks/valleys as list of (x,y) coordinate tuples\n",
        "  # print(f'type peak_x_ls is: {type(peak_x_ls)}')\n",
        "  x_all_ls = peak_x_ls + valley_x_ls\n",
        "  # readjust starting Sentence No to start with first sentence in segement window\n",
        "  x_all_ls = [x+sent_no_min for x in x_all_ls]\n",
        "  y_all_ls = peak_y_ls + valley_y_ls\n",
        "  crux_coord_ls = tuple(zip(x_all_ls, y_all_ls)) \n",
        "\n",
        "  # print(f'Original Series length={series_len} vs LOWESS Series length={len(x_all_ls)}')\n",
        "\n",
        "\n",
        "  if do_plot == True:\n",
        "    # Plot main graph.\n",
        "    (fig, ax) = plt.subplots()\n",
        "    ax.plot(sm_x, sm_y)\n",
        "\n",
        "    if text_type == 'sentence':\n",
        "      paragraph_boundries_ls = list(section_sents_df['parag_no'].unique())\n",
        "      for i, aparag in enumerate(paragraph_boundries_ls):\n",
        "        if i%5 == 0:\n",
        "          # Plot every 5th paragraph\n",
        "          sent_no = section_sents_df[section_sents_df['parag_no'] == aparag]['sent_no'].min()\n",
        "          plt.text(sent_no, sec_y_height, f'Paragraph #{aparag}', alpha=0.2, rotation=90)\n",
        "          plt.axvline(sent_no, color='blue', alpha=0.1)\n",
        "    elif text_type == 'paragraph':\n",
        "      paragraph_boundries_ls = list(section_sents_df['parag_no'].unique())\n",
        "      for i, aparag_no in enumerate(paragraph_boundries_ls):\n",
        "        if i%5 == 0:\n",
        "          # Plot every 5th paragraph\n",
        "          sent_no = section_sents_df[section_sents_df['parag_no'] == aparag]['sent_no'].min()\n",
        "          plt.text(aparag_no, sec_y_height, f'Paragraph #{aparag_no}', alpha=0.2, rotation=90)\n",
        "          plt.axvline(aparag_no, color='blue', alpha=0.1)    \n",
        "    else:\n",
        "      print(f\"ERROR: text_type is {text_type} but must be either 'sentence' or 'paragarph'\")\n",
        "\n",
        "    win_half = 0 # 2500\n",
        "\n",
        "    # Plot peaks.\n",
        "    # ax.plot(peak_x + win_half, peak_y, marker='o', linestyle='none', color='green', label=\"Peaks\")\n",
        "\n",
        "    # readjust starting Sentence No to start with first sentence in segement window\n",
        "    peak_x_ls = [x+sent_no_min for x in peak_x_ls]\n",
        "    ax.scatter(peak_x_ls, peak_y_ls)\n",
        "    for i, txt in enumerate(list(peak_x_ls)):\n",
        "        ax.annotate(f'  Sent #{txt}', (peak_x_ls[i], peak_y_ls[i]), rotation=90, annotation_clip=True)\n",
        "\n",
        "    # Plot valleys.\n",
        "    # ax.plot(valley_x + win_half, valley_y, marker='o', linestyle='none', color='red', label=\"Valleys\")\n",
        "    # readjust starting Sentence No to start with first sentence in segement window\n",
        "    valley_x_ls = [x+sent_no_min for x in valley_x_ls]\n",
        "    ax.scatter(valley_x_ls, valley_y_ls)\n",
        "    for i, txt in enumerate(list(valley_x_ls)):\n",
        "        ax.annotate(f'Sent #{txt}', (valley_x_ls[i], valley_y_ls[i]), rotation=270, xytext=(valley_x_ls[i], valley_y_ls[i]-4))\n",
        "\n",
        "    # for i, txt in enumerate(list(valley_x_ls)):\n",
        "    #     ax.annotate(f'\\n\\n\\nSent No.\\n   {txt}', (valley_x_ls[i], valley_y_ls[i]))\n",
        "    # plt.plot(x, y, 'bo')\n",
        "    # texts = [plt.text(valley_x_ls[i], valley_y_ls[i], 'Sent No.\\n   %s' %valley_x_ls[i], ha='right', va='top') for i in range(len(valley_x_ls))]\n",
        "    # adjust_text(texts)\n",
        "\n",
        "    # Confidence Interval (Min/Max Range)\n",
        "    # plt.fill_between(sentiment_lowess_df['x_value'], sentiment_lowess_df['min'], sentiment_lowess_df['max'], alpha=.3, color='lightskyblue')\n",
        "\n",
        "    plt.title(f'{CORPUS_FULL} Raw Sentence Crux Detection in Section #{Select_Section_No}\\nLOWESS Smoothed {subtitle_str} and SciPy find_peaks')\n",
        "    plt.xlabel(f'Sentence No within selected Section #{Select_Section_No}')\n",
        "\n",
        "    # locs, labels = xticks()  # Get the current locations and labels.\n",
        "    # plt.xticks(np.arange(sent_no_min, sent_no_max, step=10))  # Set label locations.\n",
        "\n",
        "    plt.ylabel(f'Sentiment Value')\n",
        "    plt.legend(loc='best');\n",
        "  \n",
        "  if save2file == True:\n",
        "    # Save graph to file.\n",
        "    plt.title(f'{BOOK_TITLE_FULL} \\n LOWESS Smoothed Median Sentiment Curve with Crux Points via SciPy.argrelextrema')\n",
        "    plt.legend(loc='best')\n",
        "    plt.savefig('argrelextrema.png')\n",
        "\n",
        "  return crux_coord_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv376c5_bfrg"
      },
      "source": [
        "def crux_sortsents(crux_ls, corpus_df=corpus_sents_df, atop_n=3, get_peaks=True, sort_key='sent_no'):\n",
        "  '''\n",
        "  Given a list of tuples (sent_no, sentiment value), atop_n cruxes to retrieve and bool flag get_peaks\n",
        "  Return a sorted list of peaks/valleys (sentiment_value, sent_no, sent_raw) from greatest down for top_n items\n",
        "  '''\n",
        "  # print(f'Entered crux_sortsents with crux_ls={crux_ls}\\natop_n={atop_n}')\n",
        "\n",
        "  crux_old_ls = []\n",
        "  crux_new_ls = []\n",
        "\n",
        "  # TODO: Error check for null/invalid corpus_df/crus_ls sent_no\n",
        "\n",
        "  if sort_key == 'sent_no':\n",
        "    crux_old_ls = sorted(crux_ls, key=lambda tup: (tup[0]))\n",
        "  else:\n",
        "    crux_old_ls = sorted(crux_ls, key=lambda tup: (tup[1]), reverse=get_peaks)\n",
        "\n",
        "  \"\"\"\n",
        "  if get_peaks == True:\n",
        "    crux_old_ls = [x for x in crux_old_ls if x[1] > 0]\n",
        "  else:\n",
        "    crux_old_ls = [x for x in crux_old_ls if x[1] < 0]\n",
        "  \"\"\";\n",
        "\n",
        "  # Return only the n_top cruxes if more cruxes than n_top else return all cruxes\n",
        "  if (sort_key != 'sent_no') & (len(crux_old_ls) >= atop_n):\n",
        "    # trim crux list if user asked for less than total number\n",
        "    crux_old_ls = crux_old_ls[:atop_n]\n",
        "\n",
        "  # Retrieve the Sentence raw text for each Crux and add as Tuple(sent_no, sentiment_val, raw_text) to return List\n",
        "  for asent_no, asentiment_val in crux_old_ls:\n",
        "    # print(f'  Retrieving Sentence #{asent_no} with Sentiment Value {asentiment_val} from DataFrame {corpus_df}')\n",
        "    asent_int = int(asent_no)\n",
        "    # print(f\"                      asent_int is type: {type(asent_int)} and Sentence Text:\\n\\n     {corpus_df.iloc[asent_int]['sent_raw']}\")\n",
        "\n",
        "    asent_raw = str(corpus_df[corpus_df['sent_no'] == asent_int]['sent_raw'].values[0])\n",
        "    crux_new_ls.append((int(asent_no), float(f'{asentiment_val:.3f}'), str(asent_raw),)) # Append a Tuple to return List\n",
        "\n",
        "  return crux_new_ls\n",
        "\n",
        "# Test\n",
        "# crux_n_top_ls = crux_sortsents(section_crux_ls, atop_n=3, get_peaks=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjb60CVnz5SF"
      },
      "source": [
        "## **crux_sortsents_report**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFDjK1o8gnQ0"
      },
      "source": [
        "def crux_sortsents_report(crux_ls, ts_df=corpus_sents_df, library_type='baseline', top_n=3, get_peaks=True, sort_by='sent_no', n_sideparags=1, sentence_highlight=True):\n",
        "  '''\n",
        "  Wrapper function to produce report based upon 'crux_sortsents() described as:\n",
        "    Given a list of tuples (sent_no, sentiment value), top_n cruxes to retrieve and bool flag get_peaks\n",
        "    Return a sorted list of peaks/valleys (sentiment_value, sent_no, sent_raw) from greatest down for top_n items\n",
        "\n",
        "    # get_sentnocontext_report\n",
        "  '''\n",
        "\n",
        "  if get_peaks == True:\n",
        "    crux_label = 'Peak'\n",
        "  else:\n",
        "    crux_label = 'Valley'\n",
        "\n",
        "  # Filter and keep only the desired crux type in List crux_subset_ls\n",
        "  crux_subset_ls = []\n",
        "  for acrux_tup in crux_ls:\n",
        "    crux_type, crux_x_coord, crux_y_coord = acrux_tup\n",
        "    if crux_type.lower() == crux_label.lower():\n",
        "      crux_subset_ls.append((crux_x_coord,crux_y_coord)) # Append a Tuple to List\n",
        "\n",
        "  flag_2few_cruxes = False\n",
        "\n",
        "  # Check to see if asked for more Cruxes than were found \n",
        "  top_n_found = len(crux_subset_ls)\n",
        "  if top_n_found < top_n:\n",
        "    flag_2few_cruxes = True\n",
        "    print(f'\\n\\nWARNING: You asked for {top_n} {crux_label}s\\n         but there only {top_n_found} were found above.\\n')\n",
        "    print(f'             Displaying as many {crux_label}s as possible,')\n",
        "    print(f'             to retrieve more, go back to the previous code cells and re-run with wider Crux Window.\\n\\n')\n",
        "\n",
        "\n",
        "  # Get Sentence no and raw text for appropriate Crux subset\n",
        "  # print(f'Calling crux_n_top_ls with crux_subset_ls={crux_subset_ls}\\ntop_n={top_n}\\nget_peaks={get_peaks}')\n",
        "  crux_n_top_ls = crux_sortsents(corpus_df = ts_df, crux_ls=crux_subset_ls, atop_n=top_n, get_peaks=get_peaks, sort_key=sort_by)\n",
        "  # print(f'Returning crux_n_top_ls = {crux_n_top_ls}')\n",
        "\n",
        "  # Print appropriate header Select_Section_No sent_no\n",
        "  print('------------------------------')\n",
        "  # print(f'library_type: {library_type}')\n",
        "  if library_type in ['baseline','sentimentr','syuzhetr','transformer']:\n",
        "    if (sort_by != 'sent_no') & (flag_2few_cruxes == False):\n",
        "      print(f'Library: {library_type.capitalize()} ALL Top {top_n} {crux_label}s Found\\n')\n",
        "    else:\n",
        "      print(f'Library #{library_type.capitalize()} ONLY Top {top_n_found} {crux_label}s Found\\n')\n",
        "  else:\n",
        "    if (sort_by != 'sent_no') & (flag_2few_cruxes == False):\n",
        "      print(f'Section #{Select_Section_No} ALL Top {top_n} {crux_label}s Found\\n')\n",
        "    else:\n",
        "      print(f'Section #{Select_Section_No} ONLY Top {top_n_found} {crux_label}s Found\\n')\n",
        "\n",
        "  # Print summary of subset Cruxes\n",
        "  for i,crux_sent_tup in enumerate(crux_n_top_ls):\n",
        "    # crux_type, crux_x_coord, crux_y_coord = crux_sent_tup\n",
        "    crux_x_coord, crux_y_coord, crux_sent_raw = crux_sent_tup\n",
        "    print(f'   {crux_label} #{i} at Sentence #{crux_x_coord} with Sentiment Value {crux_y_coord}')\n",
        "  # print('------------------------------\\n')\n",
        "  # print('Sent_No  Sentiment   Sentence (Raw Text)\\n')\n",
        "  \n",
        "  # Print details of each Crux in subset\n",
        "  for sent_no, sent_pol, sent_raw in crux_n_top_ls: \n",
        "    sent_no = int(sent_no)\n",
        "    print('\\n\\n-------------------------------------------------------------')\n",
        "    print(f'Sentence #{sent_no}   Sentiment: {sent_pol:.3f}\\n') #     {sent_raw}\\n')\n",
        "    # print('------------------------------')\n",
        "    get_sentnocontext_report(ts_df=ts_df, the_sent_no=sent_no, the_n_sideparags=n_sideparags, the_sent_highlight=sentence_highlight)\n",
        "    # get_sentnocontext(sent_no=sent_no, the_n_sideparags=n_sideparags, the_sent_highlight=sentence_highlight)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJw2WDlwHH5y"
      },
      "source": [
        "# For the selected Section, create an expanded Paragraph DataFrame to match the number of Sentences in the Section\n",
        "\n",
        "def expand_parags2sents(parags_df='corpus_parags_df', sents_df='corpus_sents_df', model_name='vader_lnorm_medianiqr'):\n",
        "  '''\n",
        "  Given a Corpus Paragraph DataFrame and a longer Sentence DataFrame that cover the same Section of a Corpus\n",
        "  Return an expanded version of the Paragraph DataFrame of equal length to the Sentence DataFrame so they can be plotted/compared along the same x-axis\n",
        "  '''\n",
        "\n",
        "  parag_sentiment_expanded_ls = []\n",
        "  parags_midpoint_ls = []\n",
        "  sent_sum = 0\n",
        "  parag_start = section_parags_df.parag_no.min()\n",
        "  print(f'parag_start: {parag_start}')\n",
        "  parag_end = section_parags_df.parag_no.max() + 1 # shape[0] + 3\n",
        "  print(f'parag_end: {parag_end}')\n",
        "  parags_range_ls = list(range(parag_start, parag_end, 1))\n",
        "  print(f'parags_range_ls: {parags_range_ls}')\n",
        "  for i, aparag_no in enumerate(parags_range_ls):\n",
        "    aparag_sentiment_fl = float(corpus_parags_df[corpus_parags_df['parag_no']==aparag_no][model_name])\n",
        "    sent_ct = len(corpus_sents_df[corpus_sents_df.parag_no == aparag_no])\n",
        "    parag_midpoint_int = int(sent_ct//2 + sent_sum)\n",
        "    parags_midpoint_ls.append(parag_midpoint_int)\n",
        "    for asent in range(sent_ct):\n",
        "      parag_sentiment_expanded_ls.append(aparag_sentiment_fl)\n",
        "    sent_sum += sent_ct\n",
        "    print(f'#{i}: Paragraph #{aparag_no} has {sent_ct} Sentences and Avg Sentiment: {aparag_sentiment_fl:.3f}')\n",
        "\n",
        "  print(f'\\nSentence Total: {sent_sum} vs Original section_sents_df: {section_sents_df.shape[0]}')\n",
        "  print(f'  Paragraph Sentiment length: {len(parag_sentiment_expanded_ls)}')\n",
        "\n",
        "  # section_sents_parags_df = section_sents_df.copy()\n",
        "  \n",
        "  # section_sents_parags_df.head(1);\n",
        "\n",
        "  # corpus_sents_df['']\n",
        "\n",
        "  return parag_sentiment_expanded_ls, parags_midpoint_ls\n",
        "\n",
        "# Test\n",
        "# section_sents_df['vader_lnorm_medianiqr_parag'] = expand_parags2sents(parags_df='corpus_parags_df', sents_df='corpus_sents_df')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXRq54NQwI7D"
      },
      "source": [
        "def get_crux_points(ts_df, col_series, text_type='sentence', win_per=5, sec_y_labels=True, sec_y_height=0, subtitle_str=' ', do_plot=True, save2file=False):\n",
        "  '''\n",
        "  Given a DataFrame and a Time Series Column within it and a LOWESS window\n",
        "  Return a list of Min/Max Crux Point (x,y) coordinate tuples for that Column Time Series\n",
        "  '''\n",
        "\n",
        "  # print('entered get_crux_points')\n",
        "  crux_ls = []\n",
        "\n",
        "  series_len = ts_df.shape[0]\n",
        "  # print(f'series_len = {series_len}')\n",
        "\n",
        "  sent_no_min = ts_df.sent_no.min()\n",
        "  sent_no_max = ts_df.sent_no.max()\n",
        "  # print(f'sent_no_min {sent_no_min}')\n",
        "\n",
        "  sm_x = ts_df.index.values\n",
        "  sm_y = ts_df[col_series].values.flatten()\n",
        "\n",
        "  half_win = int((win_per/100)*series_len)\n",
        "  # print(f'half_win = {half_win}')\n",
        "  # print(f'sm_y type = {type(sm_y)}')\n",
        "\n",
        "  # Find peaks(max).\n",
        "  # peak_indexes = signal.argrelextrema(sm_y, np.greater, order=half_win, mode='wrap') argrelextrema will not detect flat peaks\n",
        "  peak_indexes = signal.find_peaks(sm_y, distance=half_win) # np.greater, order=half_win, mode='wrap')\n",
        "  # peak_indexes = peak_indexes + sent_no_min\n",
        "  # print(f'peak_indexes[0]: {peak_indexes_np[0]}')\n",
        "  # print(f'peak_indexes type: {type(peak_indexes_np[0])}')\n",
        "  # peak_indexes_np = peak_indexes_np + sent_no_min\n",
        "  # print(f'peak_indexes type = {type(peak_indexes)}') # sent_no_start sent\n",
        "  peak_indexes = peak_indexes[0]\n",
        "\n",
        "  peak_x_ls = list(peak_indexes)\n",
        "  peak_x_adj_ls = [x+sent_no_min for x in peak_x_ls]\n",
        "\n",
        "  peak_y_ls = list(sm_y[peak_indexes])\n",
        "\n",
        "  peak_label_ls = ['peak'] * len(peak_y_ls)\n",
        "  peak_coord_ls = tuple(zip(peak_label_ls, peak_x_adj_ls, peak_y_ls))\n",
        "\n",
        "  # peak_y_all_ls = peak_y_ls + valley_y_ls\n",
        "  # crux_coord_ls = tuple(zip(x_all_ls, y_all_ls)) \n",
        "\n",
        "  # Find valleys(min).\n",
        "  # valley_indexes = signal.argrelextrema(sm_y, np.less, order=half_win, mode='clip')\n",
        "  valley_indexes = signal.find_peaks(-sm_y, distance=half_win)\n",
        "  valley_indexes = valley_indexes[0]\n",
        "  \n",
        "  valley_x_ls = list(valley_indexes)\n",
        "  valley_x_adj_ls = [x+sent_no_min for x in valley_x_ls]\n",
        "\n",
        "  valley_y_ls = list(sm_y[valley_indexes])\n",
        "\n",
        "  valley_label_ls = ['valley'] * len(valley_y_ls)\n",
        "  valley_coord_ls = tuple(zip(valley_label_ls, valley_x_adj_ls, valley_y_ls))\n",
        "\n",
        "  # Combine Peaks and Valley Coordinates into List of Tuples(label, x_coord, y_coord)\n",
        "  crux_coord_ls = peak_coord_ls + valley_coord_ls\n",
        "\n",
        "  # Save all peaks/valleys as list of (x,y) coordinate tuples\n",
        "  # print(f'type peak_x_ls is: {type(peak_x_ls)}')\n",
        "  #  x_all_ls = peak_x_ls + valley_x_ls\n",
        "  # readjust starting Sentence No to start with first sentence in segement window\n",
        "  #  x_all_ls = [x+sent_no_min for x in x_all_ls]\n",
        "  #  y_all_ls = peak_y_ls + valley_y_ls\n",
        "  # crux_coord_ls = tuple(zip(x_all_ls, y_all_ls)) \n",
        "\n",
        "  # print(f'Original Series length={series_len} vs LOWESS Series length={len(x_all_ls)}')\n",
        "\n",
        "\n",
        "  if do_plot == True:\n",
        "    # Plot main graph.\n",
        "    (fig, ax) = plt.subplots()\n",
        "    ax.plot(sm_x, sm_y)\n",
        "\n",
        "    if sec_y_labels == True:\n",
        "      section_sent_no_boundries_ls = list(corpus_sects_df['sent_no_start'])\n",
        "      section_no_ls = list(corpus_sects_df['sect_no'])\n",
        "      for i, asect_no in enumerate(section_sent_no_boundries_ls):\n",
        "        # Plot vertical lines for section boundries\n",
        "        plt.text(asect_no, sec_y_height, f'Section #{section_no_ls[i]}', alpha=0.2, rotation=90)\n",
        "        plt.axvline(asect_no, color='blue', alpha=0.1)    \n",
        "\n",
        "\n",
        "    win_half = 0 # 2500\n",
        "\n",
        "    # Plot peaks.\n",
        "    # ax.plot(peak_x + win_half, peak_y, marker='o', linestyle='none', color='green', label=\"Peaks\")\n",
        "\n",
        "    # readjust starting Sentence No to start with first sentence in segement window\n",
        "    peak_x_ls = [x+sent_no_min for x in peak_x_ls]\n",
        "    ax.scatter(peak_x_ls, peak_y_ls)\n",
        "    for i, txt in enumerate(list(peak_x_ls)):\n",
        "        ax.annotate(f'  Sent #{txt}', (peak_x_ls[i], peak_y_ls[i]), rotation=90, annotation_clip=True)\n",
        "\n",
        "    # Plot valleys.\n",
        "    # ax.plot(valley_x + win_half, valley_y, marker='o', linestyle='none', color='red', label=\"Valleys\")\n",
        "    # readjust starting Sentence No to start with first sentence in segement window\n",
        "    valley_x_ls = [x+sent_no_min for x in valley_x_ls]\n",
        "    ax.scatter(valley_x_ls, valley_y_ls)\n",
        "    for i, txt in enumerate(list(valley_x_ls)):\n",
        "        ax.annotate(f'Sent #{txt}', (valley_x_ls[i], valley_y_ls[i]), rotation=270, annotation_clip=True) # xytext=(valley_x_ls[i], valley_y_ls[i]-4))\n",
        "\n",
        "    # for i, txt in enumerate(list(valley_x_ls)):\n",
        "    #     ax.annotate(f'\\n\\n\\nSent No.\\n   {txt}', (valley_x_ls[i], valley_y_ls[i]))\n",
        "    # plt.plot(x, y, 'bo')\n",
        "    # texts = [plt.text(valley_x_ls[i], valley_y_ls[i], 'Sent No.\\n   %s' %valley_x_ls[i], ha='right', va='top') for i in range(len(valley_x_ls))]\n",
        "    # adjust_text(texts)\n",
        "\n",
        "    # Confidence Interval (Min/Max Range)\n",
        "    # plt.fill_between(sentiment_lowess_df['x_value'], sentiment_lowess_df['min'], sentiment_lowess_df['max'], alpha=.3, color='lightskyblue')\n",
        "\n",
        "    plt.title(f'{CORPUS_FULL} SMA Smoothed Sentence Sentiment Arcs Crux Detection\\n{subtitle_str} Models: {col_series}')\n",
        "    plt.xlabel(f'Sentence No') # within selected Section #{Select_Section_No}')\n",
        "\n",
        "    # locs, labels = xticks()  # Get the current locations and labels.\n",
        "    # plt.xticks(np.arange(sent_no_min, sent_no_max, step=10))  # Set label locations.\n",
        "\n",
        "    plt.ylabel(f'Sentiment Value')\n",
        "    plt.legend(loc='best');\n",
        "  \n",
        "  if save2file == True:\n",
        "    # Save graph to file.\n",
        "    plt.title(f'{BOOK_TITLE_FULL} \\n SMA Smoothed Sentence Sentiment Arcs Crux Points')\n",
        "    # plt.legend(loc='best')\n",
        "    plt.savefig(f\"{CORPUS_FILENAME.split('.')[0]}_find_peaks.png\")\n",
        "\n",
        "  return crux_coord_ls;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNdJQGtghS_X"
      },
      "source": [
        "def get_standardscaler(series_name, values_ser):\n",
        "  '''\n",
        "  Given a Series of values\n",
        "  Return a list of StandardSclar transformations on that input Series\n",
        "  '''\n",
        "\n",
        "  scaler = StandardScaler()  \n",
        "\n",
        "  # Convert to np.array\n",
        "  values_np = np.array(values_ser)\n",
        "  \n",
        "  values_flat_np = values_np.reshape((len(values_np), 1))\n",
        "\n",
        "  scaler = scaler.fit(values_flat_np)\n",
        "  print(f'Model: {series_name}\\n       Mean: {scaler.mean_}, StandardDeviation: {np.sqrt(scaler.var_)}') # % (scaler.mean_, np.sqrt(scaler.var_)))\n",
        "  values_flat_xform_np = scaler.transform(values_flat_np)\n",
        "\n",
        "  return values_flat_xform_np.flatten().tolist()\n",
        "\n",
        "# Test\n",
        "# stdscaler_series_ls = get_standardscaler('vader_lnorm_medianiqr_roll100', corpus_sents_df['vader_lnorm_medianiqr_roll100'])\n",
        "# corpus_sents_df['vader_roll100_stdscaler'] = pd.Series(stdscaler_series_ls)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABW4oQ4xJT4R"
      },
      "source": [
        "def plot_models(models_subset_ls, models_type='baseline', text_unit='sent_no', win_per=10):\n",
        "  '''\n",
        "  Given a DataFrame and list of correponding Models in that DataFrame\n",
        "  Plot the Sentiment Arcs for the stdscaler with the rolling window \n",
        "  '''\n",
        "\n",
        "\n",
        "  if models_type == 'baseline':\n",
        "    models_ls = models_baseline_ls\n",
        "  elif models_type == 'sentimentr':\n",
        "    models_ls = models_sentimentr_ls\n",
        "  elif models_type == 'syuzhetr':\n",
        "    models_ls = models_syuzhetr_ls\n",
        "  elif models_type == 'transformer':\n",
        "    models_ls = models_transformer_ls\n",
        "  else:\n",
        "    print(f'ERROR: model_type={model_type} must be one of: baseline, sentimentr, syuzhetr or transformer')\n",
        "\n",
        "\n",
        "  if (models_type == 'baseline') | (models_type == 'transformers'):\n",
        "    # Have Corpus data in 4 DataFrames: corpus_[sents|parags|sects|chaps]_df\n",
        "    if text_unit == 'sent_no':\n",
        "      ts_df = corpus_sents_df\n",
        "      text_raw = 'sent_raw'\n",
        "      text_type = 'Sentence'\n",
        "      win_roll = int(corpus_sents_df.shape[0]* win_per/100)\n",
        "    elif text_unit == 'parag_no':\n",
        "      ts_df = corpus_parags_df\n",
        "      text_raw = 'parag_raw'\n",
        "      text_type = 'Paragraph'\n",
        "      win_roll = int(corpus_parags_df.shape[0]* win_per/100)\n",
        "    elif text_unit == 'sect_no':\n",
        "      ts_df = corpus_sects_df\n",
        "      text_raw = 'sect_raw'\n",
        "      text_type = 'Section'\n",
        "      win_roll = int(corpus_sects_df.shape[0]* win_per/100)\n",
        "    elif text_unit == 'chap_no':\n",
        "      ts_df = corpus_chaps_df\n",
        "      text_raw = 'chap_raw'\n",
        "      text_type = 'Chapter'\n",
        "      win_roll = int(corpus_chaps_df.shape[0]* win_per/100)\n",
        "    else:\n",
        "      print(f'ERROR: text_unit={text_unit} must be one of: sent_no, parag_no, sect_no or chap_no')\n",
        "\n",
        "  elif (models_type == 'sentimentr') | (models_type == 'syuzhetr'):\n",
        "\n",
        "    # Only have Corpus Sentence data in one DataFrame: corpus_sentimentr_df or corpus_syuzhetr_df\n",
        "    text_raw = 'sent_raw'\n",
        "    text_type = 'Sentence'\n",
        "\n",
        "    if models_type == 'sentimentr':\n",
        "      ts_df = corpus_sentimentr_df\n",
        "      win_roll = int(corpus_sentimentr_df.shape[0]*win_per/100)\n",
        "    else:\n",
        "      ts_df = corpus_syuzhetr_df\n",
        "      win_roll = int(corpus_syuzhetr_df.shape[0]*win_per/100)\n",
        "\n",
        "  else:\n",
        "    print(f'ERROR: model_type = {model_type} but must be one of 4: [baseline|transformer|sentimentr|syuzhet]')\n",
        "\n",
        "\n",
        "  # Get Rolling Window String\n",
        "  if len(str(win_per)) == 1:\n",
        "    roll_str = 'roll' + '0' + str(win_per)\n",
        "  else:\n",
        "    roll_str = 'roll' + str(win_per%100)\n",
        "\n",
        "\n",
        "  # Translate base model name into _stdscaler_rollxxx derivative\n",
        "  all_stdscaler_roll_ls = []\n",
        "  subset_stdscaler_roll_ls = []\n",
        "  for amodel in models_ls:\n",
        "    # Create a Rolling SMA Series from the stdscaler version of model sentiment values\n",
        "    amodel_stdscaler = f'{amodel}_stdscaler'\n",
        "    col_stdscaler_rollwin = f'{amodel}_stdscaler_{roll_str}'\n",
        "    ts_df[col_stdscaler_rollwin] = ts_df[amodel_stdscaler].rolling(win_roll, center=True).mean()\n",
        "    all_stdscaler_roll_ls.append(col_stdscaler_rollwin)\n",
        "    if amodel in models_subset_ls:\n",
        "      subset_stdscaler_roll_ls.append(col_stdscaler_rollwin)\n",
        "    # col_name_roll = f'{amodel}_lnorm_medianiqr_{roll_str}'\n",
        "\n",
        "  # Compute the Mean of All\n",
        "  mean_all_col = 'mean_stdscaler_' + roll_str\n",
        "  col_stdscaler_roll_ls = [f'{x}_stdscaler_{roll_str}' for x in models_ls] #  if ('mean' not in x)]\n",
        "  # print(f'Computing Mean based upon:\\n    {col_stdscaler_roll_ls}')\n",
        "  ts_df[mean_all_col] = ts_df[all_stdscaler_roll_ls].mean(axis=1)\n",
        "\n",
        "\n",
        "  palette = cycle(px.colors.qualitative.Safe)\n",
        "  # palette = cycle(px.colors.sequential.PuBu)\n",
        "\n",
        "  my_layout = go.Layout(\n",
        "      autosize=False,\n",
        "      width=1600,\n",
        "      height=800,\n",
        "      margin=go.layout.Margin(\n",
        "          l=10,\n",
        "          r=50,\n",
        "          b=100,\n",
        "          t=100,\n",
        "          pad = 1\n",
        "      )\n",
        "  )\n",
        "\n",
        "\n",
        "  fig = go.Figure(layout=my_layout)\n",
        "\n",
        "  # add traces\n",
        "  for i,amodel_stdscaler_roll in enumerate(subset_stdscaler_roll_ls):\n",
        "    # print(f'adding trace: {amodel_stdscaler_roll}')\n",
        "    fig.add_traces(go.Line(x = ts_df[text_unit],\n",
        "                          y = ts_df[amodel_stdscaler_roll],\n",
        "                          text = ts_df[text_raw],\n",
        "                          name = amodel_stdscaler_roll,\n",
        "                          hovertemplate = \"Model: <b>\"+amodel_stdscaler_roll+\"</b><br>\"+text_type+\" #<b>%{x}</b><br>Polarity <b>%{y}</b><br>Text: <b><i>%{text}</i></b>\", \n",
        "                          marker_color=next(palette)))\n",
        "  \"\"\"\n",
        "  if Mean_Subset_Arc == True:\n",
        "    mean_subset_col = 'mean_subset_'+roll_str\n",
        "    corpus_sents_df[mean_subset_col] = corpus_sents_df[model_baseline_subset_ls].mean(axis=1)\n",
        "    fig.add_traces(go.Line(x=corpus_sents_df['sent_no'],\n",
        "                          y = corpus_sents_df[mean_subset_col],\n",
        "                          line=dict(\n",
        "                                # color='#000000',\n",
        "                                width=5\n",
        "                                ),\n",
        "                          text = 'NA', # corpus_sents_df['sent_raw'],\n",
        "                          name = 'Mean of Selected Models',\n",
        "                          hovertemplate = \"Model <b>%{mean_subset_col}</b><br>Sentence #<b>%{x}</b><br>Polarity <b>%{y}</b>\", \n",
        "                          marker_color=next(palette)))\n",
        "\n",
        "  \"\"\";\n",
        "\n",
        "  if Mean_All_Arc == True:\n",
        "    # mean_all_col = 'mean_all_stdscaler_'+roll_str\n",
        "    # ts_df[mean_all_col] = ts_df[col_stdscaler_rollwin_ls].mean(axis=1)\n",
        "    fig.add_traces(go.Line(x=ts_df[text_unit],\n",
        "                          y = ts_df[mean_all_col],\n",
        "                          line=dict(\n",
        "                                color='#000000',\n",
        "                                width=5,\n",
        "                                dash='dot',\n",
        "                                ),\n",
        "                          text = 'NA', # ts_df['sent_raw'],\n",
        "                          name = 'Mean of All Models',\n",
        "                          hovertemplate = \"Model <b>%{mean_all_col}</b><br>Paragraph #<b>%{x}</b><br>Polarity <b>%{y}</b>\", \n",
        "                          marker_color=next(palette)))\n",
        "\n",
        "\n",
        "  fig.update_layout(\n",
        "      title=f\"{CORPUS_FULL}\\n{text_type} Baseline Models<b><i> \" + roll_str.upper() + \"</i></b>\",\n",
        "      xaxis_title=text_type + \" Number\",\n",
        "      yaxis_title=\"StdScaler Sentiment Value\",\n",
        "      hoverlabel=dict(\n",
        "          bgcolor=\"white\",\n",
        "          font_size=16,\n",
        "          font_family=\"Rockwell\"\n",
        "      ),\n",
        "      font=dict(\n",
        "          family=\"Courier New, monospace\",\n",
        "          size=18,\n",
        "          color=\"RebeccaPurple\"\n",
        "      )\n",
        "  )\n",
        "\n",
        "  fig.show();\n",
        "\n",
        "# Test\n",
        "\n",
        "# plot_models(models_subset_ls = ['vader','stanza'], models_type='baseline', text_unit='sent_no', win_per=10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4ehet9JjOsK"
      },
      "source": [
        "def standardize_ts_ls(ts_df, col_ls):\n",
        "  '''\n",
        "  Given a DataFrame and list of Columns in that DataFrame\n",
        "  Create 4 new Standardized Columns for each given Columns\n",
        "  '''\n",
        "\n",
        "  # Create 4 new column names for each column provided\n",
        "  for amodel in col_ls:\n",
        "    # col_meanstd = f'{amodel}_meanstd'\n",
        "    col_medianiqr = f'{amodel}_medianiqr'\n",
        "    col_stdscaler = f'{amodel}_stdscaler'\n",
        "    col_lnorm_meanstd = f'{amodel}_lnorm_meanstd'\n",
        "    col_lnorm_medianiqr = f'{amodel}_lnorm_medianiqr'\n",
        "\n",
        "    # Standardize each column provided using Standard Scaler and  MedianIQRScaling\n",
        "    ts_df[col_stdscaler]  = list2stdscaler(ts_df[amodel])\n",
        "    ts_df[col_medianiqr]  = median_iqr_scaler.fit_transform(np.array(ts_df[amodel]).reshape(-1, 1))\n",
        "    # Normalize the Sentence Sentiment by dividing by Chapter Length\n",
        "    text_len_ls = list(ts_df['token_len'])\n",
        "    text_sentiment_ls = list(ts_df[amodel])\n",
        "    text_sentiment_norm_ls = [text_sentiment_ls[i]/text_len_ls[i] for i in range(len(text_len_ls))]\n",
        "    # RobustStandardize Sentence sentiment values\n",
        "    ts_df[col_lnorm_meanstd]  = mean_std_scaler.fit_transform(np.array(pd.Series(text_sentiment_norm_ls)).reshape(-1, 1))\n",
        "    ts_df[col_lnorm_medianiqr]  = median_iqr_scaler.fit_transform(np.array(pd.Series(text_sentiment_norm_ls)).reshape(-1, 1))\n",
        "\n",
        "  return\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daEzvNu6huM-"
      },
      "source": [
        "# **Either (a) Load Precomputed DataFrames or (b) Create Corpus DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnWJCkqDhA5L"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "len(sections_ls)\n",
        "min(sections_ls, key=len) \n",
        "\n",
        "# TODO: Spell check and correct common OCR errors\n",
        "\n",
        "# SymSpellPy\n",
        "# JamSpell\n",
        "# OCR - https://github.com/Alvant/MIL-OCR\n",
        "\n",
        "# !pip install -U symspellpy\n",
        "\n",
        "# Did not need these\n",
        "# dictionary_path = pkg_resources.resource_filename(\"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
        "# bigram_path = pkg_resources.resource_filename(\"symspellpy\", \"frequency_bigramdictionary_en_243_342.txt\")\n",
        "\n",
        "\n",
        "import pkg_resources\n",
        "from symspellpy import SymSpell, Verbosity\n",
        "\n",
        "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
        "dictionary_path = pkg_resources.resource_filename(\n",
        "    \"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
        "# term_index is the column of the term and count_index is the\n",
        "# column of the term frequency\n",
        "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
        "\n",
        "# lookup suggestions for single-word input strings\n",
        "input_term = \"memebers\"  # misspelling of \"members\"\n",
        "input_term = \"summermorning\"\n",
        "# max edit distance per lookup\n",
        "# (max_edit_distance_lookup <= max_dictionary_edit_distance)\n",
        "suggestions = sym_spell.lookup(input_term, Verbosity.CLOSEST,\n",
        "                               max_edit_distance=2)\n",
        "# display suggestion term, term frequency, and edit distance\n",
        "for suggestion in suggestions:\n",
        "    print(suggestion)\n",
        "\n",
        "\n",
        "\n",
        "import pkg_resources\n",
        "from symspellpy.symspellpy import SymSpell\n",
        "\n",
        "# Set max_dictionary_edit_distance to avoid spelling correction\n",
        "sym_spell = SymSpell(max_dictionary_edit_distance=0, prefix_length=7)\n",
        "dictionary_path = pkg_resources.resource_filename(\n",
        "    \"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
        "# term_index is the column of the term and count_index is the\n",
        "# column of the term frequency\n",
        "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
        "\n",
        "# a sentence without any spaces\n",
        "input_term = \"thequickbrownfoxjumpsoverthelazydog\"\n",
        "input_term = \"summermorning\"\n",
        "result = sym_spell.word_segmentation(input_term)\n",
        "print(\"{}, {}, {}\".format(result.corrected_string, result.distance_sum,\n",
        "                          result.log_prob_sum))\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUz1ieOU1sAF"
      },
      "source": [
        "!ls -altr *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wI5Tg1bFiERD"
      },
      "source": [
        "### **(a) Load Corpus DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxCBdYNTiDrC"
      },
      "source": [
        "# Read Preprocessed Corpus Sentences DataFrame\n",
        "\n",
        "# author_str = ''.join(CORPUS_AUTHOR.split()).lower()\n",
        "# title_str = ''.join(CORPUS_TITLE.split()).lower()\n",
        "title_str = ''.join(CORPUS_FILENAME.split('.')[0]).lower()\n",
        "datetime_now = datetime.utcnow().strftime(\"%Y%m%d_%H%M\")\n",
        "\n",
        "# Sentence DataFrame\n",
        "corpus_sents_filename = f'corpus_sents_{title_str}.csv'\n",
        "print(f'Reading from file: {corpus_sents_filename}')\n",
        "corpus_sents_df = pd.read_csv(corpus_sents_filename)\n",
        "\n",
        "# Paragraph DataFrame\n",
        "corpus_parags_filename = f'corpus_parags_{title_str}.csv'\n",
        "print(f'Reading from file: {corpus_parags_filename}')\n",
        "corpus_parags_df = pd.read_csv(corpus_parags_filename)\n",
        "\n",
        "# Section DataFrame\n",
        "corpus_sects_filename = f'corpus_sects_{title_str}.csv'\n",
        "print(f'Reading from file: {corpus_sects_filename}')\n",
        "corpus_sects_df = pd.read_csv(corpus_sects_filename)\n",
        "\n",
        "# Chapter DataFrame\n",
        "corpus_chaps_filename = f'corpus_chaps_{title_str}.csv'\n",
        "print(f'Reading from file: {corpus_chaps_filename}')\n",
        "corpus_chaps_df = pd.read_csv(corpus_chaps_filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqsUHiF9K_5L"
      },
      "source": [
        "# Verify Sentences\n",
        "\n",
        "corpus_sents_df.head(2)\n",
        "corpus_sents_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3fD5CpfKJnw"
      },
      "source": [
        "# corpus_sents_df = corpus_sents_df.loc[:, ~corpus_sents_df.columns.str.contains('^Unnamed')]\n",
        "corpus_sents_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "corpus_sents_df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl3hwS0wLEeR"
      },
      "source": [
        "# Verify Paragraphs\n",
        "\n",
        "corpus_parags_df.head(2)\n",
        "corpus_parags_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzP_CrO3J0gd"
      },
      "source": [
        "# corpus_parags_df = corpus_parags_df.loc[:, ~corpus_parags_df.columns.str.contains('^Unnamed')]\n",
        "corpus_parags_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "corpus_parags_df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZR54xIPJvm-"
      },
      "source": [
        "# Verify Sections\n",
        "\n",
        "# corpus_sects_df.head(2)\n",
        "corpus_sects_df.info(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmlXbKnbL1N7"
      },
      "source": [
        "corpus_sects_df.rename(columns={'Unnamed: 0':'sect_no','chap_raw':'sect_raw','chap_clean':'sect_clean'}, inplace=True)\n",
        "# corpus_sects_df = corpus_sects_df.loc[:, ~corpus_sects_df.columns.str.contains('^Unnamed')]\n",
        "# corpus_sects_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "corpus_sects_df = corpus_sects_df.loc[:, ~corpus_sects_df.columns.duplicated()]\n",
        "# corpus_sects_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "\n",
        "corpus_sects_df.info () # [: corpus_sects_df.columns.like('_no')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb2DYmbqMEF-"
      },
      "source": [
        "# Verfiy Chapters\n",
        "\n",
        "corpus_chaps_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmfsseAz2F8T"
      },
      "source": [
        "# corpus_chaps_df = corpus_chaps_df.loc[:, ~corpus_chaps_df.columns.str.contains('^Unnamed')]\n",
        "corpus_chaps_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "corpus_chaps_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9X5gfDoi_d0"
      },
      "source": [
        "# Verify all 4 semantic unit DataFrame shapes\n",
        "\n",
        "print(f'corpus_sents_df.shape: {corpus_sents_df.shape}')\n",
        "print(f'corpus_parags_df.shape: {corpus_parags_df.shape}')\n",
        "print(f'corpus_sects_df.shape: {corpus_sects_df.shape}')\n",
        "print(f'corpus_chaps_df.shape: {corpus_chaps_df.shape}')\n",
        "\n",
        "\"\"\"\n",
        "SButler Odyssey\n",
        "\n",
        "corpus_sents_df.shape: (2445, 8)\n",
        "corpus_parags_df.shape: (1051, 8)\n",
        "corpus_sects_df.shape: (24, 8)\n",
        "corpus_chaps_df.shape: (24, 8)\n",
        "\"\"\";\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQYjye-v9XMY"
      },
      "source": [
        "### **(b) Create Corpus DataFrames**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6qZH_qAVPQD"
      },
      "source": [
        "#### **Try to Automatically Detected File/Text Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtWVf1cJUeSW"
      },
      "source": [
        "!pwd\n",
        "!ls -altr *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4TH13cFUErD"
      },
      "source": [
        "# Try to automatically discover Corpus text Encoding scheme (default to 'utf-8', but often 'iso-8859-1', 'windows-1252', 'cp1252', or 'ascii')\n",
        "\n",
        "CORPUS_ENCODING = 'utf-8' # Python3 default encoding\n",
        "\n",
        "corpus_str, corpus_encode, encoding_confidence = get_file_encoding(CORPUS_FILENAME)\n",
        "CORPUS_ENCODING = str(corpus_encode).lower()\n",
        "\n",
        "if encoding_confidence > 0.8:\n",
        "  print(f'Setting file/text encoding to {CORPUS_ENCODING}\\n')\n",
        "  print(f\"    {encoding_confidence*100:.2f}% confidence Encoding = '{CORPUS_ENCODING}' for '{CORPUS_FILENAME}'\")\n",
        "else:\n",
        "  print(f\"WARNING: Less than 80% confidence estimating Encoding scheme for '{CORPUS_FILENAME}'\\n\")\n",
        "  print(f\"         Only {encoding_confidence*100:.2f}% confidence Encoding = '{CORPUS_ENCODING}'\")\n",
        "  print(f\"         Manually verify corpus file '{CORPUS_FILENAME}' encoding, set as GLOBAL_CONSTATANT and rerun\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMkihxoY6T6U"
      },
      "source": [
        "#### **Create Chapter and Section DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ydj8ITnTE1D"
      },
      "source": [
        "!head -n 10 $corpus_filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pwfl-0axB1X"
      },
      "source": [
        "# Parse out raw/clean Chapters/Sections from Corpus text file\n",
        "\n",
        "corpus_chaps_raw_ls, corpus_chaps_clean_ls, corpus_sects_raw_ls, corpus_sects_clean_ls, sect_chapno_ls, corpus_raw_str = corpus2chapsect(corpus_filename)\n",
        "\n",
        "# Verify Paragraph count and sample\n",
        "\n",
        "if type(corpus_chaps_raw_ls[0]) is not str:\n",
        "\n",
        "  print(f'\\nERROR: Could not parse Corpus file into Chapters and Sections correctly\\n       Edit Corpus file and re-run')\n",
        "\n",
        "else:\n",
        "\n",
        "  print(f'\\n{len(corpus_chaps_raw_ls)} Chapters found in this Corpus')\n",
        "\n",
        "  print(f'\\n{len(corpus_sects_raw_ls)} Sections found in this Corpus')\n",
        "\n",
        "\n",
        "  print(f'\\n\\n----------{len(corpus_chaps_raw_ls)} CHAPTERS ----------')\n",
        "  chap_sample_no = 0\n",
        "  print(f'First 500 character sample from Chapter #{chap_sample_no}\\n\\n     {corpus_chaps_raw_ls[chap_sample_no][:500]}')\n",
        "\n",
        "  print(f'\\n\\n----------{len(corpus_sects_raw_ls)} SECTIONS ----------')\n",
        "  sect_sample_no = 0\n",
        "  print(f'First 500 character sample from Section #{sect_sample_no}\\n\\n    {corpus_sects_raw_ls[sect_sample_no][:500]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Coq6ZS6aMkvd"
      },
      "source": [
        "# Create Chapter DataFrame\n",
        "\n",
        "chap_no_ls = list(range(len(corpus_chaps_raw_ls)))\n",
        "corpus_chaps_df = pd.DataFrame({'chap_no':chap_no_ls, 'chap_raw':corpus_chaps_raw_ls, 'chap_clean':corpus_chaps_clean_ls})\n",
        "corpus_chaps_df['chap_raw'] = corpus_chaps_df['chap_raw'].astype('string')\n",
        "corpus_chaps_df['chap_clean'] = corpus_chaps_df['chap_clean'].astype('string')\n",
        "# corpus_chaps_df.head(1)\n",
        "corpus_chaps_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdKAEsWt-y_w"
      },
      "source": [
        "# Calculate length statistics for Chapters\n",
        "\n",
        "corpus_chaps_df['char_len'] = corpus_chaps_df['chap_raw'].apply(lambda x : len(x))\n",
        "corpus_chaps_df['token_len'] = corpus_chaps_df['chap_raw'].apply(lambda x : len(x.split()))\n",
        "# corpus_chaps_df.head()\n",
        "corpus_chaps_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiBMyYDD88z5"
      },
      "source": [
        "# Create Section DataFrame\n",
        "\n",
        "sect_no_ls = list(range(len(corpus_sects_raw_ls)))\n",
        "corpus_sects_df = pd.DataFrame({'sect_no':sect_no_ls, 'chap_no':sect_chapno_ls, 'sect_raw':corpus_sects_raw_ls, 'sect_clean':corpus_sects_clean_ls})\n",
        "corpus_sects_df['sect_raw'] = corpus_sects_df['sect_raw'].astype('string')\n",
        "corpus_sects_df['sect_clean'] = corpus_sects_df['sect_clean'].astype('string')\n",
        "# corpus_sects_df.head(1)\n",
        "corpus_sects_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9jpNBIGmyBT"
      },
      "source": [
        "# Calculate length statistics for Chapters\n",
        "\n",
        "corpus_sects_df['char_len'] = corpus_sects_df['sect_raw'].apply(lambda x : len(x))\n",
        "corpus_sects_df['token_len'] = corpus_sects_df['sect_raw'].apply(lambda x : len(x.split()))\n",
        "# corpus_sects_df.head()\n",
        "corpus_sects_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFj2CQPD6l01"
      },
      "source": [
        "#### **Create Paragraph and Sentence DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weu1ZRsC6XCP"
      },
      "source": [
        "corpus_sectno = -1\n",
        "\n",
        "corpus_paragno = -1\n",
        "corpus_parags_ls = []\n",
        "\n",
        "corpus_sentno = -1\n",
        "corpus_sents_ls = []\n",
        "\n",
        "sects_raw_ls = list(corpus_sects_df.sect_raw)\n",
        "\n",
        "# For every Section in the Corpus\n",
        "for asectno, asect_raw in enumerate(sects_raw_ls):\n",
        "  # print(f'Section #{asectno}')\n",
        "  corpus_sectno += 1\n",
        "\n",
        "  # Split into a list of Paragraphs\n",
        "  sect_parags_raw_ls, sect_clean_str = sect2parags(asect_raw)\n",
        "  # For every Paragraph in Section \n",
        "  for aparagno, aparag_raw in enumerate(sect_parags_raw_ls):\n",
        "    # print(f'  Paragraph #{aparagno}')\n",
        "    corpus_paragno += 1\n",
        "\n",
        "    # Split into list of Sentences\n",
        "    parag_sents_raw_ls, parag_clean_str = parag2sents(aparag_raw)\n",
        "    aparag_clean = clean_text(aparag_raw)\n",
        "    corpus_parags_ls.append((corpus_paragno, corpus_sectno, aparag_raw, aparag_clean))\n",
        "\n",
        "    # For every Sentence in Paragraph\n",
        "    for asentno, asent_raw in enumerate(parag_sents_raw_ls):\n",
        "      print(f'Section #{asectno}, Paragraph #{aparagno}, Sentence #{asentno}')\n",
        "      corpus_sentno += 1\n",
        "      asent_clean = clean_text(asent_raw)\n",
        "      corpus_sents_ls.append((corpus_sentno, corpus_paragno, corpus_sectno, asent_raw, asent_clean))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4721-er6W96"
      },
      "source": [
        "# Verify\n",
        "\n",
        "sent_ct = len(corpus_sents_ls)\n",
        "print(f'{sent_ct} Sentences were found in the Corpus')\n",
        "\n",
        "parag_ct = len(corpus_parags_ls)\n",
        "print(f'{parag_ct} Paragraphs were found in the Corpus')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0gltS-r0QPv"
      },
      "source": [
        "print(corpus_parags_ls[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm9fDtVJziE3"
      },
      "source": [
        "# Create Paragraph DataFrame\n",
        "\"\"\"\n",
        "parag_no_ls = list(range(len(corpus_parags_ls)))\n",
        "corpus_parags_df = pd.DataFrame({'sect_no':sect_no_ls, 'chap_no':sect_chapno_ls, 'sect_raw':corpus_sects_raw_ls, 'sect_clean':corpus_sects_clean_ls})\n",
        "corpus_parags_df['sect_raw'] = corpus_parags_df['sect_raw'].astype('string')\n",
        "corpus_parags_df['sect_clean'] = corpus_parags_df['sect_clean'].astype('string')\n",
        "corpus_parags_df.info()\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ7Xdmyt0Asb"
      },
      "source": [
        "# Create Paragraph DataFrame\n",
        "\n",
        "corpus_parags_df = pd.DataFrame(corpus_parags_ls,columns=['parag_no','sect_no','parag_raw','parag_clean'])\n",
        "corpus_parags_df['parag_raw'] = corpus_parags_df['parag_raw'].astype('string')\n",
        "corpus_parags_df['parag_clean'] = corpus_parags_df['parag_clean'].astype('string')\n",
        "corpus_parags_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Arm9ZlvSl-42"
      },
      "source": [
        "# Calculate length statistics for Paragraphs\n",
        "\n",
        "corpus_parags_df['char_len'] = corpus_parags_df['parag_raw'].apply(lambda x : len(x))\n",
        "corpus_parags_df['token_len'] = corpus_parags_df['parag_raw'].apply(lambda x : len(x.split()))\n",
        "corpus_parags_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqN4aFeT3RMq"
      },
      "source": [
        "# Verify Paragraph DataFrame start and end\n",
        "\n",
        "corpus_parags_df.head(5)\n",
        "corpus_parags_df.tail(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-T27_raCzWk6"
      },
      "source": [
        "# Create Sentences DataFrame\n",
        "\n",
        "corpus_sents_df = pd.DataFrame(corpus_sents_ls,columns=['sent_no', 'parag_no','sect_no','sent_raw','sent_clean'])\n",
        "corpus_sents_df['sent_raw'] = corpus_sents_df['sent_raw'].astype('string')\n",
        "corpus_sents_df['sent_clean'] = corpus_sents_df['sent_clean'].astype('string')\n",
        "corpus_sents_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glceM5TylaA8"
      },
      "source": [
        "# Compute length statistics for Sentences\n",
        "\n",
        "corpus_sents_df['char_len'] = corpus_sents_df['sent_raw'].apply(lambda x : len(x))\n",
        "corpus_sents_df['token_len'] = corpus_sents_df['sent_raw'].apply(lambda x : len(x.split()))\n",
        "corpus_sents_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4WWrd1J2uz_"
      },
      "source": [
        "# Verify Sentence DataFrame start and end\n",
        "\n",
        "corpus_sents_df.head(10)\n",
        "corpus_sents_df.tail(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgJKnHHk4f3F"
      },
      "source": [
        "#### **For each Section, insert [start|mid|end] Sentence numbers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tnwy-rFW4swr"
      },
      "source": [
        "# Calculate the start, mid and end Sentence No for each Section\n",
        "\n",
        "sect_sent_no_start_ls = np.array(corpus_sents_df.groupby('sect_no')['sent_no'].min())\n",
        "sect_sent_no_end_ls = np.array(corpus_sents_df.groupby('sect_no')['sent_no'].max())\n",
        "\n",
        "def my_mid(anum, bnum):\n",
        "  mid_no = (anum - bnum)//2 + bnum\n",
        "\n",
        "  return mid_no\n",
        "\n",
        "print('\\nSection start sentence no: -----')\n",
        "print(sect_sent_no_start_ls)\n",
        "\n",
        "sect_sent_no_mid_ls = list(map(my_mid, sect_sent_no_end_ls, sect_sent_no_start_ls))\n",
        "print('\\nSection mid-sentence no: -----')\n",
        "print(sect_sent_no_mid_ls)\n",
        "\n",
        "print('\\nSection end sentence no: -----')\n",
        "print(sect_sent_no_end_ls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MNNcN_d48xa"
      },
      "source": [
        "# Insert 3 new columns on start,mid and end Sentence No for each Section\n",
        "\n",
        "corpus_sects_df.insert(2, 'sent_no_start', sect_sent_no_start_ls)\n",
        "corpus_sects_df.insert(3, 'sent_no_mid', sect_sent_no_mid_ls)\n",
        "corpus_sects_df.insert(4, 'sent_no_end', sect_sent_no_end_ls)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuxMQpOY2uwF"
      },
      "source": [
        "# Verfiy Section \n",
        "\n",
        "corpus_sects_df.filter(like='_no')\n",
        "corpus_sects_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z48WKV1W6KdA"
      },
      "source": [
        "#### **For Each Chapter, Insert [start|mid|end] Sentence numbers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGNlqV5G7Tk-"
      },
      "source": [
        "corpus_chaps_clean_ls[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70ntj-6X8PbU"
      },
      "source": [
        "corpus_chaps_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWFbBuEGQ4fH"
      },
      "source": [
        "search_str = 'within touch'\n",
        "\n",
        "corpus_sents_df[corpus_sents_df['sent_clean'].str.contains(search_str)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWvddQwkCjKY"
      },
      "source": [
        "corpus_sents_df.iloc[1056]['sent_clean']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuPPyK2gUZmS"
      },
      "source": [
        "corpus_sects_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DylkEa8cCwG"
      },
      "source": [
        "corpus_chaps_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vrZVqCRVOwF"
      },
      "source": [
        "achap_sentstart_clean_ls = []\n",
        "\n",
        "for indx, achap_tup in corpus_chaps_df.iterrows():\n",
        "  achap_no, achap_raw, achap_clean, achap_charlen, achap_tokenlen = achap_tup\n",
        "  achap_sentstart_clean_ls.append(achap_clean[:100])\n",
        "\n",
        "print(achap_sentstart_clean_ls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4_18dyRVOqk"
      },
      "source": [
        "corpus_sects_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2HcU3WLaHpV"
      },
      "source": [
        "!pip install fuzzywuzzy[speedup]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU_11lWzaI-I"
      },
      "source": [
        "from fuzzywuzzy import fuzz\n",
        "from fuzzywuzzy import process"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbxpUygQaL3g"
      },
      "source": [
        " fuzz.ratio(\"this is a test\", \"this is a test!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6B0n3hdbLyp"
      },
      "source": [
        "corpus_sects_df.info()\n",
        "\n",
        "type(corpus_sects_df['sect_clean'][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtGurlnd6-Qt"
      },
      "source": [
        "# Calculate the start, mid and end Sentence No for each Section\n",
        "\n",
        "min_charlen = 80  # How many characters to match at the start of start/end Sentences\n",
        "\n",
        "\n",
        "# First, find which Sections align with each Chapter and save Section's sent_no_start as the same for Chapter\n",
        "chaps_sentstart_ls = []\n",
        "sects_sentstart_ls = list(corpus_sects_df['sect_clean'].apply(lambda x: x[:min_charlen].strip()))\n",
        "for achap_indx, achap_tup in corpus_chaps_df.iterrows():\n",
        "  achap_no, achap_raw, achap_clean, achap_charlen, achap_tokenlen = achap_tup\n",
        "  achap_sentstart_str = achap_clean[:min_charlen].strip()\n",
        "  achap_sentstart_str = ' '.join(achap_sentstart_str.split())\n",
        "\n",
        "  sent_startno_found = False\n",
        "  # Loop over all the Sections to see if the starting text matches the Chapter starting text\n",
        "  for asect_indx, asect_sentstart_str in enumerate(sects_sentstart_ls):\n",
        "    asect_sentstart_str = ' '.join(asect_sentstart_str.split())\n",
        "    achap_sentstart_len = len(achap_sentstart_str)\n",
        "    asect_sentstart_len = len(asect_sentstart_str)\n",
        "    if (achap_sentstart_len > asect_sentstart_len):\n",
        "      len_diff = achap_sentstart_len - asect_sentstart_len\n",
        "      achap_sentstart_str = achap_sentstart_str[:-len_diff]\n",
        "    elif (achap_sentstart_len < asect_sentstart_len):\n",
        "      len_diff = asect_sentstart_len - achap_sentstart_len\n",
        "      asect_sentstart_str = asect_sentstart_str[:-len_diff]\n",
        "    else:\n",
        "      # Both Chapter and Section starting Sentence strings are equal length\n",
        "      pass\n",
        "\n",
        "    print(f'Fuzzy Compare:\\n\\n    Chapter Start: {achap_sentstart_str}\\n    Section Start: {asect_sentstart_str}')\n",
        "    if fuzz.ratio(achap_sentstart_str, asect_sentstart_str) > 97:\n",
        "      sent_startno_ls = list(corpus_sects_df[corpus_sects_df['sect_no'] == asect_indx]['sent_no_start'])\n",
        "      # print(f'type(sent_startno): {sent_startno_ls[0]}')\n",
        "      chaps_sentstart_ls.append(sent_startno_ls[0])\n",
        "      sent_startno_found = True\n",
        "      break\n",
        "  # If no match found, enter ERROR code -1 in the Sentence start no for the current Chapter\n",
        "  if sent_startno_found == False:\n",
        "    chaps_sentstart_ls.append((achap_indx, -1))\n",
        "\n",
        "print(f'\\n\\nchaps_sentstart_ls: {chaps_sentstart_ls}')\n",
        "\n",
        "\n",
        "\n",
        "# Second, get the end Sentence for Each Chapter by rotating Sentence Start No left and pushing on the last Sentence No\n",
        "chaps_sentend_ls = []\n",
        "chaps_sentend_ls = [x-1 for x in chaps_sentstart_ls]\n",
        "corpus_sentlast = corpus_sents_df.shape[0] - 1\n",
        "\n",
        "chaps_sentend_ls.pop(0)\n",
        "chaps_sentend_ls.append(corpus_sentlast)\n",
        "\n",
        "print(f'\\n\\nchaps_sentend_ls: {chaps_sentend_ls}')\n",
        "\n",
        "\n",
        "# Third, calculate the Sentence No in the middle of each Chapter\n",
        "\n",
        "chaps_sentmid_ls = [(((chaps_sentend_ls[i] - chaps_sentstart_ls[i])//2)+chaps_sentstart_ls[i]) for i in range(len(chaps_sentend_ls))]\n",
        "\n",
        "print(f'\\n\\nchaps_sentmid_ls: {chaps_sentmid_ls}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpOzOahxhgvU"
      },
      "source": [
        "# Verify boundry cases\n",
        "\n",
        "corpus_sents_df.iloc[268]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iN_GXkBekH0P"
      },
      "source": [
        "# corpus_chaps_df.drop(columns=['sent_no_start','sent_no_mid','sent_no_end'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZTduIsl6KdB"
      },
      "source": [
        "# Insert 3 new columns on start,mid and end Sentence No for each Chapter\n",
        "\n",
        "corpus_chaps_df.insert(1, 'sent_no_start', chaps_sentstart_ls)\n",
        "corpus_chaps_df.insert(2, 'sent_no_mid', chaps_sentmid_ls)\n",
        "corpus_chaps_df.insert(3, 'sent_no_end', chaps_sentend_ls)\n",
        "corpus_chaps_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTW3Gxmf6KdC"
      },
      "source": [
        "# Verfiy Chapter \n",
        "\n",
        "corpus_chaps_df.filter(like='_no')\n",
        "corpus_chaps_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zK27hN0KkvBI"
      },
      "source": [
        "### **END HERE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVCkjat0vffd"
      },
      "source": [
        "#### **Get All (non-null) Raw Lines**\n",
        "\n",
        "* NOTE: Corpus textfile needs to be Preprocessed before running this\n",
        "- Remove all Curve Parenthesis that span multiple sentences or paragraphs\n",
        "- Remove all Square Parenthesis\n",
        "- Filter out non-printing characters if they exist (or use proper encoding)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgqqpwagWPS7"
      },
      "source": [
        "len(corpus_lines_ls)\n",
        "print('\\n')\n",
        "print(corpus_lines_ls[11])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBl_hrhPZo29"
      },
      "source": [
        "min(corpus_lines_ls, key=lambda word: len(word))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lthUz3kpZ8_K"
      },
      "source": [
        "corpus_lines_ls.sort(key=lambda s: len(s))\n",
        "corpus_lines_ls[:100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an7SzlAuvXA0"
      },
      "source": [
        "# NOTE: ~3-15 minutes (one pass with PySBD)\n",
        "#             minutes (two passes with PySBD+NLTK)\n",
        "\n",
        "# Time consuming so only set pysbd_only=True (second NLTK sentence tokenizer pass) \n",
        "#   if necessary (e.g. Samuel Butler's 1900 trans. of Homer's Odyssey)\n",
        "#                 PySBD: 1075 lines, PySBD+NLTK: 3905 lines, NLTK: 3109 lines\n",
        "#                        Why? a 3 Sentence Paragraph enclosed in double quotes is counted as one Sentence by PySBD\n",
        "#           w/spec char strip: PySBD+NLTK: 3926\n",
        "#           w/o digits/footnotes: PySBD+NLTK: 3925\n",
        "\n",
        "corpus_lines_ls, lines_raw_str = corpus2lines(corpus_filename, pysbd_only=False)\n",
        "\n",
        "# Verify\n",
        "print(f'\\n\\nRead raw corpus lines: character count: {len(lines_raw_str)}')\n",
        "print(f'                        raw line count:  {len(corpus_lines_ls)}\\n\\n')\n",
        "\n",
        "line_ct = 10\n",
        "print(f'First {line_ct} raw lines: --------------------\\n')\n",
        "for i,aline in enumerate(corpus_lines_ls[:line_ct]):\n",
        "  print(f'Line #{i}:\\n    {aline}')\n",
        "print(f'\\n\\nLast {line_ct} raw lines: -------------------\\n')\n",
        "for i,aline in enumerate(corpus_lines_ls[-line_ct:]):\n",
        "  print(f'Line #{i}: {aline}')\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "BEFORE stripping out headings len: 610949 (605835 w/2nd pass)\n",
        "Corpus Paragraph Raw Count: 1075\n",
        "   Parag count before processing sents: 1075\n",
        "About to return corpus_sents_raw_ls with len = 2469\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_b6ORN6A08Dv"
      },
      "source": [
        "#### **Create Sentence DataFrame: [corpus_sents_df]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BeGt1ot0_dK"
      },
      "source": [
        "# Filter out all the structural/metatag and blank/punctuation only lines\n",
        "#    and save all semantically meaningful Sentences in corpus_sents_ls\n",
        "\n",
        "corpus_sents_ls = []\n",
        "\n",
        "for i, aline in enumerate(corpus_lines_ls):\n",
        "\n",
        "    # print(f'Examing line #{i}: {aline}')\n",
        "\n",
        "    aline_clean = aline.strip()\n",
        "    # Skip/delete whitespace only sentences\n",
        "    if len(aline_clean) == 0:\n",
        "      continue\n",
        "    \n",
        "    # Skip/delete any sentences starting with CHAPTER RegEx Pattern\n",
        "    if aline_clean.startswith('CHAPTER '):\n",
        "      continue\n",
        "    \n",
        "    # Skip/delete any sentences starting with SECTION RegEx Pattern\n",
        "    if aline_clean.startswith('SECTION '):\n",
        "      continue\n",
        "\n",
        "    # Skip/delete any sentences starting with SECTION RegEx Pattern\n",
        "    if aline_clean.startswith('BOOK '):\n",
        "      continue\n",
        "\n",
        "    # Skip/delete any sentence no alpha/numeric charcters (e.g. only punctuation)\n",
        "    if (re.match('^[^a-zA-Z]+$', aline_clean)):\n",
        "      print(f'No alnum line #{i}: {aline}')\n",
        "      continue\n",
        "\n",
        "    # If passed through all previous filters, save as genuine Sentence\n",
        "    corpus_sents_ls.append(aline_clean)\n",
        "\n",
        "# Test\n",
        "print(f'Raw Lines length: {len(corpus_lines_ls)}')\n",
        "print(f' Clean Sentences: {len(corpus_sents_ls)}')\n",
        "\n",
        "line_ct = 10\n",
        "print(f'First {line_ct} clean Sentences : --------------------\\n')\n",
        "for i,aline in enumerate(corpus_sents_ls[:line_ct]):\n",
        "  print(f'Line #{i}:\\n    {aline}')\n",
        "print(f'\\n\\nLast {line_ct} clean Sentences: -------------------\\n')\n",
        "for i,aline in enumerate(corpus_sents_ls[-line_ct:]):\n",
        "  print(f'Line #{i}: {aline}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8ERYqQW7U9q"
      },
      "source": [
        "# Create Sentence DataFrame\n",
        "\n",
        "sent_no_ls = list(range(len(corpus_sents_ls)))\n",
        "\n",
        "corpus_sents_df = pd.DataFrame({'sent_no': sent_no_ls, 'sent_raw': corpus_sents_ls})\n",
        "corpus_sents_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70VO_w4Oql1a"
      },
      "source": [
        "# Compute Sentence text statistics\n",
        "\n",
        "corpus_sents_df['sent_clean'] = corpus_sents_df['sent_raw'].apply(lambda x: clean_text(x))\n",
        "corpus_sents_df['token_len'] = corpus_sents_df['sent_clean'].apply(lambda x: len(x.split()))\n",
        "corpus_sents_df['char_len'] = corpus_sents_df['sent_raw'].apply(lambda x: len(x))\n",
        "corpus_sents_df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFC8GTnw6HrG"
      },
      "source": [
        "#### **Create Paragraph DataFrame: [corpus_parags_df]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGog8ZW16bbr"
      },
      "source": [
        "# Read Corpus into a single string then split into raw Paragraphs\n",
        "\n",
        "corpus_parags_ls, corpus_parags_raw_ls, corpus_raw_str = corpus2parags(CORPUS_FILENAME)\n",
        "print(f'Found #{len(corpus_parags_ls)} paragraphs\\n')\n",
        "\n",
        "print('\\nThe first 5 Paragraphs of the Corpus (first 10 chars):')\n",
        "print('-----------------------------------\\n')\n",
        "corpus_parags_ls[:5][:10]\n",
        "print('\\n')\n",
        "print('\\n\\nThe last 5 Paragraphs of the Corpus (first 10 chars):')\n",
        "print('-----------------------------------\\n')\n",
        "corpus_parags_ls[-5:][:10]\n",
        "print('\\n')\n",
        "\n",
        "n_shortest = 10\n",
        "print(f'The {n_shortest} shortest Paragraphs in the Corpus are:')\n",
        "print('--------------------------------------------')\n",
        "temp_parags_ls = sorted(corpus_parags_ls, key=lambda x: (len(x), x))\n",
        "for i, asent in enumerate(temp_parags_ls[:n_shortest]):\n",
        "  print(f'Shortest Paragraph #{i}: {asent}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZdfH-rTXwwT"
      },
      "source": [
        "# Verify Paragraphs found and Sentence-Paragraph matches\n",
        "\n",
        "# TODO: Upgrade if warranted (requires updating x2parags functions)\n",
        "\"\"\"\n",
        "print(f'{len(corpus_parags_ls)} Paragraphs found in Corpus')\n",
        "print(f'{len(sentences_section_ls)} Sentences found in a Section')\n",
        "\n",
        "sentences_nosection_ct = len(sentences_nosection_ls)\n",
        "\n",
        "if (sentences_nosection_ct > 0):\n",
        "  print(f'\\n    WARNING: The following {sentences_nosection_ct} Sentences were NOT FOUND in any Section')\n",
        "  print(f'             If these are important/numerous, go back and edit/correct source Corpus text file and rerun this notebook\\n')\n",
        "\n",
        "  for i, asent in enumerate(sentences_nosection_ls):\n",
        "    print(f'    #{i}: {asent}\\n')\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAwfcbYJnwtq"
      },
      "source": [
        "# Verify Paragraph count and sample\n",
        "\n",
        "len(corpus_parags_ls)\n",
        "print('\\n')\n",
        "\n",
        "parag_no_ls = range(len(corpus_parags_ls))\n",
        "len(corpus_parags_ls)\n",
        "print('\\n')\n",
        "\n",
        "corpus_parags_ls[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnJQvKkyHfVc"
      },
      "source": [
        "# Create DataFrame from list of Paragraphs extracted from Corpus\n",
        "\n",
        "corpus_parags_df = pd.DataFrame({'parag_no':parag_no_ls, 'parag_raw':corpus_parags_raw_ls, 'parag_clean':[clean_text(x) for x in corpus_parags_ls]})\n",
        "corpus_parags_df['parag_raw'] = corpus_parags_df['parag_raw'].astype('string')\n",
        "corpus_parags_df.head(2)\n",
        "corpus_parags_df.tail(2)\n",
        "corpus_parags_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOvIFAsgdgK2"
      },
      "source": [
        "corpus_parags_df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrQ4YmkK6HrH"
      },
      "source": [
        "# For each Paragraph, compute the start, mid and end Sentence Number\n",
        "\n",
        "# NOTE: ~5 minutes runtime\n",
        "\n",
        "# NOTE: May fail on any paragraph/sentence with dirty text and require\n",
        "#       multiple iterations of fix/run cycles\n",
        "\n",
        "# Used raw paragraph data to update Master Corpus DataFrame with Paragraph Info\n",
        "\n",
        "# Filter out all the structural/metatag and blank/punctuation only lines\n",
        "#    and save all semantically meaningful Sentences in corpus_sents_ls\n",
        "\n",
        "corpus_sents2parag_ls = []\n",
        "corpus_sents2parag_reject_ls = []\n",
        "parag_sents_tup_ls = []\n",
        "sent_no_current = 0\n",
        "\n",
        "parag_no_current = 0\n",
        "sent_no_current = 0\n",
        "\n",
        "flag_previous_miss = False\n",
        "\n",
        "corpus_parag_ct = len(corpus_parags_ls)\n",
        "\n",
        "def get_sent2paragno(asent_no, asent_raw_str):\n",
        "  '''\n",
        "  Given a sent_no and sent_raw_str\n",
        "  Search and return the corresponding parag_no that contains the sent_raw_str\n",
        "      (return -1 if not found)\n",
        "  '''\n",
        "\n",
        "  global parag_no_current\n",
        "  global flag_previous_miss\n",
        "  # NOTE: Dependencies on local vars outside this def and global vars corpus_parags_ls\n",
        "  # global parag_no_current\n",
        "\n",
        "  # Loop over every paragraph until we find matching sentence (or fail)\n",
        "  while parag_no_current < corpus_parag_ct:\n",
        "\n",
        "    print(f'Sentence #{asent_no}, Text: {asent_raw_str}')\n",
        "    print(f'    Starting search at Paragraph #{parag_no_current}')\n",
        "    print(f'    Paragraph Text:\\n    {corpus_parags_ls[parag_no_current]}')\n",
        "    parag_str = corpus_parags_ls[parag_no_current]\n",
        "\n",
        "    # Search for Sentence string in current Paragraph string\n",
        "    # if re.search(asent_raw_str, re.escape(parag_str)):\n",
        "    # problems with embedded parenthesis\n",
        "    # noparen_table = str.maketrans({'(':' ', ')':' ', '[':' ', ']':' ', '?':' ', '\"':' ', \"'\":\" \"})\n",
        "    # asent_noparens_str = asent_raw_str.translate(noparen_table)\n",
        "    # parag_noparens_str = parag_str.translate(noparen_table)\n",
        "    asent_noparens_str = re.sub('[^0-9a-zA-Z]+', ' ', asent_raw_str)\n",
        "    parag_noparens_str = re.sub('[^0-9a-zA-Z]+', ' ', parag_str)\n",
        "\n",
        "    if re.search(asent_noparens_str, parag_noparens_str):\n",
        "      print(f'    Found it!')\n",
        "      flag_previous_miss = False\n",
        "      return parag_no_current\n",
        "    else:\n",
        "      if flag_previous_miss == True:\n",
        "        # Sentence not found in 2 consecutive Paragraphs, skip this Sentence\n",
        "        print(f'    Miss: Skip this Sentence and go set current paragraph back 1')\n",
        "        parag_no_current -= 1\n",
        "        flag_previous_miss = False\n",
        "        return -1\n",
        "      else:\n",
        "        # Sentence not found in current Paragraph, so try next one\n",
        "        print(f'     Miss: Sentence not found in current Paragraph, try next one')\n",
        "        parag_no_current += 1\n",
        "        flag_previous_miss = True\n",
        "\n",
        "\n",
        "  # At this point we searched both the current and next Paragraphs for Sentence \n",
        "  #     without success so return error code\n",
        "  return -1 \n",
        "\n",
        "# Step through every Sentence and find the Paragraph Number it lies within\n",
        "# corpus_sents_df['parag_no'] = corpus_sents_df.apply(lambda x: get_sent2paragno(x.sent_no, x.sent_raw), axis=1)\n",
        "parag_no_last_match = 0\n",
        "for idx, row in corpus_sents_df.iterrows():\n",
        "  parag_no_current = parag_no_last_match\n",
        "  asent_no = row['sent_no']\n",
        "  asent_str = row['sent_raw']\n",
        "  print(f'idx #{idx}, sent_no: {asent_no}\\n    {asent_str}')\n",
        "  \n",
        "  asent_parag_no = get_sent2paragno(asent_no, asent_str)\n",
        "  print(f'back from searching for Sentence in all Paragraphs with result: {asent_parag_no}')\n",
        "  if asent_parag_no < 0:\n",
        "    # print(f'FAIL: Did not find current Sentence so skip to next Sentence\\n\\n')\n",
        "    corpus_sents2parag_reject_ls.append((asent_no, corpus_sents_ls[asent_no]))\n",
        "    parag_no_current = parag_no_last_match\n",
        "  else:\n",
        "    # print(f'SUCCESS: Sentence #{asent_no} found in Paragraph #{asent_parag_no}\\n\\n')\n",
        "    corpus_sents2parag_ls.append((asent_no, asent_parag_no))\n",
        "    parag_no_last_match = parag_no_current\n",
        "\n",
        "  # if idx > 20:\n",
        "  #   break\n",
        "\n",
        "# Test\n",
        "\"\"\"\n",
        "print(f'Raw Lines length: {len(corpus_lines_ls)}')\n",
        "print(f' Clean Sentences: {len(corpus_sents_ls)}')\n",
        "\n",
        "line_ct = 10\n",
        "print(f'First {line_ct} clean Sentences : --------------------\\n')\n",
        "for i,aline in enumerate(corpus_sents_ls[:line_ct]):\n",
        "  print(f'Line #{i}:\\n    {aline}')\n",
        "print(f'\\n\\nLast {line_ct} clean Sentences: -------------------\\n')\n",
        "for i,aline in enumerate(corpus_sents_ls[-line_ct:]):\n",
        "  print(f'Line #{i}: {aline}')\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJxi6BUWqj-l"
      },
      "source": [
        "# Any Sentences not found in Corpus Paragraphs?\n",
        "#  If not empty list, manually check and edit corpus if many/significant Sentences rejected\n",
        "\n",
        "sentences_noparag_ct = len(corpus_sents2parag_reject_ls)\n",
        "\n",
        "if sentences_noparag_ct > 0:\n",
        "  print(f'\\n    WARNING: The following {sentences_noparag_ct} Sentences were NOT FOUND in any Paragraph')\n",
        "  print(f'             If these are important/numerous, go back and edit/correct source Corpus text file and rerun this notebook\\n')\n",
        "\n",
        "  for i, asent in enumerate(corpus_sents2parag_reject_ls):\n",
        "    print(f'    #{i}: {asent}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9FrWNj80PkD"
      },
      "source": [
        "corpus_sents_df.iloc[200]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UAnLu0k1PAr"
      },
      "source": [
        "corpus_sents_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGqcTKBtF4QU"
      },
      "source": [
        "# Create a list of the Sentence Nos associated with each Paragraph in the Corpus\n",
        "\n",
        "sent_parag_no_ls = [sentnoparagno_tp[1] for sentnoparagno_tp in corpus_sents2parag_ls]\n",
        "\n",
        "corpus_sent_ct = corpus_sents_df.shape[0]\n",
        "parags_sent_ct = len(sent_parag_no_ls)\n",
        "if (corpus_sent_ct == parags_sent_ct):\n",
        "  print(f'GOOD, all {corpus_sent_ct} Sentences were matched in one of the {corpus_parags_df.shape[0]} Paragraphs\\n')\n",
        "else:\n",
        "  print(f'WARNING: only {parags_sent_ct} Sentences were matched in one of the {corpus_parags_df.shape[0]} Paragraphs')\n",
        "  print(f'         {corpus_sent_ct - parags_sent_ct} Sentences were not matched\\n')\n",
        "\n",
        "print(f'First 10 Sentences belong to these Paragraph:\\n    {sent_parag_no_ls[:10]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7-1oBkJKeJH"
      },
      "source": [
        "# Verfiy the data about to be used to update the master corpus_all_df DataFrame with Paragraph No data\n",
        "\n",
        "corpus_sents2parag_ls[3233:3237]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2vZk07BkeNw"
      },
      "source": [
        "# corpus_all_df.drop(columns=['parag_no'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29tMZKR4KERa"
      },
      "source": [
        "# Update the master corpus_all_df DataFrame with Paragraph No for each Sentence\n",
        "\n",
        "# WARNING: Only execute once (insert Column/Series into DataFrame)\n",
        "\n",
        "parag_no_ser = pd.Series(parag_no_ls)\n",
        "corpus_sents_df.insert(loc=1, column='parag_no', value=sent_parag_no_ls)\n",
        "\n",
        "corpus_sents_df.head(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsOgtjM71eKE"
      },
      "source": [
        "corpus_sents_df.iloc[300:320]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tK5kKZbVl3jR"
      },
      "source": [
        "# corpus_parags_df.drop(columns=['sent_no_start', 'sent_no_mid','sent_no_end'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmLLzsNtECDt"
      },
      "source": [
        "corpus_parags_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVkStzTrlxll"
      },
      "source": [
        "# Verify the Paragraph only DataFrame\n",
        "\n",
        "corpus_parags_df.head(2)\n",
        "corpus_parags_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkHIEWqEKz66"
      },
      "source": [
        "# Calculate the start, mid and end Sentence No for each Paragraph\n",
        "\n",
        "parag_sent_no_start_ls = np.array(corpus_sents_df.groupby('parag_no')['sent_no'].min())\n",
        "parag_sent_no_end_ls = np.array(corpus_sents_df.groupby('parag_no')['sent_no'].max())\n",
        "\n",
        "def my_mid(anum, bnum):\n",
        "  mid_no = (anum - bnum)//2 + bnum\n",
        "\n",
        "  return mid_no\n",
        "\n",
        "print('\\nParagraph Start Sentence no: -----')\n",
        "print(parag_sent_no_start_ls)\n",
        "\n",
        "parag_sent_no_mid_ls = list(map(my_mid, parag_sent_no_end_ls, parag_sent_no_start_ls))\n",
        "print('\\nParagraph Mid-Sentence no: -----')\n",
        "print(parag_sent_no_mid_ls)\n",
        "\n",
        "print('\\nParagraph End Sentence no: -----')\n",
        "print(parag_sent_no_end_ls)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbSi16c1Kz6_"
      },
      "source": [
        "# If necessary, delete prior columns to update DataFrame with new data\n",
        "\n",
        "# corpus_parags_df.drop(columns=['parag_no_start'], inplace=True)\n",
        "# corpus_parags_df.drop(columns=['parag_no_mid'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkdeR-S_Kz7B"
      },
      "source": [
        "# Insert 3 new columns on start,mid and end Sentence No for each Paragraph\n",
        "\n",
        "corpus_parags_df.insert(1, 'sent_no_start', parag_sent_no_start_ls)\n",
        "corpus_parags_df.insert(2, 'sent_no_mid', parag_sent_no_mid_ls)\n",
        "corpus_parags_df.insert(3, 'sent_no_end', parag_sent_no_end_ls)\n",
        "\n",
        "corpus_parags_df.head()\n",
        "                       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9uIWYnCLSr7"
      },
      "source": [
        "# Create a clean text version of each Paragraph\n",
        "\n",
        "# corpus_parags_df = pd.DataFrame({'parag_no':parag_no_ls, 'parag_raw':corpus_parags_ls})\n",
        "corpus_parags_df['parag_clean'] = corpus_parags_df['parag_raw'].apply(lambda x: clean_text(x))\n",
        "corpus_parags_df['parag_clean'] = corpus_parags_df['parag_clean'].astype('string')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gza5pqW3LSsF"
      },
      "source": [
        "# Compute Paragraph text Statistics\n",
        "\n",
        "corpus_parags_df['token_len'] = corpus_parags_df['parag_clean'].apply(lambda x: len(x.split()))\n",
        "corpus_parags_df['char_len'] = corpus_parags_df['parag_raw'].apply(lambda x: len(x))\n",
        "corpus_parags_df.head(2)\n",
        "corpus_parags_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOjESpbc6Izc"
      },
      "source": [
        "#### **Create Section DataFrame: [corpus_sects_df]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vITL5uo1ABR"
      },
      "source": [
        "# If Corpus has Sections, read Corpus and split into raw Sections\n",
        "#   else just copy Chapter data as pseudo Sections\n",
        "\n",
        "corpus_sects_ls = []    # List of all Section Numbers\n",
        "sent_sectno_ls = []     # Section Number for EVERY Matching Sentence in Corpus found in a Section\n",
        "sent_no_sectno_ls = []  # Sentence Number for for ANY Unmatched Sentence in Corpus NOT found in any Section\n",
        "\n",
        "\n",
        "if SECTION_HEADINGS == 'None':\n",
        "  # Just copy Chapter info\n",
        "  corpus_sects_ls = [x for x in corpus_chaps_ls]\n",
        "  print(f'No Sections in {CORPUS_FULL},\\n    so using Chapters as pseudo-Sections.')\n",
        "  sent_sectno_ls = sent_chap_no_ls # Every Sentence in Corpus belongs to the same SectionNo as CorpusNo\n",
        "\n",
        "else:\n",
        "\n",
        "  # Read corpus into a single string then split into raw Section\n",
        "\n",
        "  corpus_sects_ls, sent_sectno_ls, sent_no_sectno_ls = corpus2sects(CORPUS_FILENAME)\n",
        "  print(f'Found #{len(sent_sectno_ls)} Section\\n')\n",
        "\n",
        "  print('\\nThe first 5 Section of the Corpus (first 10 chars):')\n",
        "  print('-----------------------------------\\n')\n",
        "  sent_sectno_ls[:5][:10]\n",
        "  print('\\n')\n",
        "  print('\\n\\nThe last 5 Section of the Corpus (first 10 chars):')\n",
        "  print('-----------------------------------\\n')\n",
        "  sent_sectno_ls[-5:][:10]\n",
        "  print('\\n')\n",
        "\n",
        "  n_shortest = 10\n",
        "  print(f'The {n_shortest} shortest Section in the Corpus are:')\n",
        "  print('--------------------------------------------')\n",
        "  temp_sects_ls = sorted(sent_sectno_ls, key=lambda x: (len(x), x))\n",
        "  for i, asent in enumerate(temp_sects_ls[:n_shortest]):\n",
        "    print(f'Shortest Section #{i}: {asent}')\n",
        "\n",
        "\n",
        "  # Calculate Section Informationif SECTION_HEADINGS != 'None':\n",
        "  # encoding = 'windows-1252', 'utf-8', 'cp1252', 'iso-8859-1'\n",
        "  # with open(corpus_filename, \"r\", encoding='cp1252') as infp:\n",
        "  # with open(corpus_filename, \"r\", encoding='cp1252') as infp:\n",
        "  # with open(corpus_filename, \"r\", encoding='cp1252') as infp:\n",
        "\n",
        "  \"\"\"\n",
        "  with open(corpus_filename, \"r\", encoding='utf-8') as infp:\n",
        "    corpus_raw_str = infp.read()\n",
        "\n",
        "  len(corpus_raw_str)\n",
        "\n",
        "  # Extract and process Sections from Corpus\n",
        "  corpus_sects_ls, corpus_str_raw = corpus2sects(corpus_filename)\n",
        "\n",
        "  print('\\n\\nAFTER ----------')\n",
        "  print(f'len(corpus_raw_str): {len(corpus_raw_str)}')\n",
        "  print(\"\\n\\n-----\")\n",
        "  print(f'len(corpus_sects_ls): {len(corpus_sects_ls)}\\n\\n')\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  print(\"\\n\\n-----\")\n",
        "  print(f'corpus_sects_ls[0]:\\n\\n    {corpus_sects_ls[0]}')\n",
        "  print(\"\\n\\n-----\")\n",
        "  print(f'corpus_sects_ls[1]:\\n\\n    {corpus_sects_ls[1]}')\n",
        "  print(\"\\n\\n-----\")\n",
        "  print(f'corpus_sects_ls[2]:\\n\\n    {corpus_sects_ls[2]}')\n",
        "  print(\"\\n\\n-----\")\n",
        "  print(f'corpus_sects_ls[-2]:\\n\\n    {corpus_sects_ls[-2]}')\n",
        "  print(\"\\n\\n-----\")\n",
        "  print(f'corpus_sects_ls[-1]:\\n\\n    {corpus_sects_ls[-1]}')\n",
        "  \"\"\";\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1MJfVfpKOU-"
      },
      "source": [
        "# Create a list of the Sentence Nos associated with each Section in the Corpus\n",
        "\n",
        "# sent_chap_no_ls = [sentnochapno_tp[1] for sentnochapno_tp in corpus_sents2chap_ls]\n",
        "\n",
        "corpus_sent_ct = corpus_sents_df.shape[0]\n",
        "sect_sent_ct = len(sent_sectno_ls)\n",
        "if (corpus_sent_ct == sect_sent_ct):\n",
        "  print(f'GOOD, all {corpus_sent_ct} Sentences were matched in one of the {corpus_sects_df.shape[0]} Sections\\n')\n",
        "else:\n",
        "  print(f'WARNING: only {sect_sent_ct} Sentences were matched in one of the {corpus_sects_df.shape[0]} Sections')\n",
        "  print(f'         {corpus_sent_ct - sect_sent_ct} Sentences were not matched\\n')\n",
        "\n",
        "\n",
        "# print(f'There are {corpus_sents_df.shape[0]} Sentences in the Corpus')\n",
        "# print(f'{len(sent_chap_no_ls)} Sentences have been associated with {corpus_chaps_df.shape[0]} Sections\\n')\n",
        "\n",
        "print(f'First 10 Sentences belong to these Sections:\\n    {sent_sectno_ls[:10]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqKwpPs9JC0R"
      },
      "source": [
        "# Verify Sections found and Sentence-Section matches\n",
        "\n",
        "print(f'{len(corpus_sects_ls)} Sections found in Corpus')\n",
        "print(f'{len(sent_sectno_ls)} Sentences found in a Section')\n",
        "\n",
        "sentences_nosection_ct = len(sent_no_sectno_ls)\n",
        "\n",
        "if (sentences_nosection_ct > 0):\n",
        "  print(f'\\n    WARNING: The following {sentences_nosection_ct} Sentences were NOT FOUND in any Section')\n",
        "  print(f'             If these are important/numerous, go back and edit/correct source Corpus text file and rerun this notebook\\n')\n",
        "\n",
        "  for i, asent in enumerate(sentences_nosection_ls):\n",
        "    print(f'    #{i}: {asent}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JFQTmEgK66I"
      },
      "source": [
        "# Create DataFrame from list of Sections extracted from Corpus\n",
        "\n",
        "sect_no_ls = list(range(len(corpus_sects_ls)))\n",
        "corpus_sects_df = pd.DataFrame({'sect_no':sect_no_ls, 'sect_raw':corpus_sects_ls})\n",
        "corpus_sects_df['sect_raw'] = corpus_sects_df['sect_raw'].astype('string')\n",
        "corpus_sects_df.head(1)\n",
        "corpus_sects_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjN6omWrifWm"
      },
      "source": [
        "# Create a list of the Sentence Nos associated with each Section in the Corpus\n",
        "\n",
        "# sentno_sectno_ls = [sentno2sectno_tp[0] for sentno2sectno_tp in sentences_section_ls]\n",
        "# sentstr_sectno_ls = [sentno2sectno_tp[1] for sentno2sectno_tp in sentences_section_ls]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KM-JEKECfSa"
      },
      "source": [
        "# corpus_sents_df.drop(columns=['sect_no'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpAlcbpQru0t"
      },
      "source": [
        "# Add Section No for each Sentence in Master DataFrame corpus_all_df\n",
        "# ONLY RUN THIS CODE CELL ONCE\n",
        "\n",
        "# Test if already exists, if not execute\n",
        "corpus_sents_df.insert(3, 'sect_no', sent_sectno_ls)  # This can only be run once\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "353_Nn7pM1FX"
      },
      "source": [
        "# Verify\n",
        "\n",
        "corpus_sents_df.head(2)\n",
        "corpus_sents_df.tail(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpE0UiORYZy6"
      },
      "source": [
        "# Verfiy correct Section Nos using the Sentence No boundaries found in previous code cell\n",
        "#   Search for iloc index ranges containing 1 or more Section boundaries to check correctness\n",
        "\n",
        "corpus_sents_df.iloc[300:500]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVNIhlQpNZiV"
      },
      "source": [
        "corpus_sects_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yG53MVwkNHB"
      },
      "source": [
        "# Calculate the start, mid and end Sentence No for each Section\n",
        "\n",
        "sect_sent_no_start_ls = np.array(corpus_sents_df.groupby('sect_no')['sent_no'].min())\n",
        "sect_sent_no_end_ls = np.array(corpus_sents_df.groupby('sect_no')['sent_no'].max())\n",
        "\n",
        "def my_mid(anum, bnum):\n",
        "  mid_no = (anum - bnum)//2 + bnum\n",
        "\n",
        "  return mid_no\n",
        "\n",
        "print('\\nSection start sentence no: -----')\n",
        "print(sect_sent_no_start_ls)\n",
        "\n",
        "sect_sent_no_mid_ls = list(map(my_mid, sect_sent_no_end_ls, sect_sent_no_start_ls))\n",
        "print('\\nSection mid-sentence no: -----')\n",
        "print(sect_sent_no_mid_ls)\n",
        "\n",
        "print('\\nSection end sentence no: -----')\n",
        "print(sect_sent_no_end_ls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUofWkm0kNHC"
      },
      "source": [
        "# If necessary, delete prior columns to update DataFrame with new data\n",
        "\n",
        "# corpus_chaps_df.drop(columns=['parag_no_start'], inplace=True)\n",
        "# corpus_chaps_df.drop(columns=['parag_no_mid'], inplace=True)\n",
        "# corpus_chaps_df.drop(columns=['parag_no_end'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HxCqi2XkNHC"
      },
      "source": [
        "# Verify DataFrame before update\n",
        "\n",
        "corpus_sects_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhfgZuiPkNHD"
      },
      "source": [
        "# Insert 3 new columns on start,mid and end Sentence No for each Section\n",
        "\n",
        "corpus_sects_df.insert(1, 'sent_no_start', sect_sent_no_start_ls)\n",
        "corpus_sects_df.insert(2, 'sent_no_mid', sect_sent_no_mid_ls)\n",
        "corpus_sects_df.insert(3, 'sent_no_end', sect_sent_no_end_ls)\n",
        "\n",
        "corpus_sects_df.loc[:, corpus_sects_df.columns != 'sect_raw']\n",
        "# corpus_sects_df.loc[:, ['sect_no', 'sect_no_start', 'sect_no_mid', 'sect_no_end']]\n",
        "corpus_sects_df.info()\n",
        "\n",
        "                       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iObHkdhmkNHF"
      },
      "source": [
        "# Create a clean text version of each Paragraph\n",
        "\n",
        "corpus_sects_df['sect_clean'] = corpus_sects_df['sect_raw'].apply(lambda x: clean_text(x))\n",
        "corpus_sects_df['sect_clean'] = corpus_sects_df['sect_clean'].astype('string')\n",
        "\n",
        "# corpus_sects_df.loc[:, corpus_sects_df.columns != 'sect_raw']\n",
        "corpus_sects_df.filter(like='_no')\n",
        "# corpus_sects_df.loc[:, ['sect_no', 'sect_no_start', 'sect_no_mid', 'sect_no_end']]\n",
        "corpus_sects_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFDwD6M-kNHH"
      },
      "source": [
        "# Compute Paragraph text Statistics\n",
        "\n",
        "corpus_sects_df['token_len'] = corpus_sects_df['sect_clean'].apply(lambda x: len(x.split()))\n",
        "corpus_sects_df['char_len'] = corpus_sects_df['sect_raw'].apply(lambda x: len(x))\n",
        "corpus_sects_df.loc[:, list(set(corpus_sects_df.columns) - set(['sect_raw', 'sect_clean']))]\n",
        "corpus_sects_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SdZ4e3ALYdD"
      },
      "source": [
        "### **Add Descriptive Statistics and Clean Raw Text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWu8_C6PQ4iE"
      },
      "source": [
        "corpus_sents_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7au9Zy2kR0NK"
      },
      "source": [
        "# TODO: Verfiy and eal with any NaN entries\n",
        "#   all Sentences with NaN or '' Raw Text\n",
        "\"\"\"\n",
        "\n",
        "# Sentences\n",
        "# Let's take a look at the updated text\n",
        "corpus_sents_df['sent_clean'] = corpus_sents_df['sent_raw'].apply(lambda x: text_clean(x))\n",
        "# Ensure to drop all Sentences with NaN or '' Raw Textcorpus_sents_df.replace(\"\", np.nan, regex=True, inplace=True)\n",
        "corpus_sents_df.dropna(how='any', axis=0, subset=['sent_raw'], inplace=True)\n",
        "corpus_sents_df.dropna(how='any', axis=0, subset=['sent_clean'], inplace=True)\n",
        "\n",
        "print('\\nCompare Raw and Cleaned Sentences:')\n",
        "print('--------------------------------------')\n",
        "corpus_sents_df.head(2)\n",
        "\n",
        "\n",
        "# Paragraphs\n",
        "# Let's take a look at the updated text\n",
        "corpus_parags_df['parag_clean'] = corpus_parags_df['parag_raw'].apply(lambda x: text_clean(x))\n",
        "# Ensure to drop all Sentences with NaN or '' Raw Text\n",
        "corpus_parags_df.replace(\"\", np.nan, regex=True, inplace=True)\n",
        "corpus_parags_df.dropna(how='any', axis=0, subset=['parag_raw'], inplace=True)\n",
        "\n",
        "print('\\nCompare Raw and Cleaned Paragraphs:')\n",
        "print('--------------------------------------')\n",
        "corpus_parags_df.head(2)\n",
        "\n",
        "\n",
        "# Sections\n",
        "# Let's take a look at the updated text\n",
        "corpus_sects_df['sect_clean'] = corpus_sects_df['sect_raw'].apply(lambda x: text_clean(x))\n",
        "# Ensure to drop all Sentences with NaN or '' Raw Text\n",
        "corpus_sects_df.replace(\"\", np.nan, regex=True, inplace=True)\n",
        "corpus_sects_df.dropna(how='any', axis=0, subset=['sect_raw'], inplace=True)\n",
        "\n",
        "print('\\nCompare Raw and Cleaned Sections:')\n",
        "print('--------------------------------------')\n",
        "# corpus_sects_df.head(2)\n",
        "\n",
        "\n",
        "# Chapters\n",
        "# Let's take a look at the updated text\n",
        "corpus_chaps_df['chap_clean'] = corpus_chaps_df['chap_raw'].apply(lambda x: text_clean(x))\n",
        "# Ensure to drop all Chapters with NaN or '' Raw Text\n",
        "corpus_chaps_df.replace(\"\", np.nan, regex=True, inplace=True)\n",
        "corpus_chaps_df.dropna(how='any', axis=0, subset=['chap_raw'], inplace=True)\n",
        "\n",
        "print('\\nCompare Raw and Cleaned Chapters:')\n",
        "print('--------------------------------------')\n",
        "# corpus_sects_df.head(2)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf99apfwKPAO"
      },
      "source": [
        "# Verify shapes of all 4 Baseline 4 Models\n",
        "\n",
        "print(f'corpus_sents_df.shape: {corpus_sents_df.shape}')\n",
        "print(f'corpus_parags_df.shape: {corpus_parags_df.shape}')\n",
        "print(f'corpus_sects_df.shape: {corpus_sects_df.shape}')\n",
        "print(f'corpus_chaps_df.shape: {corpus_chaps_df.shape}')\n",
        "\n",
        "\"\"\"\n",
        "SButler Odyssey\n",
        "\n",
        "corpus_sents_df.shape: (2445, 8)\n",
        "corpus_parags_df.shape: (1051, 8)\n",
        "corpus_sects_df.shape: (24, 8)\n",
        "corpus_chaps_df.shape: (24, 8)\n",
        "\"\"\";\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHscLkclSYqN"
      },
      "source": [
        "##**Save Preprocess Corpus DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEzo8eltSvWS"
      },
      "source": [
        "# Save Corpus DataFrames\n",
        "\n",
        "save_dataframes()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL8R_ANtfYG6"
      },
      "source": [
        "# (Optional) EDA Raw Text Features: Interactive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1njcRD-jgGJh"
      },
      "source": [
        "**(Optional) Can Skip Ahead to: 'EDA of Raw Text and Extracted Features'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ti9jQK7grxO"
      },
      "source": [
        "# Review Cleaned Up Sentences\n",
        "\n",
        "corpus_sents_df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TN5ksy55kXy"
      },
      "source": [
        "# Summary Statistics\n",
        "\n",
        "corpus_sents_df.describe()\n",
        "corpus_sents_df['token_len'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxvxkbUGzkfy"
      },
      "source": [
        "# Create histogram of Paragraph lengths\n",
        "\n",
        "sns.histplot(data=corpus_sents_df['char_len'], kde=True).set_title(f'{CORPUS_FULL} \\n Histogram of Paragraph Lengths');\n",
        "\n",
        "if (PLOT_OUTPUT == 'All'):\n",
        "  # Save graph to file.\n",
        "  plot_filename = 'hist_paraglen.png'\n",
        "  plotpathfilename_str = gen_pathfiletime(plot_filename)\n",
        "  plt.savefig(plotpathfilename_str, format='png', dpi=300)\n",
        "  print(f'Plot saved: {plot_filename}');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqUtGz8UjY2b"
      },
      "source": [
        "# Plot histogram of Sentence lengths\n",
        "\n",
        "sns.histplot(data=corpus_sents_df['token_len'], kde=True).set_title(f'{CORPUS_FULL} \\n Histogram of Sentence Lengths')\n",
        "\n",
        "if (PLOT_OUTPUT == 'All'):\n",
        "  # Save graph to file.\n",
        "  plot_filename = 'hist_sentlen.png'\n",
        "  plotpathfilename_str = gen_pathfiletime(plot_filename)\n",
        "  plt.savefig(plotpathfilename_str, format='png', dpi=300)\n",
        "  print(f'Plot saved: {plot_filename}');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OoBrucYR9Xc"
      },
      "source": [
        "# SELECT CORPUS TYPE\n",
        "# TODO: Customized Preprocessing (e.g. Tweets) by Corpus Type\n",
        "\n",
        "# Novel, Tweets, Chat Transcript\n",
        "\n",
        "# Processing Options\n",
        "\n",
        "# Apply first level cleaning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2tIua7tTSRz"
      },
      "source": [
        "# (Optional) Manually Create Sentiment Arc Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dU11XOZIPalR"
      },
      "source": [
        "***Can skip to Section [Load Sentiment Polarities...] or [Calculate VADER...]***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cke3OowdWk6I"
      },
      "source": [
        "**Interactively Enter Cruxes and Edge Cases**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv7Foe3oTMmz"
      },
      "source": [
        "# Setup data structures for endpoints of Sentiment Time Series\n",
        "\n",
        "#   [-1.0 to +1.0] = [v.neg, neg, neutral, pos, v.pos]\n",
        "\n",
        "corpus_man_crux_ols = []  # working datastructure to dynamically build ordered list of manually selected Crux Points\n",
        "corpus_man_cruxes_odt = OrderedDict() # Once all manual Crux points selected, this will be working data structure\n",
        "\n",
        "corpus_sents_len = corpus_sents_df.shape[0] - 1\n",
        "\n",
        "corpus_parags_len = corpus_sents_df.parag_no.max() # make sure no omissions/repeats/skips\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-_ylgiAc6Aw"
      },
      "source": [
        "# <INPUT> Set the Begining and Ending Sentiment Values (Manual Versions)\n",
        "\n",
        "# Start of Corpus Sentiment Analysis Time Series\n",
        "Corpus_Starting_Sentiment = -0.1 #@param {type:\"slider\", min:-1, max:1, step:0.1}\n",
        "# corpus_sa_begin = Corpus_Starting_Sentiment\n",
        "\n",
        "# End of Corpus Sentiment Analysis Time Series\n",
        "Corpus_Ending_Sentiment = -1 #@param {type:\"slider\", min:-1, max:1, step:0.1}\n",
        "# corpus_sa_end = Corpus_Ending_Sentiment\n",
        "\n",
        "corpus_man_crux_ols = [tuple((0, Corpus_Starting_Sentiment)), tuple((corpus_sents_len, Corpus_Ending_Sentiment))]\n",
        "# corpus_man_cruxes_dt[0.] = corpus_sa_begin\n",
        "# corpus_man_cruxes_dt[float(corpus_sents_len)] = corpus_sa_end\n",
        "\n",
        "print(f'Manual Cruxes with Start/End: {corpus_man_crux_ols}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmcLrzyUw93d"
      },
      "source": [
        "**Seach for Key Words that suggest Min/Max Sentiment Crux**\n",
        "* Specific to the Novel: Introduction of Pivotal Character, Scene, Factual Reveal, McGuffin, etc...\n",
        "* General to Events/Themes: Death, Birth, Fight, Accident, Money, Sex, etc... "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UESgwwIAY28T"
      },
      "source": [
        "# <INPUT> Search Corpus for Line No of Peaks/Valleys\n",
        "# TODO: Better Vis\n",
        "Search_String = \"Death\" #@param {type:\"string\"}\n",
        "if (Search_String == \"\"):\n",
        "  search_str = \"accident\"\n",
        "else:\n",
        "  search_str = Search_String.lower()\n",
        "\n",
        "# search the list of cleaned paragraphs\n",
        "# results_ls = [x for x in search_match_ls if re.search(subs, x)]\n",
        "\n",
        "# creating and passsing series to new column\n",
        "match_sents_ser = corpus_sents_df[\"sent_clean\"].str.find(search_str)\n",
        "\n",
        "# print(f'Found #{len(match_index>0)} Matches')\n",
        "match_sents_df = corpus_sents_df.loc[match_sents_ser > 0]\n",
        "print(f'Found #{match_sents_df.shape[0]} Matching Sentences')\n",
        "print('------------------------------------')\n",
        "# print(f'  {match_sents_df}')\n",
        "match_sents_df[['sent_no', 'parag_no', 'sent_raw', 'token_len']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oVYBfz6-EVo"
      },
      "source": [
        "**Get Context for Matched Sentence by Retrieving Surrounding Paragraph**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AvYQqT5TsdV"
      },
      "source": [
        "# Extract Surrounding Paragraphs for context on matching Sentences\n",
        "\n",
        "def get_parag4sentno(asent_no):\n",
        "  '''\n",
        "  Return the original raw paragraph containing a \n",
        "  given sentence number.\n",
        "  '''\n",
        "  # parag_df = pd.DataFrame()\n",
        "  # print(f'Passed in sent_no: {asent_no}')\n",
        "  aparag_no = int(corpus_sents_df.loc[corpus_sents_df['sent_no'] == asent_no]['parag_no'])\n",
        "  # print(f'  This sent_no {asent_no} is in parag_no: {aparag_no}')\n",
        "  aparag_str = corpus_sents_df.loc[corpus_sents_df['parag_no'] == aparag_no]['sent_raw'].str.cat() # ['sent_clean']\n",
        "  # sentno_parag_df = corpus_sents_df[corpus_sents_df['sent_no']==asent_no]\n",
        "  # print(f'Sent #{asent_no} is in the paragraph: ')\n",
        "  # print(aparag)\n",
        "  # print(f'returning aparag_no: [{aparag_no}]: {aparag}')\n",
        "  return aparag_no, aparag_str\n",
        "\n",
        "'''\n",
        "# Testing\n",
        "asent_no = 7\n",
        "print(f'Searching for paragraph containing Sentence #{asent_no}')\n",
        "\n",
        "aparag_no, aparag_str = get_parag4sentno(asent_no)\n",
        "print(f'\\n  Found in Paragraph #{aparag_no} \\n\\n{aparag_str}')\n",
        "''';"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnHz08NyDroK"
      },
      "source": [
        "# Extract Surrounding Paragraphs for context on matching Sentences\n",
        "\n",
        "def get_parag_str(aparag_no):\n",
        "  '''\n",
        "  Return the original raw paragraph containing a \n",
        "  given sentence number.\n",
        "  '''\n",
        "  # parag_df = pd.DataFrame()\n",
        "  # print(f'Passed in sent_no: {asent_no}')\n",
        "  # aparag_no = int(corpus_sents_df.loc[corpus_sents_df['sent_no'] == asent_no]['parag_no'])\n",
        "  # print(f'  This sent_no {asent_no} is in parag_no: {aparag_no}')\n",
        "  aparag_str = corpus_sents_df.loc[corpus_sents_df['parag_no'] == aparag_no]['sent_raw'].str.cat() # ['sent_clean']\n",
        "  # sentno_parag_df = corpus_sents_df[corpus_sents_df['sent_no']==asent_no]\n",
        "  # print(f'Sent #{asent_no} is in the paragraph: ')\n",
        "  # print(aparag)\n",
        "  # print(f'returning aparag_no: [{aparag_no}]: {aparag}')\n",
        "  return aparag_str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByKLYZDsK123"
      },
      "source": [
        "# Summarize current status of manually selected Crux Points\n",
        "# TODO:\n",
        "\n",
        "def crux_sum_short():\n",
        "  print(f'\\nOrdered list of all manually selected Crux Points')\n",
        "  print('---------------------------------------')\n",
        "  for i, acrux_tp in enumerate(corpus_man_crux_ols):\n",
        "    asent_no, asent_pol = acrux_tp\n",
        "    asent_str = corpus_sents_df[corpus_sents_df.sent_no==asent_no].sent_raw.str.cat()\n",
        "    # print(f'Type: {type(asent_str)}')\n",
        "    print(f'Sent No {asent_no:4d}: Polarity: {asent_pol}\\nText: {asent_str}\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz0FLzt2UeSe"
      },
      "source": [
        "# Summarize current manually selected Crux Points\n",
        "\n",
        "def crux_summary():\n",
        "  print(f'\\nOrdered list of all manually selected Crux Points')\n",
        "  print('---------------------------------------\\n\\n')\n",
        "  for i, acrux_tp in enumerate(corpus_man_crux_ols):\n",
        "    asent_no, asent_pol = acrux_tp\n",
        "    asent_str = corpus_sents_df[corpus_sents_df.sent_no==asent_no].sent_raw.str.cat()\n",
        "    # print(f'Type: {type(asent_str)}')\n",
        "    print(f'Sent No {asent_no:4d}: Polarity: {asent_pol}')\n",
        "    print('------------------------------')\n",
        "    print(f'Text: {asent_str}\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiUmseNw3CkN"
      },
      "source": [
        "# View the Paragraph containing your Matching Sentence:\n",
        "\n",
        "def get_nparags_context(crux_sent_no, parag_ct):\n",
        "\n",
        "  parag_win = int(parag_ct)\n",
        "  parag_crux_str = ''\n",
        "\n",
        "  parag_crux_no = 0\n",
        "\n",
        "  if (crux_sent_no < 0) | (crux_sent_no > corpus_sents_len):\n",
        "    print(f'ERROR: Pick a Sentence No between 0-{corpus_sents_len-1}')\n",
        "  else:\n",
        "    # get_sent_no = crux_sent_no\n",
        "    # print(f'Retrieving Sentence No: {get_sent_no}')\n",
        "    # print('----------')\n",
        "\n",
        "    parag_crux_no, aparag_str = get_parag4sentno(crux_sent_no)\n",
        "    if parag_win == 1:\n",
        "      print(f'Match #{i}: Sentence No. {asent_no} found in Paragraph No. {parag_crux_no}')\n",
        "      print('----------------------------')\n",
        "      print(f'Sentence:\\n')\n",
        "      # print(f'     {corpus_sents_df[corpus_sents_df.sent_no == crux_sent_no]}\\n\\n')\n",
        "      corpus_sents_df[corpus_sents_df.sent_no == crux_sent_no]\n",
        "      print('----------------------------')\n",
        "      print(f'Paragraph Context:\\n')\n",
        "      print(f'     {aparag_str}\\n\\n')\n",
        "    else:\n",
        "      parag_half_win = int((parag_win-1)/2)\n",
        "      parag_start = parag_crux_no - parag_half_win\n",
        "      parag_end = parag_crux_no + parag_half_win\n",
        "      print(f'Retrieving {parag_ct} Contextual Paragraphs Nos {parag_start} to {parag_end}')\n",
        "      print(f'  for Crux Point centered on Sentence No {crux_sent_no}')\n",
        "      for i in range(parag_start, parag_end + 1, 1):\n",
        "        if i == parag_crux_no:\n",
        "          print(f'\\n   ---------------------------------------------------------')\n",
        "          print(f'** Crux Point Paragraph #{i} with Sentence No. {crux_sent_no} **')\n",
        "          print(f'   ---------------------------------------------------------')\n",
        "          parag_crux_str = get_parag_str(i)\n",
        "          print(parag_crux_str)\n",
        "        else:\n",
        "          print(f'\\n   ----------------------')\n",
        "          print(f'   Regular Paragraph #{i}')\n",
        "          print(f'   ----------------------')\n",
        "          print(get_parag_str(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjoXC8Fg3lBP"
      },
      "source": [
        "# Insert new crux point into ordered list: corpus_man_crux_ls\n",
        "\n",
        "# NOTE: For very long lists, use Python simple bisect library (at cost of additional dependency)\n",
        "\n",
        "\n",
        "def insert_ord_tp_list(crux_ord_ols, crux_tp):\n",
        "  '''\n",
        "  Insert new crux tuple: crux_tp = (sent_no, sentiment_polarity)\n",
        "  into ordered list of tuples while maintaining sent_no order\n",
        "  '''\n",
        "  sent_no, senti_pol = crux_tp\n",
        "\n",
        "  # Searching for the position\n",
        "  for i in range(len(crux_ord_ols)):\n",
        "    if crux_ord_ols[i][0] == sent_no:\n",
        "      # Attempting to insert duplicate\n",
        "      return crux_ord_ols\n",
        "    elif crux_ord_ols[i][0] < sent_no:\n",
        "      insert_idx = i\n",
        "    else:\n",
        "      break\n",
        "      \n",
        "  # Inserting n in the list\n",
        "  list = crux_ord_ols[:i] + [crux_tp] + crux_ord_ols[i:]\n",
        "  return list\n",
        "\n",
        "'''\n",
        "# Test\n",
        "crux_test_ls = [(1,0), (5,1), (10,-1)]\n",
        "crux_test_tp = (3,10)\n",
        "  \n",
        "print(insert_ord_tp_list(crux_test_ls, crux_test_tp))\n",
        "''';"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PPOLJDZ1wHc"
      },
      "source": [
        "**Start of Human in the Loop Manual Crux Point Identification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1MLexX57Guc"
      },
      "source": [
        "# Instructions\n",
        "\n",
        "print('Enter a Sentence number based upon your search above to see the ')\n",
        "print('  surrounding Paragraph context.')\n",
        "print('----------------------------------------')\n",
        "print(f'(Enter an integer between 0 and {corpus_sents_len-1})\\n\\n')\n",
        "\n",
        "print('\\n')\n",
        "print('Enter an ODD NUMBER for the Number of surrounding Paragraphs ')\n",
        "print('  around the Sentence No to give Context.')\n",
        "print('----------------------------------------')\n",
        "print(f'(Enter an integer: 3, 5, 7\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exxWtaUPC30l"
      },
      "source": [
        "# Input your Context Retrieval Parameters\n",
        "\n",
        "Sentence_No =  2692#@param {type:\"integer\"}\n",
        "No_Paragraphs_Context = \"3\" #@param [\"1\", \"3\", \"5\"]\n",
        "\n",
        "get_nparags_context(Sentence_No, No_Paragraphs_Context)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30fBikIrrgMe"
      },
      "source": [
        "**Add Crux to Manually Generated Sentiment Arc**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgljeT6ypNbo"
      },
      "source": [
        "# Instructions to add current sentence as a Crux Point\n",
        "\n",
        "crux_summary()\n",
        "\n",
        "print('--------------------------------------------------------')\n",
        "print(f'INSTRUCTIONS To current Sentence No: {Sentence_No} as a Crux Point')\n",
        "print('--------------------------------------------------------')\n",
        "\n",
        "print(\"\\nCheck this box if you want to add the Sentence/Paragraph above \")\n",
        "print(\"  as a new Min/Max Crux Point with your approximation \")\n",
        "print(\"  for a Sentiment Polarity value between -1.0 to +1.0\\n\\n\")\n",
        "\n",
        "print(f\"Crux Sentence No: {Sentence_No} in Paragraph No: {parag_crux_no}\\n\")\n",
        "print(parag_crux_str)\n",
        "\n",
        "print(\"\\n\\nLeave Add_Sentence_Crux 'unchecked' to not add\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia1IXChRmyr3"
      },
      "source": [
        "# <INPUT> Option to add this Sentence/Paragraph as a Min/Max Crux Point\n",
        "\n",
        "Sentiment_Polarity = -0.4 #@param {type:\"slider\", min:-1, max:1, step:0.1}\n",
        "Add_Sentence_Crux = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "# Add Crux if selected and give current summary status\n",
        "\n",
        "if Add_Sentence_Crux == True:\n",
        "  crux_new_tp = tuple((Sentence_No, Sentiment_Polarity))\n",
        "  corpus_man_crux_ols = insert_ord_tp_list(corpus_man_crux_ols, crux_new_tp)\n",
        "  if (corpus_man_crux_ols):\n",
        "    print(f'Successfully inserted new Crux = {crux_new_tp}')\n",
        "    print(f'Added Crux at Sentence No={Sentence_No} with Polarity={Sentiment_Polarity}')\n",
        "    # corpus_man_cruxes_dt[Sentence_No] = Sentiment_Polarity\n",
        "  else:\n",
        "    print(f'ERROR: Could not insert new Crux = {crux_new_tp}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lps67T-lUTi2"
      },
      "source": [
        "# Summary of current Crux Points after addition\n",
        "\n",
        "print('\\n------------------------------------------------------------')\n",
        "print(f'After addition of new Crux Point (Sentence No {Sentence_No})')\n",
        "print('------------------------------------------------------------\\n')\n",
        "\n",
        "crux_summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjZT9_0CrzFk"
      },
      "source": [
        "**Delete Manually Selected Crux Points**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTX30nokNPBp"
      },
      "source": [
        "len(corpus_man_crux_ols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxS-J_hPOfkI"
      },
      "source": [
        "crux_tp = (1, 2)\n",
        "a, b = crux_tp\n",
        "print(f'a is {a} and b is {b}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bi7Cu1iErvzc"
      },
      "source": [
        "# Insert new crux point into ordered list: corpus_man_crux_ls\n",
        "\n",
        "# FIX: 20210616 and move to utility functions\n",
        "\n",
        "# NOTE: For very long lists, use Python simple bisect library (at cost of additional dependency)\n",
        "\n",
        "\n",
        "def del_ord_tp_list(acorpus_man_crux_ols, crux_tp):\n",
        "  '''\n",
        "  Insert new crux tuple: crux_tp = (sent_no, sentiment_polarity)\n",
        "  into ordered list of tuples while maintaining sent_no order\n",
        "  '''\n",
        "  crux_ct = len(acorpus_man_crux_ols)\n",
        "  sent_no = crux_tp[0]\n",
        "  print(f'Deleting sent_no: {sent_no} over crux_ls len={len(acorpus_man_crux_ols)}')\n",
        "\n",
        "  # Searching for the positionk\n",
        "  del_idx = -1\n",
        "  for i in range(len(acorpus_man_crux_ols)):\n",
        "    acrux_sent_no = acorpus_man_crux_ols[i][0]\n",
        "    print(f'Crux #{i} is sent_no={acrux_sent_no}')\n",
        "    if acrux_sent_no == sent_no:\n",
        "      print(f'Matching index at {i}')\n",
        "      del_idx = i\n",
        "      \n",
        "  # Delete n in the list\n",
        "  print(f'Deletion index = {del_idx}')\n",
        "  if del_idx == 0:\n",
        "    # Delete the first Crux\n",
        "    list = acorpus_man_crux_ols[1:]\n",
        "    return list\n",
        "  elif del_idx == crux_ct -1:\n",
        "    # Delete the last Crux\n",
        "    list = acorpus_man_crux_ols[:-1]\n",
        "    return list    \n",
        "  elif (del_idx > 0) & (del_idx < crux_ct):\n",
        "    # Delete an interior Crux\n",
        "    before_idx = i - 1\n",
        "    after_idx = i\n",
        "    list = acorpus_man_crux_ols[:before_idx] + acorpus_man_crux_ols[after_idx:]\n",
        "    print(f'Returning list: {list}')\n",
        "    return list\n",
        "  else:\n",
        "    print('No matching Crux tuple found')\n",
        "    return acorpus_man_crux_ols\n",
        "  \n",
        "\n",
        "# Test\n",
        "crux_test_ls = [(1,0), (5,1), (10,-1)]\n",
        "crux_test_tp = (5,5)\n",
        "  \n",
        "print(del_ord_tp_list(crux_test_ls, crux_test_tp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI5hZqmSLg5R"
      },
      "source": [
        "# Instructions to Delete a Crux Point\n",
        "\n",
        "crux_summary()\n",
        "\n",
        "print('--------------------------------------------------------')\n",
        "print('INSTRUCTIONS To Delete a Crux Point')\n",
        "print('--------------------------------------------------------')\n",
        "\n",
        "print(\"\\nEnter the Sentence No of a Crux you want to delete.\\n\")\n",
        "print(f'     Current Crux Points by Sentence No: {corpus_man_crux_ols}\\n\\n')\n",
        "print(\" Skip this if you want to keep all manually selected Crux Points.\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzowFY-I8U1_"
      },
      "source": [
        "# Instructions\n",
        "\n",
        "print(\"\\nEnter the Sentence No of a Crux you want to delete.\\n\")\n",
        "print(f'     Current Crux Points by Sentence No: {corpus_man_crux_ols}\\n\\n')\n",
        "print(\" Skip this if you want to keep all manually selected Crux Points.\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ShFCfOsrvsv"
      },
      "source": [
        "Delete_Sent_No =  777#@param {type:\"integer\"}\n",
        "# Select a Crux to Delete\n",
        "# TODO: Drop down list\n",
        "\n",
        "# corpus_man_crux_ols\n",
        "corpus_man_crux_temp_ols = []\n",
        "\n",
        "crux_sent_set = set([x[0] for x in corpus_man_crux_ols])\n",
        "if not(Delete_Sent_No in crux_sent_set):\n",
        "  print(f'ERROR: {Delete_Sent_No} is not a Crux Point Sentence No')\n",
        "else:\n",
        "  # Keep the same tuple format for uniformity and future features\n",
        "  crux_del_tp = tuple((Delete_Sent_No, 'dummy_sentence'))\n",
        "  print(f'Selected {(crux_del_tp)} to delete')\n",
        "  # corpus_man_crux_temp_ols = \n",
        "  print(f'WTF: {del_ord_tp_list(corpus_man_crux_ols, crux_del_tp)}')\n",
        "  corpus_man_crux_old = del_ord_tp_list(corpus_man_crux_ols, crux_del_tp)\n",
        "  print(f\"corpus_man_crux_ols: {corpus_man_crux_ols}\")\n",
        "  # get_sent_no = Sentence_No\n",
        "  # print(f'Retrieving Sentence No: {get_sent_no}')\n",
        "  # print('----------')\n",
        "  print(f'Updated Crux Points by Sentence No: {corpus_man_crux_ols}\\n\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJdNu-oYrwHv"
      },
      "source": [
        "**Review Summary of all Manually Selected Crux Points**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmpggAWuvMb1"
      },
      "source": [
        "# Generate Report Summary of All Manually Selected Cruxes\n",
        "\n",
        "f = io.StringIO()\n",
        "with contextlib.redirect_stdout(f):\n",
        "    crux_summary()\n",
        "crux_summary = f.getvalue()\n",
        "\n",
        "# Print Manual Crux Report Summary to Screen\n",
        "\n",
        "# print(crux_summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ULFfHbxwDfu"
      },
      "source": [
        "# Save Manual Crux Summary Report\n",
        "\n",
        "plot_filename = 'man_cruxes.txt'\n",
        "plotpathfilename_str = gen_pathfiletime(plot_filename)\n",
        "\n",
        "with open(plotpathfilename_str, 'a+') as outfp:\n",
        "  outfp.write(crux_summary)\n",
        "\n",
        "# Verify \n",
        "\n",
        "!ls -alt $plotpathfilename_str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG_hGPgjxY7X"
      },
      "source": [
        "# Verify Report Content\n",
        "\n",
        "!cat man_cruxes_fscottfitzgerald_thegreatgatsby_20210616214050.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zPYRKCex8-U"
      },
      "source": [
        "**Clean and Organize Manual Crux Points into new Data Structures**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YICJNt3AXI2d"
      },
      "source": [
        "print(corpus_sents_df[corpus_sents_df['sent_no']==5]['sent_raw'].squeeze())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2bLtpweWQt4"
      },
      "source": [
        "# Convert and assemble all the Crux values in lists to save in a new Crux DataFrame\n",
        "\n",
        "\n",
        "pol_val_ls = [x[1] for x in corpus_man_crux_ols]\n",
        "sent_no_ls = [x[0] for x in corpus_man_crux_ols]\n",
        "parag_no_ls = [(get_parag4sentno(x))[0] for x in sent_no_ls]\n",
        "parag_str_ls = [get_parag_str(x) for x in parag_no_ls]\n",
        "sent_no_ls = [x[0] for x in corpus_man_crux_ols]\n",
        "sent_raw_ls = [corpus_sents_df[corpus_sents_df['sent_no']==x]['sent_raw'].squeeze() for x in sent_no_ls]\n",
        "sent_raw_ls\n",
        "sent_clean_ls = [corpus_sents_df[corpus_sents_df['sent_no']==x]['sent_clean'].squeeze() for x in sent_no_ls]\n",
        "sent_clean_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFEYg7Gfbj9i"
      },
      "source": [
        "# Create a Dict of Crux Points to Tuples (Polarity, Raw Sentence)\n",
        "\n",
        "# First Create the Tuples for each Sentence No (Sentiment Polarity, Raw Text)\n",
        "def merge(list1, list2):\n",
        "    merged_list = tuple(zip(list1, list2)) \n",
        "    return merged_list\n",
        "      \n",
        "crux_tp_ls = merge(pol_val_ls, sent_raw_ls)\n",
        "\n",
        "# Second, Create the Dictionary C\n",
        "corpus_man_cruxes_dt = {sent_no_ls[i]: crux_tp_ls[i] for i in range(len(crux_tp_ls))}\n",
        "\n",
        "# Verify\n",
        "corpus_man_cruxes_dt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtIHecpMdbXa"
      },
      "source": [
        "corpus_sents_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8qmpFRaTfu2"
      },
      "source": [
        "**Plot Interpolated Manual Sentiment Arc**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8ASg7uUZWf3"
      },
      "source": [
        "corpus_man_sa_df = pd.DataFrame({'sent_no':xn, 'sentiment':yn, 'sent_raw':corpus_sents_df.sent_raw.values})\n",
        "corpus_man_sa_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36VfGi4a47Yl"
      },
      "source": [
        "# Hermite Interpolation with SciPy\n",
        "\n",
        "pol_val_ls = [x[1] for x in corpus_man_crux_ols]\n",
        "sent_no_ls = [x[0] for x in corpus_man_crux_ols]\n",
        "parag_no_ls = [(get_parag4sentno(x))[0] for x in sent_no_ls]\n",
        "parag_str_ls = [get_parag_str(x) for x in parag_no_ls]\n",
        "sent_no_ls = [x[0] for x in corpus_man_crux_ols]\n",
        "sent_raw_ls = [corpus_sents_df[corpus_sents_df['sent_no']==x]['sent_raw'].squeeze() for x in sent_no_ls]\n",
        "sent_raw_ls\n",
        "sent_clean_ls = [corpus_sents_df[corpus_sents_df['sent_no']==x]['sent_clean'].squeeze() for x in sent_no_ls]\n",
        "sent_clean_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElJKawWfZWbv"
      },
      "source": [
        "sent_no_ls\n",
        "pol_val_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xufA403s3lbF"
      },
      "source": [
        "corpus_man_crux_np = np.asarray(corpus_man_crux_ols)\n",
        "corpus_man_crux_np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdgKbjpi63a9"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMkgU-JhwudG"
      },
      "source": [
        "x2 = np.array(sent_no_ls)\n",
        "y2 = np.array(pol_val_ls)\n",
        "\n",
        "xn = np.linspace(0, corpus_sents_len, corpus_sents_len)\n",
        "yn = interpolate.pchip_interpolate(x2, y2, xn)\n",
        "\n",
        "crux_man_df = pd.DataFrame(\n",
        "    {'sent_no': sent_no_ls,\n",
        "     'pol_val': pol_val_ls\n",
        "     }\n",
        ")\n",
        "\n",
        "# plt.plot(x2, y2, 'ok', label='True values')\n",
        "# plt.plot(xn, yn, label='Hermite Interpolation')\n",
        "\n",
        "# plt.plot(xn, yn4, label='Spline order 4')\n",
        "# plt.plot(xn, yn5, label='Spline order 5')\n",
        "# plt.plot(xn, yn6, label='Spline order 6')\n",
        "# plt.plot(xn, yn7, label='Spline order 7')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# sns.histplot(data=corpus_sents_df['char_len'], kde=True).set_title(f'{CORPUS_FULL} \\n Histogram of Paragraph Lengths')\n",
        "sns.histplot(data=crux_man_df, x='sent_no', y='pol_val', kde=True).set_title(f'{CORPUS_FULL} \\n Manual Cruxes with Hermite Smoothing')\n",
        "\n",
        "\n",
        "# Save graph to file.\n",
        "plot_filename = 'man_crux_plot.png'\n",
        "plotpathfilename_str = gen_pathfiletime(plot_filename)\n",
        "plt.savefig(plotpathfilename_str, format='png', dpi=300)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WW-VkS2s_ogy"
      },
      "source": [
        "**Gaussian Process Regression**\n",
        "\n",
        "* https://blog.dominodatalab.com/fitting-gaussian-process-models-python/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLFFYDfYpPjn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0BukxX9ZKYA"
      },
      "source": [
        "# (Optional) Load Sentiment Polarities: Interactive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhPJ9e-V9NMu"
      },
      "source": [
        "***If you upload a file of Sentiment Values you don't have to Calculate them in the following sections***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpx7viqf9AAJ"
      },
      "source": [
        "!ls -altr *.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aw8_mUHI9sdr"
      },
      "source": [
        "# Test\n",
        "\n",
        "files.download('sentiments_raw_all_virginiawoolf_tothelighthouse_20210618161224.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90axHClm9cGZ"
      },
      "source": [
        "# Upload your precomputed Sentiment Values\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02NH5nnto2AC"
      },
      "source": [
        "%whos DataFrame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QL9JCyCI-Sic"
      },
      "source": [
        "# Verify the file was uploaded correctly\n",
        "\n",
        "newest_csvfile = get_recentfile().split('/')[-1]\n",
        "print(f'The most recently updated *.csv file is: {newest_csvfile}')\n",
        "\n",
        "!head -n 10 $newest_file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTfBj8qdi_vZ"
      },
      "source": [
        "%whos DataFrame\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qgjz-E-mYgzI"
      },
      "source": [
        "# Upload file into DataFrame\n",
        "\n",
        "corpus_test_df = pd.read_csv(newest_csvfile)\n",
        "corpus_test_df['sent_clean'] = corpus_test_df['sent_clean'].astype('string')\n",
        "corpus_test_df['sent_raw'] = corpus_test_df['sent_raw'].astype('string')\n",
        "corpus_test_df.head()\n",
        "corpus_test_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6ajyb8Jpmzw"
      },
      "source": [
        "***Skip to Section <Calculate Median of All...> if SA Loaded***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGA6sQy6RPDC"
      },
      "source": [
        "corpus_lexicons_stats_dt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7CfH00OFkQV"
      },
      "source": [
        "# **Either (a) Load Precomputed Sentiment Series or (b) Calculate Sentiment Values**\n",
        "\n",
        "Sentiment Models\n",
        "\n",
        "* VADER [-1.0 to 1.0] zero peak\n",
        "* TextBlob [-1.0 to 1.0] zero peak\n",
        "* Stanza outliers [-1.0 to 199.0] pos, outliers(+peak)\n",
        "* AFINN [-14 (-8 to 8) 20] discrete\n",
        "* SentimentR 11,710 [-5.4 to 8.8] norm\n",
        "* Syuzhet [-5.4 to 8.8] norm\n",
        "* Bing [-100.0 (-20.0 to 20.0) 100] discrete, outliers\n",
        "* Pattern [-1.0 to 1.0] norm\n",
        "* SentiWord [-3.8 to 4.4] norm\n",
        "* SenticNet [-3.8 to 10] norm\n",
        "* NRC [-100.0 (-5.0 to 5.0) 100] zero, outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ueo8fTSqqaak"
      },
      "source": [
        "## **(a) Load Previously Computed Sentiment Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEq8eWslgu28"
      },
      "source": [
        "!ls -altr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RH8TY-LgCVf"
      },
      "source": [
        "### **Baseline 12 Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVX1gXQajWNG"
      },
      "source": [
        "# ARCHIVE: Discontinue use of redundant corpus_baseline_df (just use corpus_sents_df)\n",
        "\n",
        "# Baseline 12 Models: Read Computed sentiment data saved from previous run of this notebook\n",
        "corpus_sents_df = pd.read_csv('corpus_sents_baselines_vwoolf_tothelighthouse.csv')\n",
        "corpus_parags_df = pd.read_csv('sum_sentiments_parags_baselines_vwoolf_tothelighthouse.csv')\n",
        "corpus_sects_df = pd.read_csv('sum_sentiments_sects_baselines_vwoolf_tothelighthouse.csv')\n",
        "corpus_chaps_df = pd.read_csv('sum_sentiments_chaps_baselines_tothelighthouse.csv')\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "corpus_baseline_df = pd.read_csv('sum_sentiments_sents_baselines_hsbutler_theodyssey.csv')\n",
        "corpus_baseline_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "corpus_baseline_df['sent_raw'] = corpus_baseline_df['sent_raw'].astype('string')\n",
        "corpus_baseline_df['sent_clean'] = corpus_baseline_df['sent_clean'].astype('string')\n",
        "\n",
        "corpus_baseline_df.info()\n",
        "\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfl-NIhZeNzT"
      },
      "source": [
        "# Clean Sentences DataFrame\n",
        "\n",
        "if 'Unnamed: 0' in corpus_sents_df.columns:\n",
        "  corpus_sents_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "  \n",
        "corpus_sents_df.head(2)\n",
        "corpus_sents_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WnLPxjefkhE"
      },
      "source": [
        "# Clean Paragraphs DataFrame\n",
        "\n",
        "if 'Unnamed: 0' in corpus_parags_df.columns:\n",
        "  corpus_parags_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "  \n",
        "corpus_parags_df.head(2)\n",
        "corpus_parags_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMNQI76jfkdu"
      },
      "source": [
        "# Clean Section DataFrame\n",
        "\n",
        "if 'Unnamed: 0' in corpus_sects_df.columns:\n",
        "  corpus_sects_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "  \n",
        "corpus_sects_df.head(2)\n",
        "corpus_sects_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFfc4HTPfy5c"
      },
      "source": [
        "# Clean Chapter DataFrame\n",
        "\n",
        "if 'Unnamed: 0' in corpus_chaps_df.columns:\n",
        "  corpus_chaps_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "  \n",
        "corpus_chaps_df.head(2)\n",
        "corpus_chaps_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdYoS50pgJtz"
      },
      "source": [
        "### **SentimentR 7 Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBk7sJltaE43"
      },
      "source": [
        "# SentimentR 7 Models: Read Computed sentiment data saved from previous run of this notebook\n",
        "\n",
        "corpus_sentimentr_df = pd.read_csv('sum_sentiments_sentimentR_7models_vwoolf_tothelighthouse.csv')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5RkpbLrgWNQ"
      },
      "source": [
        "# Clean Chapter DataFrame\n",
        "\n",
        "if 'Unnamed: 0' in corpus_sentimentr_df.columns:\n",
        "  corpus_sentimentr_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "  \n",
        "corpus_sentimentr_df.head(2)\n",
        "corpus_sentimentr_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXotYX02g-Zf"
      },
      "source": [
        "# TODO: If missing, generate derived values for each model, lnorm/not, stdscaler/medianiqr, roll10/not"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krB0DGVMgNbW"
      },
      "source": [
        "### **SyuzhetR 4 Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9GOO2EseGTV"
      },
      "source": [
        "# SyuzhetR 4 Models: Read Computed sentiment data saved from previous run of this notebook\n",
        "\n",
        "corpus_syuzhetr_df = pd.read_csv('sum_sentiments_syuzhetR_4models_vwoolf_tothelighthouse.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EAxGBWwgdPz"
      },
      "source": [
        "# Clean Chapter DataFrame\n",
        "\n",
        "if 'Unnamed: 0' in corpus_syuzhetr_df.columns:\n",
        "  corpus_syuzhetr_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "  \n",
        "corpus_syuzhetr_df.head(2)\n",
        "corpus_syuzhetr_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHujhBBNlaQy"
      },
      "source": [
        "def process_timeseries(ts_df, col_models_ls, col_mod):\n",
        "  '''\n",
        "  Given a DataFrame, a list of columns to process and a modification to perform on these columns\n",
        "\n",
        "  Return the DataFrame with the following new columns inserted from each original Model column:\n",
        "\n",
        "    1. Length-Normed (col_mod='lnorm'])\n",
        "       a. {base_model}_lnorm\n",
        "\n",
        "    2. Standardized (col_mod='std')\n",
        "       a. {base_model}_stdscaler\n",
        "       b. {base_model}_medianiqr \n",
        "       a. {base_model_lnorm}_stdscaler\n",
        "       b. {base_model_lnorm}_medianiqr \n",
        "\n",
        "    3. Length-Normed Standardized (col_mod='roll[dd]') # where dd = 01 to 20 indicating rolling window width as % of corpus length\n",
        "       a. {base_model}_roll\n",
        "       b. {base_model}_roll \n",
        "       a. {base_model_lnorm}_roll\n",
        "       b. {base_model_lnorm}_roll \n",
        "       a. {base_model_lnorm_stdscaler}_roll\n",
        "       b. {base_model_lnorm_medianiqr}_roll\n",
        " \n",
        "  '''\n",
        "\n",
        "  # Prerequisite: token_len column must exists\n",
        "  if 'token_len' not in ts_df.columns:\n",
        "    ts_df['token_len'] = ts_df['sent_raw'].apply(lambda x: len(x.strip().split()))\n",
        "    ts_df['char_len'] = ts_df['sent_raw'].apply(lambda x: len(x))\n",
        "\n",
        "\n",
        "  # OPOTION 1: Apply (token) Length-Normalization to specified time series\n",
        "  if anew_mod == 'lnorm':\n",
        "\n",
        "    # Apply lnorm operation on all specificed columns\n",
        "    for anold_model_no, anold_model in enumerate(col_models_ls):\n",
        "\n",
        "      # lnorm (Length normalization of sentiment values using token_len) operation can only be applied to base model time series\n",
        "      # rule: disallowed substrings in anold_model name if applying lnorm\n",
        "      rule_badsubstr_lnorm = ['lnorm', 'stdscaler', 'medianiqr', 'roll']\n",
        "      if any(map(anold_model.__contains__, rule_badsubstr_lnorm)):\n",
        "        print(f'ERROR: Length-Normalization (lnorm) operation cannot be applied to {anold_model}\\n    any columns containing {rule_badsubstr_lnorm}')\n",
        "        return -99  # Return ERROR condition\n",
        "      else:\n",
        "        # Normalize specified sentiment time series by dividing by text length\n",
        "\n",
        "        # TODO: replace 'sent_raw'/'sent_clean' with 'text_raw'/'text_clean' for Sentence, Paragraph, Section and Chapter DataFrames\n",
        "\n",
        "        text_len_ls = list(ts_df['token_len'])\n",
        "        text_sentiment_ls = list(ts_df[anold_model])\n",
        "        text_sentiment_norm_ls = [text_sentiment_ls[i]/text_len_ls[i] for i in range(len(text_len_ls))]\n",
        "        anew_mod_name = f'{anold_model}_{anew_mod}'\n",
        "        # ts_df = ts_df.assign(anew_mod_name = pd.Series(text_sentiment_norm_ls).values)\n",
        "        ts_df[anew_mod_name] = pd.Series(text_sentiment_norm_ls)\n",
        "\n",
        "\n",
        "  # OPTION 2: Apply (Robust) Standardization to specified time series\n",
        "  if anew_mod == 'std':\n",
        "\n",
        "    # Apply lnorm operation on all specificed columns\n",
        "    for anold_model_no, anold_model in enumerate(col_models_ls):\n",
        "\n",
        "      # std (Standardization) operation can only be applied to base model time series\n",
        "      # rule: disallowed substrings in anold_model name if applying std to existing rolling averages or already standardized time series\n",
        "      rule_badsubstr_std = ['stdscaler', 'medianiqr', 'roll']\n",
        "      if any(map(anold_model.__contains__, rule_badsubstr_std)):\n",
        "        print(f'ERROR: Standardization (std) operation cannot be applied to {anold_model}\\n    any columns containing {rule_badsubstr_std}')\n",
        "        return -99  # Return ERROR condition\n",
        "      else:\n",
        "        # Standardize specificied sentiment time series by dividing by applying (Robust)Standization also configured in code below\n",
        "\n",
        "        # TODO: replace 'sent_raw'/'sent_clean' with 'text_raw'/'text_clean' for Sentence, Paragraph, Section and Chapter DataFrames\n",
        "\n",
        "        anew_mod_stdscaler = f'{anold_model}_stdscaler'\n",
        "        ts_df[anew_mod_stdscaler] = mean_std_scaler.fit_transform(np.array(ts_df[anold_model]).reshape(-1, 1))\n",
        "        anew_mod_medianiqr = f'{anold_model}_medianiqr'\n",
        "        ts_df[anew_mod_medianiqr] = median_iqr_scaler.fit_transform(np.array(ts_df[anold_model]).reshape(-1, 1))\n",
        "\n",
        "\n",
        "\n",
        "  # OPTION 3: Apply Simple Rolling Mean to specified time series\n",
        "  if anew_mod.startswith('roll'):\n",
        "\n",
        "    roll_per = 0\n",
        "\n",
        "    # Check for roll argument against several rules and return detailed error message if fail to pass any combination of rules\n",
        "    roll_err_ls = []\n",
        "    roll_arg_len = len(anew_mod)\n",
        "    if (roll_arg_len != 6):\n",
        "      roll_err_ls.append(f'ERROR: argument roll[dd]={anew_mod} is too long with {roll_arg_len} characters (must be 6)')\n",
        "    roll_arg_2last = anew_mod[-2]\n",
        "\n",
        "    if (roll_arg_2last.isdigit() == False):\n",
        "      roll_err_ls.append(f'ERROR: argument roll[dd]={anew_mod} last 2 chars {roll_arg_2last} must be both be digits [0-9]')\n",
        "    else:\n",
        "      roll_per = int(roll_arg_2last)\n",
        "      if (roll_per > 20):\n",
        "        roll_err_ls.append(f'ERROR: argument roll[dd]={anew_mod} last 2 chars {roll_arg_2last} must be integers between 01 and 20')\n",
        "\n",
        "    if len(roll_err_ls) > 0:\n",
        "      print(f'ERROR in process_timeseries() due to invalid argument roll[dd] = {anew_mod}\\n\\n')\n",
        "      for anerror_str in roll_err_ls:\n",
        "        print(f'    {anerror_str}')\n",
        "        return -99  # Return ERROR condition\n",
        "\n",
        "\n",
        "    # roll (Simple Rolling Average with specificed window size as 2-digit percentage of corpus length (01-20%)\n",
        "    # rule: disallowed substrings in anold_model name applying roll operation more than once to existing time series\n",
        "    rule_badsubstr_roll = ['roll']\n",
        "    if any(map(anold_model.__contains__, rule_badsubstr_roll)):\n",
        "      print(f'ERROR: Rolling Mean (roll) operation cannot be applied to {anold_model}\\n    any columns containing {rule_badsubstr_roll}')\n",
        "      return -99 # Return ERROR condition\n",
        "\n",
        "    else:\n",
        "        # Compute Rolling Mean with the given window size (extracted above as an int in roll_per) for the specificied sentiment time series\n",
        "\n",
        "        # TODO: replace 'sent_raw'/'sent_clean' with 'text_raw'/'text_clean' for Sentence, Paragraph, Section and Chapter DataFrames\n",
        "\n",
        "        anew_mod_roll = f'{anold_model}_{anew_nod}'\n",
        "        roll_win = int(ts_df.shape[0]*roll_per/100)\n",
        "        ts_df[anew_mod_roll] = ts_df[anold_model].rolling(roll_win, center=True).mean()\n",
        "\n",
        "  return 1  # Return SUCCESS condition\n",
        "\n",
        "# Test\n",
        "\n",
        "process_timeseries(ts_df=corpus_syuzhetr_df, col_models_ls=['syuzhet', 'bing'], col_mods_ls=['roll10'])\n",
        "corpus_syuzhetr_df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ6ohlgKELtN"
      },
      "source": [
        "\"hello world\"[-2:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2i_kQdBsMC4"
      },
      "source": [
        "corpus_syuzhetr_df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fz3XdlUJnIRp"
      },
      "source": [
        "  print('Standardizing Sentences')\n",
        "  # Get Sentence Robust Standardization with Standard Scaler and  MedianIQRScaling\n",
        "  corpus_sents_df[col_stdscaler]  = list2stdscaler(corpus_sents_df[model_base])\n",
        "  corpus_sents_df[col_medianiqr]  = median_iqr_scaler.fit_transform(np.array(corpus_sents_df[model_base]).reshape(-1, 1))\n",
        "  # Normalize the Sentence Sentiment by dividing by Chapter Length\n",
        "  sents_len_ls = list(corpus_sents_df['token_len'])\n",
        "  sents_sentiment_ls = list(corpus_sents_df[model_base])\n",
        "  sents_sentiment_norm_ls = [sents_sentiment_ls[i]/sents_len_ls[i] for i in range(len(sents_len_ls))]\n",
        "  # RobustStandardize Sentence sentiment values\n",
        "  # corpus_sents_df[col_lnorm_meanstd]  = mean_std_scaler.fit_transform(np.array(pd.Series(sents_sentiment_norm_ls)).reshape(-1, 1))\n",
        "  # corpus_sents_df[col_lnorm_meanstd]  = mean_std_scaler.fit_transform(np.array(pd.Series(sents_sentiment_norm_ls)).reshape(-1, 1))\n",
        "  corpus_sents_df[col_lnorm_stdscaler]  = mean_std_scaler.fit_transform(np.array(corpus_sents_df[model_base]).reshape(-1, 1))\n",
        "  corpus_sents_df[col_lnorm_medianiqr]  = median_iqr_scaler.fit_transform(np.array(pd.Series(sents_sentiment_norm_ls)).reshape(-1, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is7GsGTCgQik"
      },
      "source": [
        "### **Transformer 8 Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuGaejHXeGP2"
      },
      "source": [
        "# Transformer 8 Models: Read Computed sentiment data saved from previous run of this notebook\n",
        "\n",
        "corpus_trans_sents_df = pd.read_csv('sum_sentiments_sents_trans_vwoolf_tothelighthouse.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sm2Lsk4zgoce"
      },
      "source": [
        "# Clean Chapter DataFrame\n",
        "\n",
        "if 'Unnamed: 0' in corpus_trans_sents_df.columns:\n",
        "  corpus_trans_sents_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "  \n",
        "corpus_trans_sents_df.head(2)\n",
        "corpus_trans_sents_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfyebD6HhQIU"
      },
      "source": [
        "# TODO: If missing, generate derived values for each model, lnorm/not, stdscaler/medianiqr, roll10/not"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d-AM_WvbqFu"
      },
      "source": [
        "\n",
        "# Verfiy there are no NaN or Empty strings that passed the cleaning process\n",
        "\n",
        "# Only execute if previously datafile/corpus_sents_df\n",
        "\n",
        "\n",
        "# corpus_sents_df[corpus_sents_df['sent_clean'].isnull()]\n",
        "\n",
        "# corpus_sents_df[corpus_sents_df['sent_clean'].apply(lambda x: len(str(x)) <= 0)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAAQ0SwfZynO"
      },
      "source": [
        "# Verify that hyphenated words are correctly handled (e.g. 'summer-mroning' -> 'summer morning')\n",
        "\n",
        "# corpus_sents_df[corpus_sents_df['sent_clean'].str.contains('summer', na=False)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsEbvCoCX7HY"
      },
      "source": [
        "## **(b) Compute Baseline Sentiments (Auto)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZK1gA47xzkS"
      },
      "source": [
        "### **Select Sentiment Models (Manual)**\n",
        "\n",
        "NOTE:\n",
        "\n",
        "* Stanza (Stanford OpenNLP) can take upto 50 minutes to run\n",
        "\n",
        "* Listed in increasing order of (approx) run time\n",
        "\n",
        "* MPQA/SentiStrength not yet implemented (placeholders only for now)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0pStg1gJTZA"
      },
      "source": [
        "SentimentR_Arc = True #@param {type:\"boolean\"}\n",
        "Syuzhet_Arc = True #@param {type:\"boolean\"}\n",
        "Bing_Arc = True #@param {type:\"boolean\"}\n",
        "SenticNet_Arc = True #@param {type:\"boolean\"}\n",
        "SentiWord_Arc = True #@param {type:\"boolean\"}\n",
        "NRC_Arc = True #@param {type:\"boolean\"}\n",
        "AFINN_Arc = True #@param {type:\"boolean\"}\n",
        "VADER_Arc = True #@param {type:\"boolean\"}\n",
        "TextBlob_Arc = True #@param {type:\"boolean\"}\n",
        "Flair_Arc = True #@param {type:\"boolean\"}\n",
        "Pattern_Arc = True #@param {type:\"boolean\"}\n",
        "Stanza_Arc = True #@param {type:\"boolean\"}\n",
        "# MPQA_Arc = False #@param {type:\"boolean\"}\n",
        "# SentiStrength_Arc = False #@param {type:\"boolean\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0IACAN5JTZC"
      },
      "source": [
        "# Create and Verify custom list of Models to include\n",
        "\n",
        "MODELS_CUSTOM_LS = []\n",
        "\n",
        "if VADER_Arc:\n",
        "  MODELS_CUSTOM_LS.append('vader')\n",
        "if TextBlob_Arc:\n",
        "  MODELS_CUSTOM_LS.append('textblob')\n",
        "if Flair_Arc:\n",
        "  MODELS_CUSTOM_LS.append('flair')\n",
        "if Stanza_Arc:\n",
        "  MODELS_CUSTOM_LS.append('stanza')\n",
        "if SentimentR_Arc:\n",
        "  MODELS_CUSTOM_LS.append('sentimentr')\n",
        "if Syuzhet_Arc:\n",
        "  MODELS_CUSTOM_LS.append('syuzhet')\n",
        "if AFINN_Arc:\n",
        "  MODELS_CUSTOM_LS.append('afinn')\n",
        "if Bing_Arc:\n",
        "  MODELS_CUSTOM_LS.append('bing')\n",
        "if Pattern_Arc:\n",
        "  MODELS_CUSTOM_LS.append('pattern')\n",
        "if SentiWord_Arc:\n",
        "  MODELS_CUSTOM_LS.append('sentiword')\n",
        "if SenticNet_Arc:\n",
        "  MODELS_CUSTOM_LS.append('senticnet')\n",
        "if NRC_Arc:\n",
        "  MODELS_CUSTOM_LS.append('nrc')\n",
        "\n",
        "print(f'Here are the Models we are using to ensemble and save:\\n\\n   {MODELS_CUSTOM_LS}')\n",
        "\n",
        "\"\"\"\n",
        "models_incl_ls = []\n",
        "for amodel in MODELS_CUSTOM_LS:\n",
        "  models_incl_ls.append(amodel[:2])\n",
        "models_incl_str = ''.join(models_incl_ls)\n",
        "\n",
        "print(f'Here is a custom name abbr: {models_incl_str}')\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I9EVfxnffkG"
      },
      "source": [
        "%whos DataFrame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gw0JPNe6T2ap"
      },
      "source": [
        "# Calculate (win_(x)1per) 1% of Corpus length for smallest (odd-valued) rolling window\n",
        "\n",
        "# Sentences\n",
        "corpus_sents_len = corpus_sents_df.shape[0]\n",
        "\n",
        "win_raw_s1per = int(corpus_sents_len * 0.01)\n",
        "# print(f'1% Rolling Window: {win_raw_s1per}')\n",
        "\n",
        "if win_raw_s1per % 2:\n",
        "  win_s1per = win_raw_s1per\n",
        "else:\n",
        "  win_s1per = win_raw_s1per + 1\n",
        "\n",
        "# Paragraphs\n",
        "# corpus_parags_df = corpus_all_df\n",
        "corpus_parags_len = len(corpus_sents_df['parag_no'].unique())\n",
        "\n",
        "win_raw_p1per = int(corpus_parags_len * 0.01)\n",
        "# print(f'1% Rolling Window: {win_raw_1per}')\n",
        "\n",
        "if win_raw_p1per % 2:\n",
        "  win_p1per = win_raw_p1per\n",
        "else:\n",
        "  win_p1per = win_raw_p1per + 1\n",
        "\n",
        "\n",
        "# Sections\n",
        "\n",
        "# NO NEED FOR SLIDING WINDOW ON SECTIONS\n",
        "\n",
        "\n",
        "print(f'Sentence 1 Percent window: {win_s1per}')\n",
        "print(f'Paragraph 1 Percent window: {win_p1per}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGjfPK9u21HH"
      },
      "source": [
        "# Verify Sentiment Lexicon hash files are accessable\n",
        "\n",
        "lexicons_path = f'/gdrive/MyDrive/{LEXICONS_SUBDIR[1:]}/hash*.csv'\n",
        "!pwd\n",
        "!ls $lexicons_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tAxuAxU7ueg"
      },
      "source": [
        "### **Calculate SentimentR (Jockers-Rinker) Sentiment Polarities (Optional: Auto)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foQeDPQpvyB3"
      },
      "source": [
        "if SentimentR_Arc == True:\n",
        "  model_base = 'sentimentr'\n",
        "\n",
        "  \"\"\"\n",
        "  model_name = 'sentimentr_lnorm_medianiqr'\n",
        "\n",
        "  col_medianiqr = f'{model_base}_medianiqr'\n",
        "  col_meanstd = f'{model_base}_meanstd'\n",
        "\n",
        "  col_lnorm_medianiqr = f'{model_base}_lnorm_medianiqr'\n",
        "  col_lnorm_meanstd = f'{model_base}_lnorm_meanstd'\n",
        "  \"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEnJj5rIMcSj"
      },
      "source": [
        "# Verify Lexicon subdirectory and datafiles\n",
        "!ls /gdrive/MyDrive/$LEXICONS_SUBDIR\n",
        "\n",
        "print('\\nTop of Dictionary datafile ----------')\n",
        "!head -n 5  /gdrive/MyDrive/$LEXICONS_SUBDIR/hash_sentiment_sentimentr.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gq7dImOJozm5"
      },
      "source": [
        "# Read Lexicon into DataFrame \n",
        "\n",
        "if SentimentR_Arc == True:\n",
        "\n",
        "  lexicon_sentimentr_df = get_lexicon(f'/gdrive/MyDrive/{LEXICONS_SUBDIR}/hash_sentiment_sentimentr.csv')\n",
        "  lexicon_sentimentr_df['x'] = lexicon_sentimentr_df['x'].astype('string')\n",
        "\n",
        "  # Clean/Reorg DataFrame\n",
        "  lexicon_sentimentr_df.drop(columns=['Unnamed: 0'], axis=1, inplace=True)\n",
        "  lexicon_sentimentr_df.rename(columns={'x':'word', 'y':'polarity'}, inplace=True)\n",
        "\n",
        "  # Verify\n",
        "  if (PLOT_OUTPUT == 'All'):\n",
        "    lexicon_sentimentr_df.head()\n",
        "    lexicon_sentimentr_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25_Zjja0o_Hx"
      },
      "source": [
        "# Convert DataFrame to Dict[word] = polarity\n",
        "\n",
        "if SentimentR_Arc == True:\n",
        "\n",
        "  id = lexicon_sentimentr_df.word.values\n",
        "  values = lexicon_sentimentr_df.polarity.values\n",
        "\n",
        "  lexicon_sentimentr_dt = dict(zip(id, values))\n",
        "  # lexicon_sentimentr_dt\n",
        "\n",
        "  # Test\n",
        "  sent_test='I hate Mondays.'\n",
        "  print(text2sentiment(sent_test, lexicon_sentimentr_dt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQYYP2hiO53j"
      },
      "source": [
        "# Verify\n",
        "\n",
        "# corpus_sents_df['sent_clean'].isna().any()\n",
        "# corpus_chaps_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVSImJ3ETSYt"
      },
      "source": [
        "corpus_parags_df.columns\n",
        "print('\\n')\n",
        "corpus_sects_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxe15XjNwByS"
      },
      "source": [
        "# Calculate all the Sentence, Paragraph, Section and Chapter Sentiment Scores and Standardized variants\n",
        "\n",
        "# Sentiment evaluation function\n",
        "def sentiment_sentimentr(text_str):\n",
        "  '''\n",
        "  Given a text string\n",
        "  Return corresponding sentiment value based on sentimentr lexicon\n",
        "  '''\n",
        "  \n",
        "  sentiment_val = text2sentiment(str(text_str), lexicon_sentimentr_dt)\n",
        "\n",
        "  return sentiment_val \n",
        "\n",
        "# Calculate all Sentiment values and variants\n",
        "if SentimentR_Arc == True:\n",
        "  model_base = 'sentimentr'\n",
        "  get_sentiments(model_base=model_base, sentiment_fn=sentiment_sentimentr, sentiment_type='lexicon')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVX6rg5KwBvF"
      },
      "source": [
        "corpus_sents_df.head(2)\n",
        "corpus_sents_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Pkrp6TwY7OI"
      },
      "source": [
        "# Verify there are no empty Sentences\n",
        "\n",
        "corpus_sents_df[corpus_sents_df['token_len'] == 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbGz2Yi5wByY"
      },
      "source": [
        "# Get/Set Sentiment Statistics\n",
        "\n",
        "if SentimentR_Arc == True:\n",
        "  get_lexstats(corpus_sents_df, model_base, text_unit='sentence')\n",
        "  get_lexstats(corpus_parags_df, model_base, text_unit='paragraph')\n",
        "  get_lexstats(corpus_sects_df, model_base, text_unit='section')\n",
        "  get_lexstats(corpus_chaps_df, model_base, text_unit='chapter')\n",
        "\n",
        "  # Validate\n",
        "  corpus_lexicons_stats_dt\n",
        "\n",
        "  # corpus_lexicons_stats_dt['vader']['sents']['sentiment_max']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4aDdJcrzlE1"
      },
      "source": [
        "corpus_sents_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOSiIyhbN2-8"
      },
      "source": [
        "# Verify \n",
        "\n",
        "if SentimentR_Arc == True:\n",
        "  # corpus_sents_df['sentimentr'].plot(alpha=0.3)\n",
        "  corpus_sents_df['sentimentr_stdscaler'].plot(alpha=0.1)\n",
        "  corpus_sents_df['sentimentr_medianiqr'].plot(alpha=0.3)\n",
        "  plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8POYGujomVt"
      },
      "source": [
        "corpus_sents_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lvswx9yovMV"
      },
      "source": [
        "corpus_parags_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZjqwTvU76AR"
      },
      "source": [
        "### **Calculate Syuzhet (Jockers) Sentiment Polarities (Optional: Auto)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjOXGQX54lbX"
      },
      "source": [
        "# Define Model names\n",
        "\n",
        "if Syuzhet_Arc == True:\n",
        "  model_base = 'syuzhet'\n",
        "  model_name = 'syuzhet_lnorm_medianiqr'\n",
        "\n",
        "  col_medianiqr = f'{model_base}_medianiqr'\n",
        "  col_meanstd = f'{model_base}_meanstd'\n",
        "\n",
        "  col_lnorm_medianiqr = f'{model_base}_lnorm_medianiqr'\n",
        "  col_lnorm_meanstd = f'{model_base}_lnorm_meanstd'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB5fBNQ-QNwk"
      },
      "source": [
        "# Verify Lexicon subdirectory and datafiles\n",
        "!ls /gdrive/MyDrive/$LEXICONS_SUBDIR\n",
        "\n",
        "print('\\nTop of Dictionary datafile ----------')\n",
        "!head -n 5  /gdrive/MyDrive/$LEXICONS_SUBDIR/hash_sentiment_syuzhet.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkhaGcuy4lbg"
      },
      "source": [
        "# Read Lexicon into DataFrame \n",
        "\n",
        "if Syuzhet_Arc == True:\n",
        "\n",
        "  lexicon_syuzhet_df = get_lexicon(f'/gdrive/MyDrive/{LEXICONS_SUBDIR}/hash_sentiment_syuzhet.csv')\n",
        "  lexicon_syuzhet_df['word'] = lexicon_syuzhet_df['word'].astype('string')\n",
        "\n",
        "  # Clean/Reorg DataFrame\n",
        "  lexicon_syuzhet_df.drop(columns=['Unnamed: 0'], axis=1, inplace=True)\n",
        "  lexicon_syuzhet_df.rename(columns={'x':'word', 'y':'polarity'}, inplace=True)\n",
        "\n",
        "  # Verify\n",
        "  if (PLOT_OUTPUT == 'All'):\n",
        "    lexicon_syuzhet_df.head()\n",
        "    lexicon_syuzhet_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9IuINuR4lbi"
      },
      "source": [
        "# Convert DataFrame to Dict[word] = polarity\n",
        "\n",
        "if Syuzhet_Arc == True:\n",
        "\n",
        "  id = lexicon_syuzhet_df.word.values\n",
        "  values = lexicon_syuzhet_df.value.values\n",
        "\n",
        "  lexicon_syuzhet_dt = dict(zip(id, values))\n",
        "  # lexicon_sentimentr_dt\n",
        "\n",
        "  # Test\n",
        "  sent_test='I hate Mondays.'\n",
        "  print(text2sentiment(sent_test, lexicon_syuzhet_dt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO-txaFL4lbo"
      },
      "source": [
        "# Calculate all the Sentence, Paragraph, Section and Chapter Sentiment Scores and Standardized variants\n",
        "\n",
        "# Sentiment evaluation function\n",
        "def sentiment_syuzhet(text_str):\n",
        "  '''\n",
        "  Given a text string\n",
        "  Return corresponding sentiment value based on sentimentr lexicon\n",
        "  '''\n",
        "  \n",
        "  sentiment_val = text2sentiment(str(text_str), lexicon_syuzhet_dt)\n",
        "\n",
        "  return sentiment_val \n",
        "\n",
        "# Calculate all Sentiment values and variants\n",
        "\n",
        "if Syuzhet_Arc == True:\n",
        "  get_sentiments(model_base=model_base, sentiment_fn=sentiment_syuzhet, sentiment_type='lexicon')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfsLZSo04lbp"
      },
      "source": [
        "# Get/Set Sentiment Statistics\n",
        "\n",
        "if Syuzhet_Arc == True:\n",
        "  get_lexstats(corpus_sents_df, model_base, text_unit='sentence')\n",
        "  get_lexstats(corpus_parags_df, model_base, text_unit='paragraph')\n",
        "  get_lexstats(corpus_sects_df, model_base, text_unit='section')\n",
        "  get_lexstats(corpus_chaps_df, model_base, text_unit='chapter')\n",
        "\n",
        "  # Validate\n",
        "  corpus_lexicons_stats_dt\n",
        "\n",
        "  # corpus_lexicons_stats_dt['vader']['sents']['sentiment_max']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9VFBSXD0vJo"
      },
      "source": [
        "corpus_sents_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-BwrbyXR5Hd"
      },
      "source": [
        "# Verify \n",
        "\n",
        "if Syuzhet_Arc == True:\n",
        "  # corpus_sents_df['syuzhet'].plot(alpha=0.3)\n",
        "  corpus_sents_df['syuzhet_stdscaler'].plot(alpha=0.3)\n",
        "  corpus_sents_df['syuzhet_medianiqr'].plot(alpha=0.1)\n",
        "  plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA3dWsnF78mi"
      },
      "source": [
        "### **Calculate Bing (HuLiu) Sentiment Polarities (Optional: Auto)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wvq1prK7n1k"
      },
      "source": [
        "if Bing_Arc == True:\n",
        "  model_base = 'bing'\n",
        "  model_name = 'bing_lnorm_medianiqr'\n",
        "\n",
        "  col_medianiqr = f'{model_base}_medianiqr'\n",
        "  col_meanstd = f'{model_base}_meanstd'\n",
        "\n",
        "  col_lnorm_medianiqr = f'{model_base}_lnorm_medianiqr'\n",
        "  col_lnorm_meanstd = f'{model_base}_lnorm_meanstd'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDfB2f0olded"
      },
      "source": [
        "# Verify Lexicon subdirectory and datafiles\n",
        "!ls /gdrive/MyDrive/$LEXICONS_SUBDIR\n",
        "\n",
        "print('\\nTop of Dictionary datafile ----------')\n",
        "!head -n 5  /gdrive/MyDrive/$LEXICONS_SUBDIR/hash_sentiment_bing.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZELGxS8y9PiS"
      },
      "source": [
        "# Read Lexicon into DataFrame \n",
        "\n",
        "if Bing_Arc == True:\n",
        "  \n",
        "  lexicon_bing_df = get_lexicon(f'/gdrive/MyDrive/{LEXICONS_SUBDIR}/hash_sentiment_bing.csv')\n",
        "  lexicon_bing_df['x'] = lexicon_bing_df['x'].astype('string')\n",
        "\n",
        "  # Clean/Reorg DataFrame\n",
        "  lexicon_bing_df.drop(columns=['Unnamed: 0'], axis=1, inplace=True)\n",
        "  lexicon_bing_df.rename(columns={'x':'word', 'y':'polarity'}, inplace=True)\n",
        "\n",
        "  # Verify\n",
        "  if (PLOT_OUTPUT == 'All'):\n",
        "    lexicon_bing_df.head()\n",
        "    lexicon_bing_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJQTaeue9VjI"
      },
      "source": [
        "# Convert DataFrame to Dict[word] = polarity\n",
        "\n",
        "if Bing_Arc == True:\n",
        "\n",
        "  id = lexicon_bing_df.word.values\n",
        "  values = lexicon_bing_df.polarity.values\n",
        "\n",
        "  lexicon_bing_dt = dict(zip(id, values))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_Ffzu1m7n10"
      },
      "source": [
        "# Calculate all the Sentence, Paragraph, Section and Chapter Sentiment Scores and Standardized variants\n",
        "\n",
        "# Sentiment evaluation function\n",
        "def sentiment_bing(text_str):\n",
        "  '''\n",
        "  Given a text string\n",
        "  Return corresponding sentiment value based on sentimentr lexicon\n",
        "  '''\n",
        "  \n",
        "  sentiment_val = text2sentiment(str(text_str), lexicon_bing_dt)\n",
        "\n",
        "  return sentiment_val \n",
        "\n",
        "# Calculate all Sentiment values and variants\n",
        "if Bing_Arc == True:\n",
        "  get_sentiments(model_base=model_base, sentiment_fn=sentiment_bing, sentiment_type='lexicon')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWITnL2a9rrx"
      },
      "source": [
        "# Calculate Bing Sentiment [0,1,2]\n",
        "\n",
        "def bing_discrete2continous_sentiment(text):\n",
        "  '''\n",
        "  Given a plain text string, give it to\n",
        "    Stanford Stanza (OpenNLP) to calculate sentiment for each word on a 3 point scale 0-2\n",
        "  Return a sentiment value for the entire sentence (sum of word sentiments/log(len of sentence)) \n",
        "    that approximates a normal distribution for all values\n",
        "    In order to get more fine grained measure of overall Sentence sentiment\n",
        "    Sentiment values will be Normalized/Standardized so absolute precision is not required\n",
        "  '''\n",
        "  text_sentiment_total = 0.\n",
        "  text_ls = text.split()\n",
        "  text_len = len(text_ls)\n",
        "  for aword in text_ls:\n",
        "    text_sentiment_total += lex_discrete2continous_sentiment(str(aword), lexicon_bing_dt)\n",
        "  text_sentiment_norm = text_sentiment_total/(np.log(text_len)+1)\n",
        "\n",
        "  return text_sentiment_norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xpzm3hi7n1x"
      },
      "source": [
        "# Test\n",
        "\n",
        "if Bing_Arc == True:\n",
        "  sent_test='I hate Mondays.'\n",
        "  print(bing_discrete2continous_sentiment(sent_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UFEItnO-i7h"
      },
      "source": [
        "# Calculate all the Sentence, Paragraph, Section and Chapter Sentiment Scores and Standardized variants\n",
        "\n",
        "# Calculate all Sentiment values and variants\n",
        "if Bing_Arc == True:\n",
        "  get_sentiments(model_base=model_base, sentiment_fn=bing_discrete2continous_sentiment, sentiment_type='function')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4thQWz3-i7k"
      },
      "source": [
        "# Get/Set Sentiment Statistics\n",
        "\n",
        "if Bing_Arc == True:\n",
        "  get_lexstats(corpus_sents_df, model_base, text_unit='sentence')\n",
        "  get_lexstats(corpus_parags_df, model_base, text_unit='paragraph')\n",
        "  get_lexstats(corpus_sects_df, model_base, text_unit='section')\n",
        "  get_lexstats(corpus_chaps_df, model_base, text_unit='chapter')\n",
        "\n",
        "  # Validate\n",
        "  corpus_lexicons_stats_dt\n",
        "\n",
        "  # corpus_lexicons_stats_dt['vader']['sents']['sentiment_max']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKlKnqmWmBEP"
      },
      "source": [
        "# Verify \n",
        "\n",
        "if Bing_Arc == True:\n",
        "  # corpus_sents_df['bing'].plot(alpha=0.3)\n",
        "  corpus_sents_df['bing_stdscaler'].plot(alpha=0.3)\n",
        "  corpus_sents_df['bing_medianiqr'].plot(alpha=0.1)\n",
        "  plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkNZVk128jV9"
      },
      "source": [
        "### **Calculate SentiWord Sentiment Polarities (Optional: Auto)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnL4ORNp8MgB"
      },
      "source": [
        "if SentiWord_Arc == True:\n",
        "  model_base = 'sentiword'\n",
        "  model_name = 'sentiword_lnorm_medianiqr'\n",
        "\n",
        "  col_medianiqr = f'{model_base}_medianiqr'\n",
        "  col_meanstd = f'{model_base}_meanstd'\n",
        "\n",
        "  col_lnorm_medianiqr = f'{model_base}_lnorm_medianiqr'\n",
        "  col_lnorm_meanstd = f'{model_base}_lnorm_meanstd'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ootf8xdbnHPx"
      },
      "source": [
        "# Verify Lexicon subdirectory and datafiles\n",
        "!ls /gdrive/MyDrive/$LEXICONS_SUBDIR\n",
        "\n",
        "print('\\nTop of Dictionary datafile ----------')\n",
        "!head -n 5  /gdrive/MyDrive/$LEXICONS_SUBDIR/hash_sentiment_sentiword.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpVmt0fK8xi_"
      },
      "source": [
        "# Read Lexicon into DataFrame \n",
        "\n",
        "if SentiWord_Arc == True:\n",
        "\n",
        "  lexicon_sentiword_df = get_lexicon(f'/gdrive/MyDrive/{LEXICONS_SUBDIR}/hash_sentiment_sentiword.csv')\n",
        "  lexicon_sentiword_df['x'] = lexicon_sentiword_df['x'].astype('string')\n",
        "\n",
        "  # Clean/Reorg DataFrame\n",
        "  lexicon_sentiword_df.drop(columns=['Unnamed: 0'], axis=1, inplace=True)\n",
        "  lexicon_sentiword_df.rename(columns={'x':'word', 'y':'polarity'}, inplace=True)\n",
        "\n",
        "  # Verify\n",
        "  if (PLOT_OUTPUT == 'All'):\n",
        "    lexicon_sentiword_df.head()\n",
        "    lexicon_sentiword_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwtK2M9h879M"
      },
      "source": [
        "# Convert DataFrame to Dict[word] = polarity\n",
        "\n",
        "if SentiWord_Arc == True:\n",
        "\n",
        "  id = lexicon_sentiword_df.word.values\n",
        "  values = lexicon_sentiword_df.polarity.values\n",
        "\n",
        "  lexicon_sentiword_dt = dict(zip(id, values))\n",
        "  # lexicon_sentiword_dt\n",
        "\n",
        "  # Test\n",
        "  sent_test='I hate Mondays.'\n",
        "  print(text2sentiment(sent_test, lexicon_sentiword_dt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I-QwB478MgP"
      },
      "source": [
        "# Calculate all the Sentence, Paragraph, Section and Chapter Sentiment Scores and Standardized variants\n",
        "\n",
        "# Sentiment evaluation function\n",
        "def sentiment_sentiword(text_str):\n",
        "  '''\n",
        "  Given a text string\n",
        "  Return corresponding sentiment value based on sentimentr lexicon\n",
        "  '''\n",
        "  \n",
        "  sentiment_val = text2sentiment(str(text_str), lexicon_sentiword_dt)\n",
        "\n",
        "  return sentiment_val \n",
        "\n",
        "# Calculate all Sentiment values and variants\n",
        "if SentiWord_Arc == True:\n",
        "  get_sentiments(model_base=model_base, sentiment_fn=sentiment_sentiword, sentiment_type='lexicon')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbEF88568MgS"
      },
      "source": [
        "# Get/Set Sentiment Statistics\n",
        "\n",
        "if SentiWord_Arc == True:\n",
        "  get_lexstats(corpus_sents_df, model_base, text_unit='sentence')\n",
        "  get_lexstats(corpus_parags_df, model_base, text_unit='paragraph')\n",
        "  get_lexstats(corpus_sects_df, model_base, text_unit='section')\n",
        "  get_lexstats(corpus_chaps_df, model_base, text_unit='chapter')\n",
        "\n",
        "  # Validate\n",
        "  corpus_lexicons_stats_dt\n",
        "\n",
        "  # corpus_lexicons_stats_dt['vader']['sents']['sentiment_max']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9GfZ5RQnn4G"
      },
      "source": [
        "# Verify \n",
        "\n",
        "if SentiWord_Arc == True:\n",
        "  # corpus_sents_df['sentiword'].plot(alpha=0.3)\n",
        "  corpus_sents_df['sentiword_stdscaler'].plot(alpha=0.3)\n",
        "  corpus_sents_df['sentiword_medianiqr'].plot(alpha=0.1)\n",
        "  plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUcANLM_8mtT"
      },
      "source": [
        "### **Calculate SenticNet Sentiment Polarities (Optional: Auto)**\n",
        "\n",
        "* https://sentic.net/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OqhSberA1hZ"
      },
      "source": [
        "if SenticNet_Arc == True:\n",
        "  model_base = 'senticnet'\n",
        "  model_name = 'senticnet_lnorm_medianiqr'\n",
        "\n",
        "  col_medianiqr = f'{model_base}_medianiqr'\n",
        "  col_meanstd = f'{model_base}_meanstd'\n",
        "\n",
        "  col_lnorm_medianiqr = f'{model_base}_lnorm_medianiqr'\n",
        "  col_lnorm_meanstd = f'{model_base}_lnorm_meanstd'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsnCzsfFnx7B"
      },
      "source": [
        "# Verify Lexicon subdirectory and datafiles\n",
        "!ls /gdrive/MyDrive/$LEXICONS_SUBDIR\n",
        "\n",
        "print('\\nTop of Dictionary datafile ----------')\n",
        "!head -n 5  /gdrive/MyDrive/$LEXICONS_SUBDIR/hash_sentiment_senticnet.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmMfvQvYBBoM"
      },
      "source": [
        "# Read Lexicon into DataFrame \n",
        "\n",
        "if SenticNet_Arc == True:\n",
        "\n",
        "  lexicon_senticnet_df = get_lexicon(f'/gdrive/MyDrive/{LEXICONS_SUBDIR}/hash_sentiment_senticnet.csv')\n",
        "  lexicon_senticnet_df['x'] = lexicon_senticnet_df['x'].astype('string')\n",
        "\n",
        "  # Clean/Reorg DataFrame\n",
        "  lexicon_senticnet_df.drop(columns=['Unnamed: 0'], axis=1, inplace=True)\n",
        "  lexicon_senticnet_df.rename(columns={'x':'word', 'y':'polarity'}, inplace=True)\n",
        "\n",
        "  # Verify\n",
        "  if (PLOT_OUTPUT == 'All'):\n",
        "    lexicon_senticnet_df.head()\n",
        "    lexicon_senticnet_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2oS71STBIUS"
      },
      "source": [
        "# Convert DataFrame to Dict[word] = polarity\n",
        "\n",
        "if SenticNet_Arc == True:\n",
        "\n",
        "  id = lexicon_senticnet_df.word.values\n",
        "  values = lexicon_senticnet_df.polarity.values\n",
        "\n",
        "  lexicon_senticnet_dt =dict(zip(id, values))\n",
        "  # lexicon_jockersrinker_dt\n",
        "\n",
        "  # Test\n",
        "  sent_test='I hate Mondays.'\n",
        "  text2sentiment(sent_test, lexicon_senticnet_dt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHQwXBl5BlRM"
      },
      "source": [
        "# Calculate all the Sentence, Paragraph, Section and Chapter Sentiment Scores and Standardized variants\n",
        "\n",
        "# Sentiment evaluation function\n",
        "def sentiment_senticnet(text_str):\n",
        "  '''\n",
        "  Given a text string\n",
        "  Return corresponding sentiment value based on senticnet lexicon\n",
        "  '''\n",
        "  \n",
        "  sentiment_val = text2sentiment(str(text_str), lexicon_senticnet_dt)\n",
        "\n",
        "  return sentiment_val \n",
        "\n",
        "# Calculate all Sentiment values and variants\n",
        "if SenticNet_Arc == True:\n",
        "  get_sentiments(model_base=model_base, sentiment_fn=sentiment_senticnet, sentiment_type='lexicon')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raHUj3a4A1hs"
      },
      "source": [
        "# Get/Set Sentiment Statistics\n",
        "\n",
        "if SenticNet_Arc == True:\n",
        "  get_lexstats(corpus_sents_df, model_base, text_unit='sentence')\n",
        "  get_lexstats(corpus_parags_df, model_base, text_unit='paragraph')\n",
        "  get_lexstats(corpus_sects_df, model_base, text_unit='section')\n",
        "  get_lexstats(corpus_chaps_df, model_base, text_unit='chapter')\n",
        "\n",
        "  # Validate\n",
        "  corpus_lexicons_stats_dt\n",
        "\n",
        "  # corpus_lexicons_stats_dt['vader']['sents']['sentiment_max']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9lSo0Kmn_T4"
      },
      "source": [
        "# Verify \n",
        "\n",
        "if SenticNet_Arc == True:\n",
        "  # corpus_sents_df['senticnet'].plot(alpha=0.3)\n",
        "  corpus_sents_df['senticnet_stdscaler'].plot(alpha=0.3)\n",
        "  corpus_sents_df['senticnet_medianiqr'].plot(alpha=0.1)\n",
        "  plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cn4KQYpH3glK"
      },
      "source": [
        "### **Calculate NRC Sentiment Polarities (Optional: Auto)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USx6LRmoCFV8"
      },
      "source": [
        "if NRC_Arc == True:\n",
        "  model_base = 'nrc'\n",
        "  model_name = 'nrc_lnorm_medianiqr'\n",
        "\n",
        "  col_medianiqr = f'{model_base}_medianiqr'\n",
        "  col_meanstd = f'{model_base}_meanstd'\n",
        "\n",
        "  col_lnorm_medianiqr = f'{model_base}_lnorm_medianiqr'\n",
        "  col_lnorm_meanstd = f'{model_base}_lnorm_meanstd'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EdOTv3KoFEV"
      },
      "source": [
        "# Verify Lexicon subdirectory and datafiles\n",
        "!ls /gdrive/MyDrive/$LEXICONS_SUBDIR\n",
        "\n",
        "print('\\nTop of Dictionary datafile ----------')\n",
        "!head -n 5  /gdrive/MyDrive/$LEXICONS_SUBDIR/hash_sentiment_nrc.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFEszSc13glL"
      },
      "source": [
        "# Read Lexicon into DataFrame \n",
        "\n",
        "if NRC_Arc == True:\n",
        "\n",
        "  lexicon_nrc_df = get_lexicon(f'/gdrive/MyDrive/{LEXICONS_SUBDIR}/hash_sentiment_nrc.csv')\n",
        "  lexicon_nrc_df['x'] = lexicon_nrc_df['x'].astype('string')\n",
        "\n",
        "  # Clean/Reorg DataFrame\n",
        "  lexicon_nrc_df.drop(columns=['Unnamed: 0'], axis=1, inplace=True)\n",
        "  lexicon_nrc_df.rename(columns={'x':'word', 'y':'polarity'}, inplace=True)\n",
        "\n",
        "  # Verify\n",
        "  if (PLOT_OUTPUT == 'All'):\n",
        "    lexicon_nrc_df.head()\n",
        "    lexicon_nrc_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nAkx4Mv3glL"
      },
      "source": [
        "# Convert DataFrame to Dict[word] = polarity\n",
        "\n",
        "if NRC_Arc == True:\n",
        "\n",
        "  id = lexicon_nrc_df.word.values\n",
        "  values = lexicon_nrc_df.polarity.values\n",
        "\n",
        "  lexicon_nrc_dt =dict(zip(id, values))\n",
        "  # lexicon_jockersrinker_dt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv1nVSATb7z4"
      },
      "source": [
        "# Calculate NRC Sentiment [0,1,2]\n",
        "\n",
        "def nrc_discrete2continous_sentiment(text):\n",
        "  '''\n",
        "  Given a plain text string, give it to\n",
        "    Stanford Stanza (OpenNLP) to calculate sentiment for each word on a 3 point scale 0-2\n",
        "  Return a sentiment value for the entire sentence (sum of word sentiments/log(len of sentence)) \n",
        "    that approximates a normal distribution for all values\n",
        "    In order to get more fine grained measure of overall Sentence sentiment\n",
        "    Sentiment values will be Normalized/Standardized so absolute precision is not required\n",
        "  '''\n",
        "  text_sentiment_total = 0.\n",
        "  text_ls = text.split()\n",
        "  text_len = len(text_ls)\n",
        "  for aword in text_ls:\n",
        "    text_sentiment_total += lex_discrete2continous_sentiment(str(aword), lexicon_nrc_dt)\n",
        "  text_sentiment_norm = text_sentiment_total/(np.log(text_len)+10)\n",
        "\n",
        "  return text_sentiment_norm\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss3Xixo_CX2q"
      },
      "source": [
        "# Test\n",
        "\n",
        "if NRC_Arc == True:\n",
        "  sent_test='I hate Mondays.'\n",
        "  print(nrc_discrete2continous_sentiment(sent_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhqnljMSCX2w"
      },
      "source": [
        "# Calculate all the Sentence, Paragraph, Section and Chapter Sentiment Scores and Standardized variants\n",
        "\n",
        "# Calculate all Sentiment values and variants\n",
        "if NRC_Arc == True:\n",
        "  get_sentiments(model_base=model_base, sentiment_fn=nrc_discrete2continous_sentiment, sentiment_type='function')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2q97Dm-CX2z"
      },
      "source": [
        "# Get/Set Sentiment Statistics\n",
        "\n",
        "if NRC_Arc == True:\n",
        "  get_lexstats(corpus_sents_df, model_base, text_unit='sentence')\n",
        "  get_lexstats(corpus_parags_df, model_base, text_unit='paragraph')\n",
        "  get_lexstats(corpus_sects_df, model_base, text_unit='section')\n",
        "  get_lexstats(corpus_chaps_df, model_base, text_unit='chapter')\n",
        "\n",
        "  # Validate\n",
        "  corpus_lexicons_stats_dt\n",
        "\n",
        "  # corpus_lexicons_stats_dt['vader']['sents']['sentiment_max']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBK7LQx4oXI-"
      },
      "source": [
        "# Verify \n",
        "\n",
        "if NRC_Arc == True:\n",
        "  # corpus_sents_df['nrc'].plot(alpha=0.3)\n",
        "  corpus_sents_df['nrc_stdscaler'].plot(alpha=0.1)\n",
        "  corpus_sents_df['nrc_medianiqr'].plot(alpha=0.3)\n",
        "  plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRTjCPLb8cbB"
      },
      "source": [
        "### **Calculate Afinn Sentiment Polarities (Optional: Auto)**\n",
        "\n",
        "* https://github.com/fnielsen/afinn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcnxqnyzDCde"
      },
      "source": [
        "if AFINN_Arc == True:\n",
        "  model_base = 'afinn'\n",
        "  model_name = 'afinn_lnorm_medianiqr'\n",
        "\n",
        "  col_medianiqr = f'{model_base}_medianiqr'\n",
        "  col_meanstd = f'{model_base}_meanstd'\n",
        "\n",
        "  col_lnorm_medianiqr = f'{model_base}_lnorm_medianiqr'\n",
        "  col_lnorm_meanstd = f'{model_base}_lnorm_meanstd'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDG2KxvNBdj6"
      },
      "source": [
        "if AFINN_Arc == True:\n",
        "  !pip install afinn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evnkXWL58CcX"
      },
      "source": [
        "# Install and configure for English\n",
        "\n",
        "if AFINN_Arc == True:\n",
        "  from afinn import Afinn\n",
        "  afinn = Afinn(language='en')\n",
        "\n",
        "  # Test\n",
        "\n",
        "  # afinn.score('I had the worst day.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKbeW_cMXhmI"
      },
      "source": [
        "# Calculate AFINN Sentiment [0,1,2]\n",
        "\n",
        "def afinn_discrete2continous_sentiment(text):\n",
        "  '''\n",
        "  Given a plain text string, give it to\n",
        "    Stanford Stanza (OpenNLP) to calculate sentiment for each word on a 3 point scale 0-2\n",
        "  Return a sentiment value for the entire sentence (sum of word sentiments/log(len of sentence)) \n",
        "    that approximates a normal distribution for all values\n",
        "    In order to get more fine grained measure of overall Sentence sentiment\n",
        "    Sentiment values will be Normalized/Standardized so absolute precision is not required\n",
        "  '''\n",
        "  text_sentiment_total = 0.\n",
        "  text_ls = text.split()\n",
        "  text_len = len(text_ls)\n",
        "  for aword in text_ls:\n",
        "    text_sentiment_total += afinn.score(aword)\n",
        "  text_sentiment_norm = text_sentiment_total/(np.log(text_len)+0.1)\n",
        "\n",
        "  return float(text_sentiment_norm)  # return float vs np.float64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRCd4VpwDO0Q"
      },
      "source": [
        "# Test\n",
        "\n",
        "if AFINN_Arc == True:\n",
        "  sent_test='I hate Mondays.'\n",
        "  print(afinn_discrete2continous_sentiment(sent_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrP_wxB3DO0S"
      },
      "source": [
        "# Calculate all the Sentence, Paragraph, Section and Chapter Sentiment Scores and Standardized variants\n",
        "\n",
        "# Calculate all Sentiment values and variants\n",
        "if AFINN_Arc == True:\n",
        "  get_sentiments(model_base=model_base, sentiment_fn=afinn_discrete2continous_sentiment, sentiment_type='function')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgZaMPYKDO0T"
      },
      "source": [
        "# Get/Set Sentiment Statistics\n",
        "\n",
        "if AFINN_Arc == True:\n",
        "  get_lexstats(corpus_sents_df, model_base, text_unit='sentence')\n",
        "  get_lexstats(corpus_parags_df, model_base, text_unit='paragraph')\n",
        "  get_lexstats(corpus_sects_df, model_base, text_unit='section')\n",
        "  get_lexstats(corpus_chaps_df, model_base, text_unit='chapter')\n",
        "\n",
        "  # Validate\n",
        "  corpus_lexicons_stats_dt\n",
        "\n",
        "  # corpus_lexicons_stats_dt['vader']['sents']['sentiment_max']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clUzylGOog5h"
      },
      "source": [
        "# Verify \n",
        "\n",
        "if AFINN_Arc == True:\n",
        "  # corpus_sents_df['afinn'].plot(alpha=0.3)\n",
        "  corpus_sents_df['afinn_stdscaler'].plot(alpha=0.3)\n",
        "  corpus_sents_df['afinn_medianiqr'].plot(alpha=0.1)\n",
        "  plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAEiglIPDfFI"
      },
      "source": [
        "### **Calculate VADER Sentiment Polarities (Optional: Auto)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgkvefzpDgx-"
      },
      "source": [
        "if VADER_Arc == True:\n",
        "  model_base = 'vader'\n",
        "  model_name = 'vader_lnorm_medianiqr'\n",
        "\n",
        "  col_medianiqr = f'{model_base}_medianiqr'\n",
        "  col_meanstd = f'{model_base}_meanstd'\n",
        "\n",
        "  col_lnorm_medianiqr = f'{model_base}_lnorm_medianiqr'\n",
        "  col_lnorm_meanstd = f'{model_base}_lnorm_meanstd'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wodGtjXhDmZN"
      },
      "source": [
        "if VADER_Arc == True:\n",
        "  # Sentiment evaluation function\n",
        "  sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "  # Test\n",
        "  sid.polarity_scores('hello world')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS8e25MkDmZP"
      },
      "source": [
        "# Calculate all the Sentence, Paragraph, Section and Chapter Sentiment Scores and Standardized variants\n",
        "\n",
        "if VADER_Arc == True:\n",
        "  get_sentiments(model_base=model_base, sentiment_fn=sid.polarity_scores, sentiment_type='compound')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2Azyv2lDmZP"
      },
      "source": [
        "# Get/Set Sentiment Statistics\n",
        "\n",
        "if VADER_Arc == True:\n",
        "  get_lexstats(corpus_sents_df, model_base, text_unit='sentence')\n",
        "  get_lexstats(corpus_parags_df, model_base, text_unit='paragraph')\n",
        "  get_lexstats(corpus_sects_df, model_base, text_unit='section')\n",
        "  get_lexstats(corpus_chaps_df, model_base, text_unit='chapter')\n",
        "\n",
        "  # Validate\n",
        "  corpus_lexicons_stats_dt\n",
        "\n",
        "  # corpus_lexicons_stats_dt['vader']['sents']['sentiment_max']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq8KNwpjom4X"
      },
      "source": [
        "# Verify \n",
        "\n",
        "if VADER_Arc == True:\n",
        "  # corpus_sents_df['vader'].plot(alpha=0.3)\n",
        "  corpus_sents_df['vader_stdscaler'].plot(alpha=0.1)\n",
        "  corpus_sents_df['vader_medianiqr'].plot(alpha=0.3)\n",
        "  plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCN4c-G48e7-"
      },
      "source": [
        "### **Calculate TextBlob Sentiment Polarities (Optional: Auto)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MfVWZ34Vg8U"
      },
      "source": [
        "if TextBlob_Arc == True:\n",
        "  model_base = 'textblob'\n",
        "  model_name = 'textblob_lnorm_medianiqr'\n",
        "\n",
        "  col_medianiqr = f'{model_base}_medianiqr'\n",
        "  col_meanstd = f'{model_base}_meanstd'\n",
        "\n",
        "  col_lnorm_medianiqr = f'{model_base}_lnorm_medianiqr'\n",
        "  col_lnorm_meanstd = f'{model_base}_lnorm_meanstd'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "118Blghk7fjp"
      },
      "source": [
        "if TextBlob_Arc == True:\n",
        "  from textblob import TextBlob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhJsYxPoVhY4"
      },
      "source": [
        "# Calculate all the Sentence, Paragraph, Section and Chapter Sentiment Scores and Standardized variants\n",
        "\n",
        "def textblob_sentiment(text_str):\n",
        "  '''\n",
        "  Given a text string\n",
        "  Return a sentiment value between -1.0 to +1.0 using TextBlob\n",
        "  '''\n",
        "  return TextBlob(text_str).sentiment.polarity\n",
        "\n",
        "# Calculate all Sentiment values and variants\n",
        "if TextBlob_Arc == True:\n",
        "  get_sentiments(model_base=model_base, sentiment_fn=textblob_sentiment, sentiment_type='function')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlHRf2aFVhY7"
      },
      "source": [
        "# Get/Set Sentiment Statistics\n",
        "\n",
        "if TextBlob_Arc == True:\n",
        "  get_lexstats(corpus_sents_df, model_name, text_unit='sentence')\n",
        "  get_lexstats(corpus_parags_df, model_name, text_unit='paragraph')\n",
        "  get_lexstats(corpus_sects_df, model_name, text_unit='section')\n",
        "  get_lexstats(corpus_chaps_df, model_name, text_unit='chapter')\n",
        "\n",
        "  # Validate\n",
        "  corpus_lexicons_stats_dt\n",
        "\n",
        "  # corpus_lexicons_stats_dt['vader']['sents']['sentiment_max']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMWewkTgord1"
      },
      "source": [
        "# Verify \n",
        "\n",
        "if TextBlob_Arc == True:\n",
        "  # corpus_sents_df['textblob'].plot(alpha=0.3)\n",
        "  corpus_sents_df['textblob_stdscaler'].plot(alpha=0.3)\n",
        "  corpus_sents_df['textblob_medianiqr'].plot(alpha=0.1)\n",
        "  plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2blGfVlKb_s"
      },
      "source": [
        "### **Calculate Pattern Sentiment Polarities (Optional: Auto)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU60-nqpCsl7"
      },
      "source": [
        "if Pattern_Arc == True:\n",
        "  model_base = 'pattern'\n",
        "  model_name = 'pattern_lnorm_medianiqr'\n",
        "\n",
        "  col_medianiqr = f'{model_base}_medianiqr'\n",
        "  col_meanstd = f'{model_base}_meanstd'\n",
        "\n",
        "  col_lnorm_medianiqr = f'{model_base}_lnorm_medianiqr'\n",
        "  col_lnorm_meanstd = f'{model_base}_lnorm_meanstd'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KxnLfHoL3Fy"
      },
      "source": [
        "if Pattern_Arc == True:\n",
        "  !pip install pattern"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtwmIrSOKZRm"
      },
      "source": [
        "if Pattern_Arc == True:\n",
        "  from pattern.en import sentiment as pattern_sa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vwtm_jBKZM2"
      },
      "source": [
        "# Test\n",
        "\n",
        "if Pattern_Arc == True:\n",
        "  sent_test='I hate Mondays.'\n",
        "  pattern_sa(sent_test)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXq-jDPxasVY"
      },
      "source": [
        "# Calculate Pattern Sentiment [0,1,2]\n",
        "\n",
        "def pattern_discrete2continous_sentiment(text):\n",
        "  '''\n",
        "  Given a plain text string, give it to\n",
        "    Stanford Stanza (OpenNLP) to calculate sentiment for each word on a 3 point scale 0-2\n",
        "  Return a sentiment value for the entire sentence (sum of word sentiments/log(len of sentence)) \n",
        "    that approximates a normal distribution for all values\n",
        "    In order to get more fine grained measure of overall Sentence sentiment\n",
        "    Sentiment values will be Normalized/Standardized so absolute precision is not required\n",
        "  '''\n",
        "  text_sentiment_total = 0.\n",
        "  text_ls = text.split()\n",
        "  text_len = len(text_ls)\n",
        "  for aword in text_ls:\n",
        "    text_sentiment_total += pattern_sa(str(aword))[0]\n",
        "  text_sentiment_norm = text_sentiment_total/(np.log(text_len)+0.01)\n",
        "\n",
        "  return text_sentiment_norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-sXRBNWC08o"
      },
      "source": [
        "# Test\n",
        "\n",
        "if Pattern_Arc == True:\n",
        "  sent_test='I hate Mondays.'\n",
        "  print(pattern_discrete2continous_sentiment(sent_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db0hezLKC08p"
      },
      "source": [
        "# Calculate all the Sentence, Paragraph, Section and Chapter Sentiment Scores and Standardized variants\n",
        "\n",
        "# Calculate all Sentiment values and variants\n",
        "if Pattern_Arc == True:\n",
        "  get_sentiments(model_base=model_base, sentiment_fn=pattern_discrete2continous_sentiment, sentiment_type='function')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGHixqpOC08q"
      },
      "source": [
        "# Get/Set Sentiment Statistics\n",
        "\n",
        "if Pattern_Arc == True:\n",
        "  get_lexstats(corpus_sents_df, model_base, text_unit='sentence')\n",
        "  get_lexstats(corpus_parags_df, model_base, text_unit='paragraph')\n",
        "  get_lexstats(corpus_sects_df, model_base, text_unit='section')\n",
        "  get_lexstats(corpus_chaps_df, model_base, text_unit='chapter')\n",
        "\n",
        "  # Validate\n",
        "  corpus_lexicons_stats_dt\n",
        "\n",
        "  # corpus_lexicons_stats_dt['vader']['sents']['sentiment_max']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clydVLby2KhG"
      },
      "source": [
        "# Verify \n",
        "\n",
        "if Pattern_Arc == True:\n",
        "  # corpus_sents_df['pattern'].plot(alpha=0.3)\n",
        "  corpus_sents_df['pattern_stdscaler'].plot(alpha=0.3)\n",
        "  corpus_sents_df['pattern_medianiqr'].plot(alpha=0.1)\n",
        "  plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-X3xNWkoyLS"
      },
      "source": [
        "# Verify \n",
        "\n",
        "if Pattern_Arc == True:\n",
        "  corpus_sents_df['pattern'].rolling(10*win_s1per, center=True).mean().plot();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQwX3APKnhjP"
      },
      "source": [
        "corpus_sents_df['pattern'].plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cM1OmuaiVQIH"
      },
      "source": [
        "# Check Pattern Series for Outliers\n",
        "\n",
        "if Pattern_Arc == True:\n",
        "  print('Furthest Positive Outlier in Pattern Time Series:')\n",
        "  corpus_sents_df[corpus_sents_df['pattern'] == corpus_sents_df['pattern'].max()][['sent_no', 'pattern', 'sent_raw']]\n",
        "\n",
        "  pattern_max_sentno = int(corpus_sents_df[corpus_sents_df['pattern'] == corpus_sents_df['pattern'].max()][['sent_no']].max())\n",
        "  print(f'Max Outlier for Pattern Sentiment Model is at Sentence #{pattern_max_sentno}')\n",
        "\n",
        "  print('Furthest Negative Outlier in Pattern Time Series:')\n",
        "  corpus_sents_df[corpus_sents_df['pattern'] == corpus_sents_df['pattern'].min()][['sent_no', 'pattern', 'sent_raw']]\n",
        "\n",
        "  pattern_min_sentno = int(corpus_sents_df[corpus_sents_df['pattern'] == corpus_sents_df['pattern'].min()][['sent_no']].min())\n",
        "  print(f'Max Outlier for Pattern Sentiment Model is at Sentence #{pattern_min_sentno}')\n",
        "\n",
        "  print('\\n')\n",
        "  print('Median Absolute Deviation (MAD) for Pattern Time Series:')\n",
        "  robust.mad(corpus_sents_df['pattern'])\n",
        "\n",
        "  temp_df = pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny19347PZ85l"
      },
      "source": [
        "# Verify what is happening in the neighborhood of the Maximum Sentiment Outlier for Pattern\n",
        "\n",
        "if Pattern_Arc == True:\n",
        "  outlier_halfwin = 10\n",
        "  outlier_winstart = pattern_max_sentno - outlier_halfwin\n",
        "  outlier_winend = pattern_max_sentno + outlier_halfwin\n",
        "\n",
        "  corpus_sents_df.iloc[outlier_winstart:outlier_winend]['pattern'].plot();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRDctGTdUfKk"
      },
      "source": [
        "# Pattern library has a bug wherein a/several Sentences have far outlying Sentiments\n",
        "#   we need to clip these to within n * MAD\n",
        "\n",
        "if Pattern_Arc == True:\n",
        "  MAD_Clip_Boundary = 5.2 #@param {type:\"slider\", min:1.0, max:10, step:0.1}\n",
        "\n",
        "  # find the limits of 2.5 Median Absolute Deviation of Pattern Time Series\n",
        "\n",
        "  clip_25mad = MAD_Clip_Boundary * robust.mad(corpus_sents_df['pattern'])\n",
        "  print(f'Clip Pattern Series at 2.5 x Median Absolute Deviation (MAD) = {clip_25mad}')\n",
        "\n",
        "  # Create a Temporary DataFrame to test/find best MAD Clipping multiplier for Pattern\n",
        "  temp_df['pattern'] = pd.Series(corpus_sents_df['pattern'].clip(upper=clip_25mad))\n",
        "  temp_df['pattern'].clip(lower=-clip_25mad, inplace=True)\n",
        "\n",
        "  # Verify \n",
        "  temp_df['pattern'].plot();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "co3jaquyZom7"
      },
      "source": [
        "# Once a good Clip_MAD_multiplier if found, update Pattern Time Series with it\n",
        "\n",
        "if Pattern_Arc == True:\n",
        "  corpus_sents_df['pattern'] = temp_df['pattern']\n",
        "  corpus_sents_df['pattern'].plot();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsaziON_Z263"
      },
      "source": [
        "### **Calculate Stanza/OpenNLP Sentiment Polarities (Optional: Auto)**\n",
        "\n",
        "* https://github.com/piyushpathak03/NLP-using-STANZA/blob/main/Stanza.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZgGfcCuFnmI"
      },
      "source": [
        "if Stanza_Arc == True:\n",
        "  model_base = 'stanza'\n",
        "  model_name = 'stanza_lnorm_medianiqr'\n",
        "\n",
        "  col_medianiqr = f'{model_base}_medianiqr'\n",
        "  col_meanstd = f'{model_base}_meanstd'\n",
        "\n",
        "  col_lnorm_medianiqr = f'{model_base}_lnorm_medianiqr'\n",
        "  col_lnorm_meanstd = f'{model_base}_lnorm_meanstd'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoZUi2AwZ_7L"
      },
      "source": [
        "if Stanza_Arc == True:\n",
        "  !pip install stanza"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5txTb6aIZ2tN"
      },
      "source": [
        "%time\n",
        "\n",
        "import stanza\n",
        "\n",
        "if Stanza_Arc == True:\n",
        "  stanza.download('en')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NORYbxsxZ2qg"
      },
      "source": [
        "if Stanza_Arc == True:\n",
        "  nlp = stanza.Pipeline('en', processors='tokenize,sentiment')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtOtBfYwZ2na"
      },
      "source": [
        "# Test stanza directly\n",
        "\n",
        "# doc = nlp('Ram is a bad boy')\n",
        "# for i, sentence in enumerate(doc.sentences):\n",
        "#     print(i, sentence.sentiment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKnox67kayod"
      },
      "source": [
        "# Calculate Stanza Sentiment [0,1,2]\n",
        "\n",
        "def stanza_discrete2continous_sentiment(text):\n",
        "  '''\n",
        "  Given a plain text string, give it to\n",
        "    Stanford Stanza (OpenNLP) to calculate sentiment for each word on a 3 point scale 0-2\n",
        "  Return a sentiment value for the entire sentence (sum of word sentiments/log(len of sentence)) \n",
        "    that approximates a normal distribution for all values\n",
        "    In order to get more fine grained measure of overall Sentence sentiment\n",
        "    Sentiment values will be Normalized/Standardized so absolute precision is not required\n",
        "  '''\n",
        "  text_sentiment_tot = 0.\n",
        "  text_ls = text.split()\n",
        "  text_len = len(text_ls)\n",
        "  for aword in text_ls:\n",
        "    adoc = nlp(aword)\n",
        "    for i, sentence in enumerate(adoc.sentences):\n",
        "      text_sentiment_tot += float(sentence.sentiment)\n",
        "  text_sentiment_norm = text_sentiment_tot/(np.log(text_len)+0.1)\n",
        "\n",
        "  return text_sentiment_norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNngkBBAF26C"
      },
      "source": [
        "# Test\n",
        "\n",
        "if Stanza_Arc == True:\n",
        "  sent_test='I hate Mondays.'\n",
        "  print(stanza_discrete2continous_sentiment(sent_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrY2mrhVF26D"
      },
      "source": [
        "# Calculate all the Sentence, Paragraph, Section and Chapter Sentiment Scores and Standardized variants\n",
        "\n",
        "# NOTE: requires about 30-50mins (20210708 at 0730) Colab Pro: GPU+RAM \n",
        "\n",
        "# Calculate all Sentiment values and variants\n",
        "if Stanza_Arc == True:\n",
        "  get_sentiments(model_base=model_base, sentiment_fn=stanza_discrete2continous_sentiment, sentiment_type='function')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSiYC73nF26D"
      },
      "source": [
        "# Get/Set Sentiment Statistics\n",
        "\n",
        "if Stanza_Arc == True:\n",
        "  get_lexstats(corpus_sents_df, model_base, text_unit='sentence')\n",
        "  get_lexstats(corpus_parags_df, model_base, text_unit='paragraph')\n",
        "  get_lexstats(corpus_sects_df, model_base, text_unit='section')\n",
        "  get_lexstats(corpus_chaps_df, model_base, text_unit='chapter')\n",
        "\n",
        "  # Validate\n",
        "  corpus_lexicons_stats_dt\n",
        "\n",
        "  # corpus_lexicons_stats_dt['vader']['sents']['sentiment_max']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5tUYZA1DExu"
      },
      "source": [
        "# Verify \n",
        "\n",
        "if Stanza_Arc == True:\n",
        "  # corpus_sents_df['stanza'].plot(alpha=0.3)\n",
        "  corpus_sents_df['stanza_stdscaler'].plot(alpha=0.3)\n",
        "  corpus_sents_df['stanza_medianiqr'].plot(alpha=0.1)\n",
        "  plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIGQgWvyOtg6"
      },
      "source": [
        "### **Calculate Flair Sentiment Polarities (Optional: Auto)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWbcaaDDO1J1"
      },
      "source": [
        "if Flair_Arc == True:\n",
        "  model_base = 'flair'\n",
        "  model_name = 'flair_lnorm_medianiqr'\n",
        "\n",
        "  col_medianiqr = f'{model_base}_medianiqr'\n",
        "  col_meanstd = f'{model_base}_meanstd'\n",
        "\n",
        "  col_lnorm_medianiqr = f'{model_base}_lnorm_medianiqr'\n",
        "  col_lnorm_meanstd = f'{model_base}_lnorm_meanstd'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooLdktLHO1J3"
      },
      "source": [
        "if Flair_Arc == True:\n",
        "  !pip install flair"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77-3mVyRPJbb"
      },
      "source": [
        "if Flair_Arc == True:\n",
        "  from flair.models import TextClassifier\n",
        "  from flair.data import Sentence\n",
        "\n",
        "  classifier = TextClassifier.load('en-sentiment')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJOopGZhO1J5"
      },
      "source": [
        "# Test\n",
        "\n",
        "if Flair_Arc == True:\n",
        "  sentence = Sentence('The food was great!')\n",
        "  classifier.predict(sentence)\n",
        "\n",
        "  # print sentence with predicted labels\n",
        "  print('Sentence above is: ', sentence.labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7fZT10HQDqd"
      },
      "source": [
        "def get_flairsentiment(text_str):\n",
        "  # TODO: For efficiency, combine sentences in batches as arrays (if possible)\n",
        "  '''\n",
        "  Given a text string\n",
        "  Return a floating point -1.0 to 1.0 value for Sentiment\n",
        "  '''\n",
        "\n",
        "  text_tokenized_obj = Sentence(text_str)\n",
        "  classifier.predict(text_tokenized_obj)\n",
        "\n",
        "  sentiment_str = str(text_tokenized_obj.labels[0])\n",
        "\n",
        "  sentiment_ls = sentiment_str.split(' ')\n",
        "  \n",
        "  sentiment_sign = sentiment_ls[0]\n",
        "\n",
        "  if sentiment_sign.lower() == 'positive':\n",
        "    sign_multiplier = 1.0\n",
        "  else:\n",
        "    sign_multiplier = -1.0\n",
        "\n",
        "  sentiment_abs = float(sentiment_ls[1][1:-1])\n",
        "\n",
        "  sentiment_fl = sign_multiplier * sentiment_abs \n",
        "\n",
        "  return sentiment_fl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbgQVQlNSdcE"
      },
      "source": [
        "# Test\n",
        "\n",
        "if Flair_Arc == True:\n",
        "  get_flairsentiment('it is.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX0PDn5AO1J9"
      },
      "source": [
        "# Calculate all the Sentence, Paragraph, Section and Chapter Sentiment Scores and Standardized variants\n",
        "\n",
        "# Calculate all Sentiment values and variants\n",
        "if Flair_Arc == True:\n",
        "  get_sentiments(model_base=model_base, sentiment_fn=get_flairsentiment, sentiment_type='function')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vlK-dyHO1J-"
      },
      "source": [
        "# Get/Set Sentiment Statistics\n",
        "\n",
        "if Flair_Arc == True:\n",
        "  get_lexstats(corpus_sents_df, model_base, text_unit='sentence')\n",
        "  get_lexstats(corpus_parags_df, model_base, text_unit='paragraph')\n",
        "  get_lexstats(corpus_sects_df, model_base, text_unit='section')\n",
        "  get_lexstats(corpus_chaps_df, model_base, text_unit='chapter')\n",
        "\n",
        "  # Validate\n",
        "  corpus_lexicons_stats_dt\n",
        "\n",
        "  # corpus_lexicons_stats_dt['vader']['sents']['sentiment_max']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VycWC2gDO1J_"
      },
      "source": [
        "# Verify \n",
        "\n",
        "if Flair_Arc == True:\n",
        "  corpus_sents_df['flair'].plot(alpha=0.3)\n",
        "  corpus_sents_df['flair_stdscaler'].plot(alpha=0.3)\n",
        "  corpus_sents_df['flair_medianiqr'].plot(alpha=0.1)\n",
        "  plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfMwbhVMwgXw"
      },
      "source": [
        "### **(Optional) Calculate SentimentR and SyuzhetR Sentiments in RStudio**\n",
        "\n",
        "**NOTE** Process in RStudio with the following R Script\n",
        "```\n",
        "# Setup\n",
        "library('syuzhet')\n",
        "# getwd()\n",
        "# list.files(pattern=’*.txt’)\n",
        "\n",
        "\n",
        "# Set Input Corpus textfile\n",
        "# corpus_input = 'vwoolf_tothelighthouse.txt'\n",
        "\n",
        "###\n",
        "corpus_input = 'vwoolf_tothelighthouse.txt'\n",
        "###\n",
        "\n",
        "\n",
        "# corpus_input = 'confessions_staugustine'\n",
        "# Set Output Sentiments Datafile names\n",
        "#  corpus_output = 'sum_sentiments_vwoolf_tothelighthouse_4models.csv'\n",
        "\n",
        "###\n",
        "syuzhet_output = 'sum_sentimentsvwoolf_tothelighthouse_syuzhetR_4models.csv'\n",
        "###\n",
        "\n",
        "# Use 4 Models in Syuzhet to parse Corpus and generate 4 Sentiment Time Series\n",
        "syuzhet_str <- syuzhet::get_text_as_string(syuzhet_input)\n",
        "syuzhet_sents_v <- syuzhet::get_sentences(syuzhet_str)\n",
        "\n",
        "syuzhet_all_df <- data.frame(sent_raw =syuzhet_sents_v)\n",
        "\n",
        "syuzhet_all_df$syuzhet <- syuzhet::get_sentiment(corpus_sents_v, method='syuzhet')\n",
        "syuzhet_all_df$bing <- syuzhet::get_sentiment(corpus_sents_v, method='bing')\n",
        "syuzhet_all_df$afinn <- syuzhet::get_sentiment(corpus_sents_v, method='afinn')\n",
        "syuzhet_all_df$nrc <- syuzhet::get_sentiment(corpus_sents_v, method='nrc')\n",
        "\n",
        "\n",
        "# Save Results    \n",
        "# write.csv(rc_ddefoe_all_df, ‘sum_sentiments_rc_ddefoe_syuzhetR_4models.csv’)\n",
        "write.csv(syuzhet_all_df, syuzhet_output)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "library('sentimentr')\n",
        "# conflict with syuzhet::get_sentences\n",
        "# getwd()\n",
        "# list.files(pattern=’*.txt’)\n",
        "\n",
        "# Set Input Corpus textfile\n",
        "# corpus_input = 'ddefoe_robinsoncrusoe_final_hand.txt'\n",
        "# sentimentr_input = 'ttl_final_hand.txt'\n",
        "sentimentr_input = corpus_input\n",
        "\n",
        "# Set Output Sentiments Datafile names\n",
        "\n",
        "###\n",
        "sentimentr_output = 'sum_sentiments_vwoolf_tothelighthouse_sentimentR_7models.csv'\n",
        "###\n",
        "\n",
        "# continuing from syuzhet code above we inherit global var: syuzhet_sents_v\n",
        "# SentimentR recommends reparsing these with sentimentr::get_sentences(rc_ddefoe_sents_v)\n",
        "sentimentr_sents_v <- sentimentr::get_sentences(syuzhet_sents_v)\n",
        "\n",
        "# Create data.frame with jockers_rinker sentiments\n",
        "sentimentr_all_df <- data.frame(sent_raw = syuzhet_sents_v)\n",
        "\n",
        "# Add other lexicon sentiments\n",
        "sentimentr_all_df$jockers_rinker <- sentimentr::sentiment(sentimentr_sents_v, polarity_dt=lexicon::hash_sentiment_jockers_rinker, hyphen=\" \", neutral.nonverb.like=TRUE)$sentiment\n",
        "sentimentr_all_df$jockers <- sentimentr::sentiment(sentimentr_sents_v, polarity_dt=lexicon::hash_sentiment_jockers, hyphen=\" \", neutral.nonverb.like=TRUE)$sentiment\n",
        "sentimentr_all_df$huliu <- sentimentr::sentiment(sentimentr_sents_v, polarity_dt=lexicon::hash_sentiment_huliu, hyphen=\" \", neutral.nonverb.like=TRUE)$sentiment\n",
        "sentimentr_all_df$lmcd <- sentimentr::sentiment(sentimentr_sents_v, polarity_dt=lexicon::hash_sentiment_loughran_mcdonald, hyphen=\" \", neutral.nonverb.like=TRUE)$sentiment\n",
        "sentimentr_all_df$nrc <- sentimentr::sentiment(sentimentr_sents_v, polarity_dt=lexicon::hash_sentiment_nrc, hyphen=\" \", neutral.nonverb.like=TRUE)$sentiment\n",
        "sentimentr_all_df$senticnet <- sentimentr::sentiment(sentimentr_sents_v, polarity_dt=lexicon::hash_sentiment_senticnet, hyphen=\" \", neutral.nonverb.like=TRUE)$sentiment\n",
        "sentimentr_all_df$sentiword <- sentimentr::sentiment(sentimentr_sents_v, polarity_dt=lexicon::hash_sentiment_sentiword, hyphen=\" \", neutral.nonverb.like=TRUE)$sentiment\n",
        "\n",
        "write.csv(sentimentr_all_df, sentimentr_output)\n",
        "\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNCGf1KZEpld"
      },
      "source": [
        "## **Save Checkpoint**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q5JJa0TqlEE"
      },
      "source": [
        "corpus_sents_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FblNRdEbMm_b"
      },
      "source": [
        "corpus_sents_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMRog9JWk40F"
      },
      "source": [
        "# Save Corpus Text DataFrames and Sentiment Values\n",
        "\n",
        "save_dataframes()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNkAJzWhEpld"
      },
      "source": [
        "# Save Preprocessed Corpus Sentences DataFrame\n",
        "\n",
        "# author_str = ''.join(CORPUS_AUTHOR.split()).lower()\n",
        "title_str = ''.join(CORPUS_FILENAME.split('.')[0]).lower()\n",
        "datetime_now = datetime.utcnow().strftime(\"%Y%m%d_%H%M\")\n",
        "\n",
        "\"\"\"\n",
        "# Save Sentences of original Raw and Cleaned Corpus\n",
        "corpus_text_sentences_raw_filename = f'corpus_text_sentences_raw_{title_str}.csv' # _{datetime_now}.txt'\n",
        "print(f'Saving Corpus text raw sentences to file: {corpus_text_sentences_raw_filename}')\n",
        "corpus_sents_df['sent_raw'].to_csv(corpus_text_sentences_raw_filename)\n",
        "\n",
        "corpus_text_sentences_clean_filename = f'corpus_text_sentences_clean_{title_str}.csv' # _{datetime_now}.txt'\n",
        "print(f'Saving Corpus text clean sentences to file: {corpus_text_sentences_clean_filename}')\n",
        "corpus_sents_df['sent_clean'].to_csv(corpus_text_sentences_clean_filename)\n",
        "\n",
        "\n",
        "# Save Paragraphs of original Raw and Cleaned Corpus\n",
        "corpus_text_paragraphs_raw_filename = f'corpus_text_paragraphs_raw_{title_str}.csv' # _{datetime_now}.txt'\n",
        "print(f'Saving Corpus text raw paragraphs to file: {corpus_text_paragraphs_raw_filename}')\n",
        "corpus_parags_df['parag_raw'].to_csv(corpus_text_paragraphs_raw_filename)\n",
        "\n",
        "corpus_text_paragraphs_clean_filename = f'corpus_text_paragraphs_clean_{title_str}.csv' # _{datetime_now}.txt'\n",
        "print(f'Saving Corpus text clean sentences to file: {corpus_text_paragraphs_clean_filename}')\n",
        "corpus_parags_df['parag_clean'].to_csv(corpus_text_paragraphs_clean_filename)\n",
        "\n",
        "\"\"\";\n",
        "\n",
        "# Save DataFrames that divide Corpus at Sentence, Paragraph, Section and Chapter Levels\n",
        "corpus_sents_filename = f'corpus_sents_baselines_{title_str}.csv' # _{datetime_now}.csv'\n",
        "print(f'Saving Corpus Sentences to file: {corpus_sents_filename}')\n",
        "corpus_sents_df.to_csv(corpus_sents_filename)\n",
        "\n",
        "corpus_parags_filename = f'sum_sentiments_parags_baselines_{title_str}.csv' # _{datetime_now}.csv'\n",
        "print(f'Saving Corpus Paragraphs to file: {corpus_parags_filename}')\n",
        "corpus_parags_df.to_csv(corpus_parags_filename)\n",
        "\n",
        "corpus_sects_filename = f'sum_sentiments_sects_baselines_{title_str}.csv' # _{datetime_now}.csv'\n",
        "print(f'Saving Corpus Sections to file: {corpus_sects_filename}')\n",
        "corpus_sects_df.to_csv(corpus_sects_filename)\n",
        "\n",
        "corpus_chaps_filename = f'sum_sentiments_chaps_baselines_{title_str}.csv' # _{datetime_now}.csv'\n",
        "print(f'Saving Corpus Chapters to file: {corpus_chaps_filename}')\n",
        "corpus_chaps_df.to_csv(corpus_chaps_filename)\n",
        "\n",
        "\"\"\"\n",
        "# Save Sentiment Values from Models\n",
        "\n",
        "corpus_sents_filename = f'sum_sentiments_sents_baselines_{title_str}.csv' # _{datetime_now}.csv'\n",
        "print(f'Saving Corpus Sentences to file: {corpus_sents_filename}')\n",
        "corpus_sents_df.to_csv(corpus_sents_filename)\n",
        "\n",
        "corpus_parags_filename = f'sum_sentiments_parags_baselines_{title_str}.csv' # _{datetime_now}.csv'\n",
        "print(f'Saving Corpus Paragraphs to file: {corpus_parags_filename}')\n",
        "corpus_parags_df.to_csv(corpus_parags_filename)\n",
        "\n",
        "corpus_sects_filename = f'sum_sentiments_sects_baselines_{title_str}.csv' # _{datetime_now}.csv'\n",
        "print(f'Saving Corpus Sections to file: {corpus_sects_filename}')\n",
        "corpus_sects_df.to_csv(corpus_sects_filename)\n",
        "\n",
        "corpus_chaps_filename = f'sum_sentiments_chaps_baselines_{title_str}.csv' # _{datetime_now}.csv'\n",
        "print(f'Saving Corpus Chapters to file: {corpus_chaps_filename}')\n",
        "corpus_chaps_df.to_csv(corpus_chaps_filename)\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0s6LIujwDD2"
      },
      "source": [
        "# **Explore Sentiment Models and Arcs**\n",
        "\n",
        "Baseline Models\n",
        "\n",
        "* VADER [-1.0 to 1.0] zero peak\n",
        "* TextBlob [-1.0 to 1.0] zero peak\n",
        "* Stanza outliers [-1.0 to 199.0] pos, outliers(+peak)\n",
        "* AFINN [-14 (-8 to 8) 20] discrete\n",
        "* SentimentR 11,710 [-5.4 to 8.8] norm\n",
        "* Syuzhet [-5.4 to 8.8] norm\n",
        "* Bing [-100.0 (-20.0 to 20.0) 100] discrete, outliers\n",
        "* Pattern [-1.0 to 1.0] norm\n",
        "* SentiWord [-3.8 to 4.4] norm\n",
        "* SenticNet [-3.8 to 10] norm\n",
        "* NRC [-100.0 (-5.0 to 5.0) 100] zero, outliers\n",
        "\n",
        "SentimentR Models\n",
        "\n",
        "* Jockers_Rinker\n",
        "* Jockers\n",
        "* HuLiu\n",
        "* NRC\n",
        "* Loughran-McDonald\n",
        "* SenticNet\n",
        "* SentiWord\n",
        "\n",
        "SyuzhetR Models\n",
        "\n",
        "* Syuzhet\n",
        "* Bing\n",
        "* AFINN\n",
        "* NRC\n",
        "\n",
        "Tranformer Models\n",
        "\n",
        "* NLPTown\n",
        "* RoBERTa Large 15 Datasets\n",
        "* BERT Yelp Dataset\n",
        "* BERT Code Switching Hinglish\n",
        "* IMDB 2-way \n",
        "* Huggingface Default (Distilled BERT)\n",
        "* T5 IMDB 50k Dataset\n",
        "* RoBERTa XML 8 Languages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGqpjXvRwS20"
      },
      "source": [
        "## **EDA Baseline Plots**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8gYxSS0GRWk"
      },
      "source": [
        "# Create SMA roll=10% for all models_stdscaler as baseline\n",
        "\n",
        "win_s1per = int(corpus_sents_df.shape[0] * 1/100)\n",
        "\n",
        "col_stdscaler_roll_ls = []\n",
        "for amodel in models_baseline_ls:\n",
        "  col_stdscaler = f'{amodel}_stdscaler'\n",
        "  col_stdscaler_roll = f'{amodel}_stdscaler_{roll_str}'\n",
        "  corpus_sents_df[col_stdscaler_roll] = corpus_sents_df[col_stdscaler].rolling(10*win_s1per, center=True).mean()\n",
        "  col_stdscaler_roll_ls.append(col_stdscaler_roll)\n",
        "\n",
        "col_stdscaler_roll_mean = col_stdscaler_roll + '_mean'\n",
        "corpus_sents_df[col_stdscaler_roll_mean] = corpus_sents_df[col_stdscaler_roll_ls].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZYRLVQYH6__"
      },
      "source": [
        "corpus_sents_df[col_stdscaler_roll_ls].plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJJNNaxR0iJ0"
      },
      "source": [
        "##### **Sentence SMA Plots**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqmU4QRLOClI"
      },
      "source": [
        "# Sentence Plotly Interactive/Zoom Sentiment Plots\n",
        "\n",
        "SMA_Window_Percent = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "SentimentR_Arc = True #@param {type:\"boolean\"}\n",
        "Syuzhet_Arc = True #@param {type:\"boolean\"}\n",
        "Bing_Arc = True #@param {type:\"boolean\"}\n",
        "SenticNet_Arc = True #@param {type:\"boolean\"}\n",
        "SentiWord_Arc = True #@param {type:\"boolean\"}\n",
        "NRC_Arc = True #@param {type:\"boolean\"}\n",
        "AFINN_Arc = True #@param {type:\"boolean\"}\n",
        "VADER_Arc = True #@param {type:\"boolean\"}\n",
        "TextBlob_Arc = True #@param {type:\"boolean\"}\n",
        "Flair_Arc = True #@param {type:\"boolean\"}\n",
        "Pattern_Arc = True #@param {type:\"boolean\"}\n",
        "Stanza_Arc = True #@param {type:\"boolean\"}\n",
        "Mean_All_Arc = True #@param {type:\"boolean\"}\n",
        "# Mean_Subset_Arc = False #@param {type:\"boolean\"}\n",
        "# MPQA_Arc = False #@param {type:\"boolean\"}\n",
        "# SentiStrength_Arc = False #@param {type:\"boolean\"}\n",
        "\n",
        "models_subset_ls = []\n",
        "if SentimentR_Arc == True:\n",
        "  models_subset_ls.append('sentimentr')\n",
        "if Syuzhet_Arc == True:\n",
        "  models_subset_ls.append('syuzhet')\n",
        "if Bing_Arc == True:\n",
        "  models_subset_ls.append('bing')\n",
        "if SenticNet_Arc == True:\n",
        "  models_subset_ls.append('senticnet')\n",
        "if SentiWord_Arc == True:\n",
        "  models_subset_ls.append('sentiword')\n",
        "if NRC_Arc == True:\n",
        "  models_subset_ls.append('nrc')\n",
        "if AFINN_Arc == True:\n",
        "  models_subset_ls.append('afinn')\n",
        "if VADER_Arc == True:\n",
        "  models_subset_ls.append('vader')\n",
        "if TextBlob_Arc == True:\n",
        "  models_subset_ls.append('textblob')\n",
        "if Flair_Arc == True:\n",
        "  models_subset_ls.append('flair')\n",
        "if Pattern_Arc == True:\n",
        "  models_subset_ls.append('pattern')\n",
        "if Stanza_Arc == True:\n",
        "  models_subset_ls.append('stanza')\n",
        "if Mean_All_Arc == True:\n",
        "  models_subset_ls.append('mean_all')\n",
        "\n",
        "if len(str(SMA_Window_Percent)) == 1:\n",
        "  roll_str = 'roll0' + str(SMA_Window_Percent)\n",
        "else:\n",
        "  roll_str = 'roll' + str(SMA_Window_Percent%100)\n",
        "\n",
        "print(f'Rolling Window: {roll_str}')\n",
        "\n",
        "plot_models(models_subset_ls, models_type='baseline', text_unit='sent_no', win_per=SMA_Window_Percent)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bafsX4zKd-wT"
      },
      "source": [
        "##### **(ABOVE) Plotly SMA Sentence, (BELOW) Correlation Heatmap**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxRGGdcgHj2S"
      },
      "source": [
        "# Sentence Heatmap Correlation of StdScaler Roll100 Sentiments\n",
        "# Depends on 'col_stdscaler_rollwin_ls' defined in prior code cell\n",
        "\n",
        "Correlation_Algo = \"spearman\" #@param [\"pearson\", \"spearman\", \"kendall\"]\n",
        "# corr_methods_ls = ['pearson', 'spearman', 'kendall']\n",
        "\n",
        "col_stdscaler_rollwin_ls = []\n",
        "for amodel in models_baseline_ls:\n",
        "  col_amodel_stdscaler_rollwin = f'{amodel}_stdscaler_{roll_str}'\n",
        "  col_stdscaler_rollwin_ls.append(col_amodel_stdscaler_rollwin)\n",
        "print(f'col_stdscaler_rollwin_ls: {col_stdscaler_rollwin_ls}')\n",
        "\n",
        "corr_df = corpus_sents_df[col_stdscaler_rollwin_ls].dropna(axis=0, how='any').corr(method=Correlation_Algo)\n",
        "\n",
        "# Customize the heatmap of the corr_meat correlation matrix and rotate the x-axis labels\n",
        "fig = sns.clustermap(corr_df, # corpus_sents_df[col_stdscaler_rollwin_ls].dropna(axis=0, how='any').corr(method=corr_method),\n",
        "                    row_cluster=True,\n",
        "                    col_cluster=True,\n",
        "                    figsize=(10, 10))\n",
        "\n",
        "\n",
        "plt.setp(fig.ax_heatmap.xaxis.get_majorticklabels(), rotation=90)\n",
        "plt.setp(fig.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
        "plt.title(f'{CORPUS_FULL} Sentence Sentiment for Baseline Model Sentiments\\n {Correlation_Algo.capitalize()} Correlation - StdScale Sentiments SMA ({roll_str.capitalize()})')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxfultUPZr-J"
      },
      "source": [
        "##### **Sentence Sentiment DTW Hierarichal Clustering**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1rU88PlFkss"
      },
      "source": [
        "# Dynamic Time Series Clustering\n",
        "\n",
        "# !pip install dtaidistance[all]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44Hys86nFkox"
      },
      "source": [
        "from dtaidistance import dtw\n",
        "from dtaidistance import dtw_visualisation as dtwvis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMq5XOXTFkjL"
      },
      "source": [
        "s1 = np.array([0., 0, 1, 2, 1, 0, 1, 0, 0, 2, 1, 0, 0])\n",
        "s2 = np.array([0., 1, 2, 3, 1, 0, 0, 0, 2, 1, 0, 0, 0])\n",
        "path = dtw.warping_path(s1, s2)\n",
        "dtwvis.plot_warping(s1, s2, path, filename=\"warp.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mra_zDRSF0LN"
      },
      "source": [
        "from dtaidistance import dtw\n",
        "import numpy as np\n",
        "series = np.matrix([\n",
        "    [0.0, 0, 1, 2, 1, 0, 1, 0, 0],\n",
        "    [0.0, 1, 2, 0, 0, 0, 0, 0, 0],\n",
        "    [0.0, 0, 1, 2, 1, 0, 0, 0, 0]])\n",
        "ds = dtw.distance_matrix_fast(series)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGTnnTynGYJR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wycvgBTtvJYY"
      },
      "source": [
        "##### **Explore Crux Points and Contexts**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8QX8tSKM376"
      },
      "source": [
        "**Search Corpus for Substring**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* In [Search_for_Substring] enter a Substring to search for in the Corpus\n",
        "\n",
        "* Enter a Substring long enough/unique enough so only a reasonable number of Sentences will be returned\n",
        "\n",
        "* Substring can contain spaces/punctuation, for example: 'in the garden'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJYjOu9Ks_pL"
      },
      "source": [
        "# Search Corpus Sentences for Substring\n",
        "\n",
        "Search_for_Substring = \"combat\" #@param {type:\"string\"}\n",
        "\n",
        "sentno_matching_ls = corpus_sents_df[corpus_sents_df['sent_raw'].str.contains(Search_for_Substring, regex=False)]['sent_no']\n",
        "\n",
        "for i, asentno in enumerate(sentno_matching_ls):\n",
        "  # sentno, sentraw = asent\n",
        "  print(f\"\\n\\nMatch #{i}: Sentence #{asentno}\\n\\n\")\n",
        "  sent_highlight = re.sub(Search_for_Substring, Search_for_Substring.upper(), corpus_sents_df.iloc[asentno]['sent_raw'])\n",
        "  print(f'    {sent_highlight}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ap_K_gpH0FTm"
      },
      "source": [
        "**Plot Top-n Crux Peaks/Valleys for selected Model**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Select [Crux_Window_Percent] exclusive zone around Crux Points as a percentage of Corpus length\n",
        "\n",
        "* [Sentiment_Model] Select a Sentiment Analysis model\n",
        "\n",
        "* Select [Anomaly_Detction] to plot raw Sentiment values to detect outlier/anomaly Sentences. Leave unchecked to plot SMA smoothed Sentiment arc and detect Crux points\n",
        "\n",
        "* Select [Save_to_File] to also save plot to external *.png file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHPx5a0xvJYb"
      },
      "source": [
        "Crux_Window_Percent = 5 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "Baseline_SMA_Model = \"VADER\" #@param [\"SentimentR\", \"SyuzhetR\", \"Bing\", \"SenticNet\", \"SentiWord\", \"NRC\", \"AFINN\", \"VADER\", \"TextBlob\", \"Flair\", \"Pattern\", \"Stanza\"]\n",
        "Anomaly_Detection = False #@param {type:\"boolean\"}\n",
        "Vertical_Labels = True #@param {type:\"boolean\"}\n",
        "Vertical_Labels_Height = -0.1 #@param {type:\"slider\", min:-50, max:50, step:0.1}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "if Baseline_SMA_Model == 'SentimentR':\n",
        "  model_selected = f'sentimentr'\n",
        "if Baseline_SMA_Model == 'SyuzhetR':\n",
        "  model_selected = f'syuzhet'\n",
        "if Baseline_SMA_Model == 'Bing':\n",
        "  model_selected = f'bing'\n",
        "if Baseline_SMA_Model == 'SenticNet':\n",
        "  model_selected = f'senticnet'\n",
        "if Baseline_SMA_Model == 'SentiWord':\n",
        "  model_selected = f'sentiword'\n",
        "if Baseline_SMA_Model == 'NRC':\n",
        "  model_selected = f'nrc'\n",
        "if Baseline_SMA_Model == 'AFINN':\n",
        "  model_selected = f'afinn'\n",
        "if Baseline_SMA_Model == 'VADER':\n",
        "  model_selected = f'vader'\n",
        "if Baseline_SMA_Model == 'TextBlob':\n",
        "  model_selected = f'textblob'\n",
        "if Baseline_SMA_Model == 'Flair':\n",
        "  model_selected = f'flair'\n",
        "if Baseline_SMA_Model == 'Pattern':\n",
        "  model_selected = f'pattern'\n",
        "if Baseline_SMA_Model == 'Stanza':\n",
        "  model_selected = f'stanza'\n",
        "\n",
        "if Anomaly_Detection == False:\n",
        "  # (a) Use Sentence SMA smoothed Sentiment models to detect Crux Points\n",
        "  model_selected_fullname = f'{model_selected}_stdscaler_{roll_str}'\n",
        "else:\n",
        "  # (b)Use Sentence Raw Sentiment models to detect outliers\n",
        "  model_selected_fullname = f'{model_selected}'\n",
        "\n",
        "\n",
        "# TODO: enable multiple overlay crux points with underlying mean/median arc\n",
        "corpus_models_selected_ls = [model_selected_fullname]\n",
        "\n",
        "# Warning: requires definitions of: x, section_sents_df\n",
        "#          so Baseline models must be run first\n",
        "\n",
        "for amodel in corpus_models_selected_ls:\n",
        "  corpus_cruxes_all_dt[amodel] = get_crux_points(ts_df=corpus_sents_df, \n",
        "                                         col_series=corpus_models_selected_ls, \n",
        "                                         text_type='sentence', \n",
        "                                         win_per=Crux_Window_Percent, \n",
        "                                         sec_y_labels=Vertical_Labels,\n",
        "                                         sec_y_height=Vertical_Labels_Height, \n",
        "                                         subtitle_str= '5% Crux ', \n",
        "                                         do_plot=True, \n",
        "                                         save2file=False);\n",
        "  \n",
        "model_crux_ls = corpus_cruxes_all_dt[amodel]\n",
        "# model_crux_ls;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6PU1zR8vJYf"
      },
      "source": [
        "**Get Top-n Crux Peaks/Valleys with surrounding Context**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Select [Get_Peak_Cruxes] to retrieve Peaks (if unchecked Valleys are retrieved)\n",
        "\n",
        "* [Get_n_Cruxes] determines how many Top-n Cruxes to retrieve\n",
        "\n",
        "* Enter [No_Paragraphs_on_Each_Side] to retrieve this many Paragraphs before and after the Paragraph containing your Crux Sentence (e.g. 2 will bring back 5 paragraphs centered around the Paragraph containing the Crux Sentence)\n",
        "\n",
        "* Select [Highlight_Crux_Sentence] to have the Crux Sentence converted to ALL CAPS for easier identification. The Paragraph containing the Crux Sentence will be prefaced with a '<*>' as well.\n",
        "\n",
        "* Select [Save_to_File] to also save output to external *.txt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUoJz_nyvJYh"
      },
      "source": [
        "# Crux Point Details\n",
        "Get_Peak_Cruxes = False #@param {type:\"boolean\"}\n",
        "Get_n_Cruxes = 20 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "Sort_by_SentenceNo = True #@param {type:\"boolean\"}\n",
        "\n",
        "# Context Details\n",
        "No_Paragraphs_on_Each_Side = 2 #@param {type:\"slider\", min:0, max:5, step:1}\n",
        "Highlight_Sentence = True #@param {type:\"boolean\"}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "if Sort_by_SentenceNo == True:\n",
        "  sort_on = 'sent_no'\n",
        "else:\n",
        "  sort_on = 'sentiment_val'\n",
        "\n",
        "if Save_to_Report == False:\n",
        "  crux_sortsents_report(model_crux_ls, \n",
        "                        ts_df = corpus_sents_df,\n",
        "                        library_type='baselines', \n",
        "                        top_n=Get_n_Cruxes, \n",
        "                        get_peaks=Get_Peak_Cruxes,\n",
        "                        sort_by = sort_on, # sent_no, or abs(polarity)\n",
        "                        n_sideparags=No_Paragraphs_on_Each_Side,\n",
        "                        sentence_highlight=Highlight_Sentence)\n",
        "else:\n",
        "  # import sys\n",
        "  # with open('filename.txt', 'w') as f:\n",
        "  #   print('This message will be written to a file.', file=f)\n",
        "  # https://www.kite.com/python/answers/how-to-get-stdout-and-stderr-from-a-process-as-a-string-in-python\n",
        "  # process = subprocess.run([\"echo\", \"This goes to stdout\"], capture_output=True)\n",
        "  # stdout_as_str = process.stdout.decode(\"utf-8\")\n",
        "  # print(stdout_as_str)\n",
        "  temp_out = StringIO()\n",
        "  sys.stdout = temp_out\n",
        "  crux_sortsents_report(model_crux_ls, top_n=Get_n_Cruxes, get_peaks=Get_Peak_Cruxes, n_sideparags=No_Paragraphs_on_Each_Side)\n",
        "  print(temp_out)\n",
        "  # attempt to save temp_out to generated filename\n",
        "  sys.stdout = sys.__stdout__\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1EnCO6sZx_0"
      },
      "source": [
        "%whos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJlFM5kFJDdA"
      },
      "source": [
        "asent_no = 124\n",
        "corpus_df = corpus_sents_df\n",
        "asent_raw = str(corpus_df[corpus_df['sent_no'] == int(asent_no)]['sent_raw'].values[0])\n",
        "asent_raw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-XtE7xovJYj"
      },
      "source": [
        "**Zoom in on Context surrounding a particular Crux Point**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Enter [Crux_Sentence_No] that matches a Crux point/Sentence No you want to explore\n",
        "\n",
        "* Enter [No_Paragraphs_on_Each_Side] to retrieve this many Paragraphs before and after the Paragraph containing your Crux Sentence (e.g. 2 will bring back 5 paragraphs centered around the Paragraph containing the Crux Sentence)\n",
        "\n",
        "* Select [Highlight_Crux_Sentence] to have the Crux Sentence converted to ALL CAPS for easier identification. The Paragraph containing the Crux Sentence will be prefaced with a '<*>' as well.\n",
        "\n",
        "* Select [Save_to_File] to also save output to external *.txt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1By1LTGvJYk"
      },
      "source": [
        "# Select details about the Crux Point Context to Retrieve\n",
        "\n",
        "# print(f'Last Sentence No: {corpus_sents_df.shape[0]}')\n",
        "Crux_Sentence_No =  200#@param {type:\"number\"}\n",
        "No_Paragraphs_on_Each_Side = 4 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "Highlight_Crux_Sentence = True #@param {type:\"boolean\"}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "corpus_sents_len = corpus_sents_df.shape[0]\n",
        "\n",
        "# if (Crux_Sentence_No >= No_Paragraphs_on_Each_Side) & (Crux_Sentence_No+No_Paragraphs_on_Each_Side <= corpus_parag_len):\n",
        "# get_sentnocontext_report()\n",
        "# try:\n",
        "get_sentnocontext_report(the_sent_no=Crux_Sentence_No, the_n_sideparags=No_Paragraphs_on_Each_Side, the_sent_highlight=Highlight_Crux_Sentence)\n",
        "# except:\n",
        "#   print('ERROR')\n",
        "# else:\n",
        "#   print(f'ERROR: The combination of your [Crux_Sentence_No] and [No_Pargraphs_on_Each_Side]\\n       results in a window outside the range of the Corpus Paragraphs.\\n\\n       Try again with different values.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmXIEIpY3jrX"
      },
      "source": [
        "##### **Selected Sentence Interactive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTD3VvWj3jrY"
      },
      "source": [
        "# Multiple Sentence Plotly Interactive/Zoom Sentiment Plots\n",
        "\n",
        "SMA_Window_Percent = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "SentimentR_Arc = False #@param {type:\"boolean\"}\n",
        "Syuzhet_Arc = True #@param {type:\"boolean\"}\n",
        "Bing_Arc = False #@param {type:\"boolean\"}\n",
        "SenticNet_Arc = False #@param {type:\"boolean\"}\n",
        "SentiWord_Arc = False #@param {type:\"boolean\"}\n",
        "NRC_Arc = False #@param {type:\"boolean\"}\n",
        "AFINN_Arc = False #@param {type:\"boolean\"}\n",
        "VADER_Arc = True #@param {type:\"boolean\"}\n",
        "TextBlob_Arc = True #@param {type:\"boolean\"}\n",
        "Flair_Arc = True #@param {type:\"boolean\"}\n",
        "Pattern_Arc = True #@param {type:\"boolean\"}\n",
        "Stanza_Arc = True #@param {type:\"boolean\"}\n",
        "Mean_All_Arc = True #@param {type:\"boolean\"}\n",
        "Mean_Subset_Arc = False #@param {type:\"boolean\"}\n",
        "MPQA_Arc = False #@param {type:\"boolean\"}\n",
        "SentiStrength_Arc = False #@param {type:\"boolean\"}\n",
        "\n",
        "models_subset_ls = []\n",
        "if SentimentR_Arc == True:\n",
        "  models_subset_ls.append('sentimentr')\n",
        "if Syuzhet_Arc == True:\n",
        "  models_subset_ls.append('syuzhet')\n",
        "if Bing_Arc == True:\n",
        "  models_subset_ls.append('bing')\n",
        "if SenticNet_Arc == True:\n",
        "  models_subset_ls.append('senticnet')\n",
        "if SentiWord_Arc == True:\n",
        "  models_subset_ls.append('sentiword')\n",
        "if NRC_Arc == True:\n",
        "  models_subset_ls.append('nrc')\n",
        "if AFINN_Arc == True:\n",
        "  models_subset_ls.append('afinn')\n",
        "if VADER_Arc == True:\n",
        "  models_subset_ls.append('vader')\n",
        "if TextBlob_Arc == True:\n",
        "  models_subset_ls.append('textblob')\n",
        "if Flair_Arc == True:\n",
        "  models_subset_ls.append('flair')\n",
        "if Pattern_Arc == True:\n",
        "  models_subset_ls.append('pattern')\n",
        "if Stanza_Arc == True:\n",
        "  models_subset_ls.append('stanza')\n",
        "if Mean_All_Arc == True:\n",
        "  models_subset_ls.append('mean_all')\n",
        "\n",
        "plot_models(models_subset_ls, models_type='baseline', text_unit='sent_no', win_per=SMA_Window_Percent)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuvAAR2x0x1B"
      },
      "source": [
        "##### **Selected Paragraph Interactive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhh0wT5yGaa0"
      },
      "source": [
        "# Paragraph Plotly Interactive/Zoom Sentiment Plots\n",
        "\n",
        "SMA_Window_Percent = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "SentimentR_Arc = False #@param {type:\"boolean\"}\n",
        "Syuzhet_Arc = True #@param {type:\"boolean\"}\n",
        "Bing_Arc = False #@param {type:\"boolean\"}\n",
        "SenticNet_Arc = False #@param {type:\"boolean\"}\n",
        "SentiWord_Arc = False #@param {type:\"boolean\"}\n",
        "NRC_Arc = False #@param {type:\"boolean\"}\n",
        "AFINN_Arc = False #@param {type:\"boolean\"}\n",
        "VADER_Arc = True #@param {type:\"boolean\"}\n",
        "TextBlob_Arc = True #@param {type:\"boolean\"}\n",
        "Flair_Arc = True #@param {type:\"boolean\"}\n",
        "Pattern_Arc = True #@param {type:\"boolean\"}\n",
        "Stanza_Arc = True #@param {type:\"boolean\"}\n",
        "Mean_All_Arc = True #@param {type:\"boolean\"}\n",
        "Mean_Subset_Arc = False #@param {type:\"boolean\"}\n",
        "MPQA_Arc = False #@param {type:\"boolean\"}\n",
        "SentiStrength_Arc = False #@param {type:\"boolean\"}\n",
        "\n",
        "models_subset_ls = []\n",
        "if SentimentR_Arc == True:\n",
        "  models_subset_ls.append('sentimentr')\n",
        "if Syuzhet_Arc == True:\n",
        "  models_subset_ls.append('syuzhet')\n",
        "if Bing_Arc == True:\n",
        "  models_subset_ls.append('bing')\n",
        "if SenticNet_Arc == True:\n",
        "  models_subset_ls.append('senticnet')\n",
        "if SentiWord_Arc == True:\n",
        "  models_subset_ls.append('sentiword')\n",
        "if NRC_Arc == True:\n",
        "  models_subset_ls.append('nrc')\n",
        "if AFINN_Arc == True:\n",
        "  models_subset_ls.append('afinn')\n",
        "if VADER_Arc == True:\n",
        "  models_subset_ls.append('vader')\n",
        "if TextBlob_Arc == True:\n",
        "  models_subset_ls.append('textblob')\n",
        "if Flair_Arc == True:\n",
        "  models_subset_ls.append('flair')\n",
        "if Pattern_Arc == True:\n",
        "  models_subset_ls.append('pattern')\n",
        "if Stanza_Arc == True:\n",
        "  models_subset_ls.append('stanza')\n",
        "if Mean_All_Arc == True:\n",
        "  models_subset_ls.append('mean_all')\n",
        "\n",
        "plot_models(models_subset_ls, models_type='baseline', text_unit='parag_no', win_per=SMA_Window_Percent)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYt6fgEsapFj"
      },
      "source": [
        "##### **Selected Section Interactive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "culyTw0tapFk"
      },
      "source": [
        "# Paragraph Plotly Interactive/Zoom Sentiment Plots\n",
        "\n",
        "SMA_Window_Percent = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "SentimentR_Arc = False #@param {type:\"boolean\"}\n",
        "Syuzhet_Arc = True #@param {type:\"boolean\"}\n",
        "Bing_Arc = False #@param {type:\"boolean\"}\n",
        "SenticNet_Arc = False #@param {type:\"boolean\"}\n",
        "SentiWord_Arc = False #@param {type:\"boolean\"}\n",
        "NRC_Arc = False #@param {type:\"boolean\"}\n",
        "AFINN_Arc = False #@param {type:\"boolean\"}\n",
        "VADER_Arc = True #@param {type:\"boolean\"}\n",
        "TextBlob_Arc = True #@param {type:\"boolean\"}\n",
        "Flair_Arc = True #@param {type:\"boolean\"}\n",
        "Pattern_Arc = True #@param {type:\"boolean\"}\n",
        "Stanza_Arc = True #@param {type:\"boolean\"}\n",
        "Mean_All_Arc = True #@param {type:\"boolean\"}\n",
        "Mean_Subset_Arc = False #@param {type:\"boolean\"}\n",
        "MPQA_Arc = False #@param {type:\"boolean\"}\n",
        "SentiStrength_Arc = False #@param {type:\"boolean\"}\n",
        "\n",
        "models_subset_ls = []\n",
        "if SentimentR_Arc == True:\n",
        "  models_subset_ls.append('sentimentr')\n",
        "if Syuzhet_Arc == True:\n",
        "  models_subset_ls.append('syuzhet')\n",
        "if Bing_Arc == True:\n",
        "  models_subset_ls.append('bing')\n",
        "if SenticNet_Arc == True:\n",
        "  models_subset_ls.append('senticnet')\n",
        "if SentiWord_Arc == True:\n",
        "  models_subset_ls.append('sentiword')\n",
        "if NRC_Arc == True:\n",
        "  models_subset_ls.append('nrc')\n",
        "if AFINN_Arc == True:\n",
        "  models_subset_ls.append('afinn')\n",
        "if VADER_Arc == True:\n",
        "  models_subset_ls.append('vader')\n",
        "if TextBlob_Arc == True:\n",
        "  models_subset_ls.append('textblob')\n",
        "if Flair_Arc == True:\n",
        "  models_subset_ls.append('flair')\n",
        "if Pattern_Arc == True:\n",
        "  models_subset_ls.append('pattern')\n",
        "if Stanza_Arc == True:\n",
        "  models_subset_ls.append('stanza')\n",
        "if Mean_All_Arc == True:\n",
        "  models_subset_ls.append('mean_all')\n",
        "\n",
        "plot_models(models_subset_ls, models_type='baseline', text_unit='sect_no', win_per=SMA_Window_Percent)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRt69D1Zbem0"
      },
      "source": [
        "##### **Chapter SMA Plots**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjlr8LEybem0"
      },
      "source": [
        "# Paragraph Plotly Interactive/Zoom Sentiment Plots\n",
        "\n",
        "SMA_Window_Percent = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "SentimentR_Arc = False #@param {type:\"boolean\"}\n",
        "Syuzhet_Arc = True #@param {type:\"boolean\"}\n",
        "Bing_Arc = False #@param {type:\"boolean\"}\n",
        "SenticNet_Arc = False #@param {type:\"boolean\"}\n",
        "SentiWord_Arc = False #@param {type:\"boolean\"}\n",
        "NRC_Arc = False #@param {type:\"boolean\"}\n",
        "AFINN_Arc = False #@param {type:\"boolean\"}\n",
        "VADER_Arc = True #@param {type:\"boolean\"}\n",
        "TextBlob_Arc = True #@param {type:\"boolean\"}\n",
        "Flair_Arc = True #@param {type:\"boolean\"}\n",
        "Pattern_Arc = True #@param {type:\"boolean\"}\n",
        "Stanza_Arc = True #@param {type:\"boolean\"}\n",
        "Mean_All_Arc = True #@param {type:\"boolean\"}\n",
        "Mean_Subset_Arc = False #@param {type:\"boolean\"}\n",
        "MPQA_Arc = False #@param {type:\"boolean\"}\n",
        "SentiStrength_Arc = False #@param {type:\"boolean\"}\n",
        "\n",
        "models_subset_ls = []\n",
        "if SentimentR_Arc == True:\n",
        "  models_subset_ls.append('sentimentr')\n",
        "if Syuzhet_Arc == True:\n",
        "  models_subset_ls.append('syuzhet')\n",
        "if Bing_Arc == True:\n",
        "  models_subset_ls.append('bing')\n",
        "if SenticNet_Arc == True:\n",
        "  models_subset_ls.append('senticnet')\n",
        "if SentiWord_Arc == True:\n",
        "  models_subset_ls.append('sentiword')\n",
        "if NRC_Arc == True:\n",
        "  models_subset_ls.append('nrc')\n",
        "if AFINN_Arc == True:\n",
        "  models_subset_ls.append('afinn')\n",
        "if VADER_Arc == True:\n",
        "  models_subset_ls.append('vader')\n",
        "if TextBlob_Arc == True:\n",
        "  models_subset_ls.append('textblob')\n",
        "if Flair_Arc == True:\n",
        "  models_subset_ls.append('flair')\n",
        "if Pattern_Arc == True:\n",
        "  models_subset_ls.append('pattern')\n",
        "if Stanza_Arc == True:\n",
        "  models_subset_ls.append('stanza')\n",
        "if Mean_All_Arc == True:\n",
        "  models_subset_ls.append('mean_all')\n",
        "\n",
        "plot_models(models_subset_ls, models_type='baseline', text_unit='chap_no', win_per=SMA_Window_Percent)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TszUw6HFQ6lU"
      },
      "source": [
        "##### **Comparison of Sentence Baseline Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSNxgw5TjU8L"
      },
      "source": [
        "# Compare Sentence Baseline Length-Normed Standardized Sentiment Values\n",
        "\n",
        "\"\"\"\n",
        "model_baselines_ls = ['sentimentr', 'syuzhet', 'bing',\n",
        "                  'sentiword', 'senticnet', 'nrc',\n",
        "                  'afinn', 'vader', 'textblob',\n",
        "                  'flair', 'pattern', 'stanza']\n",
        "\"\"\";\n",
        "\n",
        "\"\"\"\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# col_roll_ls = []\n",
        "model_base_standardized_roll_ls = []\n",
        "for amodel in model_baselines_ls:\n",
        "  # Create the simple model_rollxxx rolling mean\n",
        "  col_roll = f'{amodel}_{roll_str}'\n",
        "  corpus_sents_df['col_roll'] = corpus_sents_df[amodel].rolling(10*win_s1per, center=True).mean()\n",
        "\n",
        "  # Create list of column names for model_lnorm_medianiqr_rollxxx\n",
        "  # col_name = f'{amodel}_lnorm_medianiqr_{roll_str}'  # TODO: drop lnorm_medianiqr earlier and just Standardize here                                                   # NOTE: Simple SciPy StandardScaler works on SMA Series that don't have outliers like Raw Series\n",
        "  col_name = f'{amodel}_{roll_str}'  # TODO: drop lnorm_medianiqr earlier and just Standardize here                                                   # NOTE: Simple SciPy StandardScaler works on SMA Series that don't have outliers like Raw Series\n",
        "  # print(f'col_name: {col_name}')\n",
        "  model_base_standardized_roll_ls.append(col_name)\n",
        "\n",
        "  # for i,amodel in enumerate(model_base_standardized_roll_ls):\n",
        "\n",
        "  col_name_roll_stand = f'{col_roll}_stdscale'\n",
        "  # print(f'col_name_roll_stand: {col_name_roll_stand}')\n",
        "  model_roll_stand_np = np.array(corpus_sents_df[col_roll])\n",
        "  # .apply(lambda x: Scale_SentimentR*x))\n",
        "  \n",
        "  model_roll_stand_np = model_roll_stand_np.reshape((len(model_roll_stand_np), 1))\n",
        "\n",
        "  scaler = scaler.fit(model_roll_stand_np)\n",
        "  print('Mean: %f, StandardDeviation: %f' % (scaler.mean_, np.sqrt(scaler.var_)))\n",
        "  model_roll_stand_xform_np = scaler.transform(model_roll_stand_np)\n",
        "\n",
        "  corpus_sents_df[col_name_roll_stand] = pd.Series(model_roll_stand_xform_np.flatten())\n",
        "\n",
        "  # Plot\n",
        "  corpus_sents_df[col_name_roll_stand].plot(label=amodel) # label=col_name_roll_stand))\n",
        "\n",
        "plt.grid()\n",
        "plt.title(f'{CORPUS_FULL} Compare Sentences for Baseline Model Sentiments\\nMean StdScale Sentiments SMA ({roll_str.capitalize()})')\n",
        "plt.legend(loc='best');\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YsG5H1xway0"
      },
      "source": [
        "## **EDA SentimentR Plots**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kGpC98FInPh"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "# Create SMA roll=10% for all models_stdscaler as baseline\n",
        "\n",
        "win_s1per = int(corpus_sentimentr_df.shape[0] * 1/100)\n",
        "\n",
        "col_stdscaler_roll_ls = []\n",
        "for amodel in models_sentimentr_ls:\n",
        "  col_stdscaler = f'{amodel}_stdscaler'\n",
        "  col_stdscaler_roll = f'{amodel}_stdscaler_{roll_str}'\n",
        "  corpus_sentimentr_df[col_stdscaler_roll] = corpus_sentimentr_df[col_stdscaler].rolling(10*win_s1per, center=True).mean()\n",
        "  col_stdscaler_roll_ls.append(col_stdscaler_roll)\n",
        "\n",
        "col_stdscaler_roll_mean = col_stdscaler_roll + '_mean'\n",
        "corpus_sentimentr_df[col_stdscaler_roll_mean] = corpus_sentimentr_df[col_stdscaler_roll_ls].mean()\n",
        "\n",
        "# Test\n",
        "\n",
        "corpus_sentimentr_df[col_stdscaler_roll_ls].plot()\n",
        "\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id_VKOPiR7Mg"
      },
      "source": [
        "#### **Import SentimentR Sentiment Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTPbrXDM0Gm1"
      },
      "source": [
        "# Verify SentimentR Sentiment Files exported from RStudio\n",
        "!pwd\n",
        "!ls -altr sum_sentiments_*.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlONG-ZwuuVb"
      },
      "source": [
        "# Get SentimentR Sentiment Datafile (with data on 7 Models)\n",
        "\n",
        "SentimentR_sentiment_datafile = 'sum_sentiments_sentimentR_7models_vwoolf_tothelighthouse.csv' #@param {type:\"string\"}\n",
        "\n",
        "sum_sentiments_sentimentr_filename = SentimentR_sentiment_datafile\n",
        "\n",
        "!head -n 3 $sum_sentiments_sentimentr_filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u39nsvJb5YD-"
      },
      "source": [
        "corpus_sentimentr_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJp4DgcIwa7A"
      },
      "source": [
        "# (Optional) Read Sentiment Series generated in RStudio by SentimentR into DataFrame: corpus_sents_sentimentr_df\n",
        "#            SKIP if no SyuzhetR sentiment datafile to read in\n",
        "\n",
        "# MANUALLY: copy and paste the filename above into the quotes below for sum_sentiment_sentimentR_filename\n",
        "\n",
        "corpus_sentimentr_df = pd.read_csv(sum_sentiments_sentimentr_filename, encoding = 'unicode_escape', engine ='python')\n",
        "\n",
        "# Rename columns if necessary\n",
        "corpus_sentimentr_df.rename(columns={'Unnamed: 0':'sent_no'}, inplace=True)\n",
        "corpus_sentimentr_df['sent_raw'] = corpus_sentimentr_df['sent_raw'].astype('string')\n",
        "corpus_sentimentr_df['sent_raw'] = corpus_sentimentr_df['sent_raw'].apply(lambda x : re.sub(f'[^{re.escape(string.printable)}]', '', x))\n",
        "corpus_sentimentr_df['sent_raw'] = corpus_sentimentr_df['sent_raw'].apply(lambda x : filter_nonprintable(x))\n",
        "\n",
        "\n",
        "# create a clean version of Sentence in sent_clean column\n",
        "corpus_sentimentr_df['sent_clean'] = corpus_sentimentr_df['sent_raw'].apply(lambda x : clean_text(x))\n",
        "corpus_sentimentr_df['sent_clean'] = corpus_sentimentr_df['sent_raw'].apply(lambda x : re.sub(f'[^{re.escape(string.printable)}]', '', x))\n",
        "corpus_sentimentr_df['sent_clean'] = corpus_sentimentr_df['sent_raw'].apply(lambda x : filter_nonprintable(x))\n",
        "\n",
        "corpus_sentimentr_df['sent_clean'] = corpus_sentimentr_df['sent_clean'].astype('string')\n",
        "\n",
        "corpus_sentimentr_df.head(2)\n",
        "corpus_sentimentr_df.info()\n",
        "corpus_sentimentr_df.columns\n",
        "\n",
        "corpus_sents_sentimentr_len = corpus_sentimentr_df.shape[0]\n",
        "\n",
        "# BUG FIX: SentimentR can create many additional rows that must be deleted \n",
        "#          to enable it to be merged with other Sentiment Models on the same Corpus\n",
        "#          OR just leave SentimentR unmerged and analyze separately (preferred)\n",
        "#\n",
        "# POSSIBLE SOLUTIONS (from worst/easiest to better)\n",
        "#     \n",
        "#   1) Trim extra n rows from head/tail\n",
        "#   2) Naive Downsampling of Series\n",
        "#   3) Clustering and distribute deletes of near-medians from longest runs, avoiding outliers, start/end\n",
        "#   4) DTW character-preserving Compression\n",
        "# \n",
        "#          Simplification, 1D cluster jockers_rinker column as proxy for full interrow distance features\n",
        "#                          and delete rows near the median from the largest cluster (vs taking into account\n",
        "#                          all features in Euclidian or other distance metric)\n",
        "\n",
        "# import kmeans1d\n",
        "\n",
        "# Approximate k cluster number as 1 cluster for every 500 sentences in Corpus\n",
        "# k = corpus_sentimentr_df.shape[0]//500  \n",
        "# clusters, centroids = kmeans1d.cluster(np.array(corpus_sentimentr_df['jockers_rinker']), k)\n",
        "\n",
        "def del_oneincluster(df, cluster_per=1):\n",
        "  '''\n",
        "  TODO: Skip for now and use kmeans1d instead\n",
        "  Given a DataFrame and a Cluster Percent to calculate a sliding window\n",
        "  Return DataFrame with one row removed within a sliding window cluster with most self-similiar rows\n",
        "  '''\n",
        "\n",
        "  # Compute sliding window for cluster size\n",
        "  win_cluster_len = int(cluster_per/100 * df.shape[0])\n",
        "  win_start = 0\n",
        "  win_stop = df.shape[0] - win_cluster_len\n",
        "\n",
        "  # Get numeric columns\n",
        "  numeric_df = df.select_dtypes(include=numerics)\n",
        "\n",
        "  most_selfsimilar_value = 0\n",
        "  most_selfsimilar_index = 0\n",
        "  for i in range(win_start, win_stop, 1):\n",
        "    selfsim_score = selfsim_metric(numeric_df.iloc[i:win_cluster_len+1])\n",
        "    if selfsim_score > most_selfsimilar_value:\n",
        "      most_selfsimilar_index = i\n",
        "\n",
        "  oneless_df = del_onerow(most_selfsimilar_index)\n",
        "\n",
        "  return oneless_df\n",
        "\n",
        "# BAD SOLUTION, just trim the last n rows of corpus_sentimentr_df to make lengths match for merging\n",
        "# corpus_sentimentr_df = corpus_sentimentr_df.iloc[:-n,:]\n",
        "\n",
        "corpus_sentimentr_len = corpus_sentimentr_df.shape[0]\n",
        "if corpus_sentimentr_len != corpus_sents_df.shape[0]:\n",
        "  print('\\n\\n\\n======================================================================\\n')\n",
        "  print(f'ERROR: sentence sentiment values read into corpus_syuzhetr (len={corpus_sents_sentimentr_len})')\n",
        "  print(f'       is not the same length as corpus_sents_df (len={corpus_sents_df.shape[0]}) ')\n",
        "  print(f'\\nRECOMMENDATION: Use the preprocessed corpus output created by this notebook ')\n",
        "  print(f'                as input to SentimentR in RStudio to generate sentiment series')\n",
        "  print(f'                and then retry importing')\n",
        "  print('\\n======================================================================\\n');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bpDK9m_5Ea6"
      },
      "source": [
        "# Add summary statistics\n",
        "\n",
        "corpus_sentimentr_df['char_len'] = corpus_sentimentr_df['sent_clean'].apply(lambda x: len(x))\n",
        "corpus_sentimentr_df['token_len'] = corpus_sentimentr_df['sent_clean'].apply(lambda x: len(x.split())) \n",
        "\n",
        "# Verify\n",
        "\n",
        "corpus_sentimentr_df.head(2)\n",
        "corpus_sentimentr_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnLz5_Gzh-DO"
      },
      "source": [
        "# Create 4 Standardized versions of each Model: stdscaler, medianiqr both lnormed and not\n",
        "\n",
        "print('\\nBefore Standardization ----------')\n",
        "corpus_sentimentr_df.columns\n",
        "\n",
        "standardize_ts_ls(corpus_sentimentr_df, models_sentimentr_ls)\n",
        "\n",
        "print('\\nAfter Standardization ----------')\n",
        "corpus_sentimentr_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ0IX-wJ-1fv"
      },
      "source": [
        "# Create SMA roll=10% for all models_stdscaler as baseline\n",
        "\n",
        "win_s1per = int(corpus_sentimentr_df.shape[0] * 1/100)\n",
        "\n",
        "col_stdscaler_roll_ls = []\n",
        "for amodel in models_sentimentr_ls:\n",
        "  col_stdscaler = f'{amodel}_stdscaler'\n",
        "  col_stdscaler_roll = f'{amodel}_stdscaler_{roll_str}'\n",
        "  corpus_sentimentr_df[col_stdscaler_roll] = corpus_sentimentr_df[col_stdscaler].rolling(10*win_s1per, center=True).mean()\n",
        "  col_stdscaler_roll_ls.append(col_stdscaler_roll)\n",
        "\n",
        "col_stdscaler_roll_mean = col_stdscaler_roll + '_mean'\n",
        "corpus_sentimentr_df[col_stdscaler_roll_mean] = corpus_sentimentr_df[col_stdscaler_roll_ls].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpoUy0Dm5Ea8"
      },
      "source": [
        "# Standardize all values with MedianIQR\n",
        "\"\"\"\n",
        "model_sentimentr_ls = ['jockers_rinker', 'jockers', 'huliu', 'lmcd', 'nrc', 'senticnet', 'sentiword']\n",
        "\n",
        "for model_sentimentr in models_sentimentr_ls:\n",
        "\n",
        "  # Normalize the Sentence Sentiment by dividing Sentiment by Sentence Length\n",
        "  sents_len_ls = list(corpus_sentimentr_df['token_len'])\n",
        "  sents_sentiment_ls = list(corpus_sentimentr_df[model_sentimentr])\n",
        "  sents_sentiment_norm_ls = [sents_sentiment_ls[i]/(sents_len_ls[i]+0.01) for i in range(len(sents_len_ls))]\n",
        "\n",
        "  # RobustStandardize Sentence sentiment values\n",
        "  # corpus_sentimentr_df[col_lnorm_meanstd]  = mean_std_scaler.fit_transform(np.array(pd.Series(sents_sentiment_norm_ls)).reshape(-1, 1))\n",
        "  col_medianiqr = f'{model_sentimentr}_medianiqr'\n",
        "  corpus_sentimentr_df[col_medianiqr]  = median_iqr_scaler.fit_transform(np.array(corpus_sentimentr_df[model_sentimentr]).reshape(-1, 1))\n",
        "  col_lnorm_medianiqr = f'{model_sentimentr}_lnorm_medianiqr'\n",
        "  corpus_sentimentr_df[col_lnorm_medianiqr]  = median_iqr_scaler.fit_transform(np.array(pd.Series(sents_sentiment_norm_ls)).reshape(-1, 1))\n",
        "\"\"\";\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqrVGplu3txO"
      },
      "source": [
        "#### **Sentence SMA Plots**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuOLcZq4dmFL"
      },
      "source": [
        "corpus_sentimentr_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFV8VTo1dtf4"
      },
      "source": [
        "# Sentence Plotly Interactive/Zoom Sentiment Plots\n",
        "\n",
        "SMA_Window_Percent = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "SentimentR_JockersRinker = True #@param {type:\"boolean\"}\n",
        "SentimentR_Jockers = True #@param {type:\"boolean\"}\n",
        "SentimentR_HuLiu = True #@param {type:\"boolean\"}\n",
        "SentimentR_SenticNet = True #@param {type:\"boolean\"}\n",
        "SentimentR_SentiWord = True #@param {type:\"boolean\"}\n",
        "SentimentR_NRC = True #@param {type:\"boolean\"}\n",
        "SentimentR_LoughranMcDonald = True #@param {type:\"boolean\"}\n",
        "\n",
        "models_subset_ls = []\n",
        "\n",
        "if SentimentR_JockersRinker == True:\n",
        "  models_subset_ls.append('jockers_rinker')\n",
        "if SentimentR_Jockers == True:\n",
        "  models_subset_ls.append('jockers')\n",
        "if SentimentR_HuLiu == True:\n",
        "  models_subset_ls.append('huliu')\n",
        "if SentimentR_SenticNet == True:\n",
        "  models_subset_ls.append('senticnet')\n",
        "if SentimentR_SentiWord == True:\n",
        "  models_subset_ls.append('sentiword')\n",
        "if SentimentR_NRC == True:\n",
        "  models_subset_ls.append('nrc')\n",
        "if SentimentR_LoughranMcDonald == True:\n",
        "  models_subset_ls.append('lmcd')\n",
        "\n",
        "print(f'models_subset_ls:\\n\\n    {models_subset_ls}')\n",
        "plot_models(models_subset_ls, models_type='sentimentr', text_unit='sent_no', win_per=SMA_Window_Percent);\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP-Moy3DdrRr"
      },
      "source": [
        "#### **(ABOVE) Plotly SMA Sentence, (BELOW) Correlation Heatmap**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaY7ZYNSm0MM"
      },
      "source": [
        "# Sentence Heatmap Correlation of StdScaler Roll100 Sentiments\n",
        "# Depends on 'col_stdscaler_rollwin_ls' defined in prior code cell\n",
        "\n",
        "Correlation_Algo = \"spearman\" #@param [\"pearson\", \"spearman\", \"kendall\"]\n",
        "# corr_methods_ls = ['pearson', 'spearman', 'kendall']\n",
        "\n",
        "col_stdscaler_rollwin_ls = []\n",
        "for amodel in models_sentimentr_ls:\n",
        "  col_amodel_stdscaler_rollwin = f'{amodel}_stdscaler_{roll_str}'\n",
        "  col_stdscaler_rollwin_ls.append(col_amodel_stdscaler_rollwin)\n",
        "print(f'col_stdscaler_rollwin_ls: {col_stdscaler_rollwin_ls}')\n",
        "\n",
        "corr_df = corpus_sentimentr_df[col_stdscaler_rollwin_ls].dropna(axis=0, how='any').corr(method=Correlation_Algo)\n",
        "corr_df\n",
        "# Customize the heatmap of the corr_meat correlation matrix and rotate the x-axis labels\n",
        "fig = sns.clustermap(corr_df, # corpus_sents_df[col_stdscaler_rollwin_ls].dropna(axis=0, how='any').corr(method=corr_method),\n",
        "                    row_cluster=True,\n",
        "                    col_cluster=True,\n",
        "                    figsize=(10, 10))\n",
        "\n",
        "\n",
        "plt.setp(fig.ax_heatmap.xaxis.get_majorticklabels(), rotation=90)\n",
        "plt.setp(fig.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
        "plt.title(f'{CORPUS_FULL} Sentence Sentiment for SentimentR Model Sentiments\\n {Correlation_Algo.capitalize()} Correlation - StdScale Sentiments SMA ({roll_str.capitalize()})')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yaxyt-MqOxdV"
      },
      "source": [
        "#### **Sentence Sentiment DTW Hierarichal Clustering**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa2RSwSBnqxd"
      },
      "source": [
        "# Compare Sentence SentimentR Standardized Sentiment Values\n",
        "\"\"\"\n",
        "model_sentimentr_ls = ['jockers_rinker', 'jockers', 'huliu', 'senticnet', 'sentiword', 'nrc', 'lmcd']\n",
        "\n",
        "model_sentimentr_standardized_roll_ls = []\n",
        "for amodel in model_sentimentr_ls:\n",
        "  col_name = f'{amodel}_{roll_str}'  # TODO: drop lnorm_medianiqr earlier and just Standardize here\n",
        "                                                     # NOTE: Simple SciPy StandardScaler works on SMA Series that don't have outliers like Raw Series\n",
        "  # print(f'col_name: {col_name}')\n",
        "  model_sentimentr_standardized_roll_ls.append(col_name)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "for i,amodel in enumerate(model_sentimentr_standardized_roll_ls):\n",
        "  col_name_roll_stand = f'{amodel}_stdscale'\n",
        "  # print(f'col_name_roll_stand: {col_name_roll_stand}')\n",
        "  model_roll_stand_np = np.array(corpus_sentimentr_df[amodel])\n",
        "  # .apply(lambda x: Scale_SentimentR*x))\n",
        "  \n",
        "  model_roll_stand_np = model_roll_stand_np.reshape((len(model_roll_stand_np), 1))\n",
        "\n",
        "  scaler = scaler.fit(model_roll_stand_np)\n",
        "  print('Mean: %f, StandardDeviation: %f' % (scaler.mean_, np.sqrt(scaler.var_)))\n",
        "  model_roll_stand_xform_np = scaler.transform(model_roll_stand_np)\n",
        "\n",
        "  corpus_sentimentr_df[col_name_roll_stand] = pd.Series(model_roll_stand_xform_np.flatten())\n",
        "\n",
        "  # Plot\n",
        "  corpus_sentimentr_df[col_name_roll_stand].plot(label=amodel) # label=col_name_roll_stand))\n",
        "\n",
        "plt.grid()\n",
        "plt.title(f'{CORPUS_FULL} Compare Sentence SentimentR Sentiments\\nMean Length-Normed MedianIQR Sentiments SMA ({roll_str.capitalize()})')\n",
        "plt.legend(loc='best');\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEUx7KmlZw_o"
      },
      "source": [
        "corpus_sentimentr_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uvlleo0avaZ"
      },
      "source": [
        "models_sentimentr_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S83JA_esuSxc"
      },
      "source": [
        "#### **Explore Crux Points and Contexts**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgETYM8xMGGW"
      },
      "source": [
        "**Search Corpus for Substring**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* In [Search_for_Substring] enter a Substring to search for in the Corpus\n",
        "\n",
        "* Enter a Substring long enough/unique enough so only a reasonable number of Sentences will be returned\n",
        "\n",
        "* Substring can contain spaces/punctuation, for example: 'in the garden'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nyUrE2_L_yr"
      },
      "source": [
        "# Search Corpus Sentences for Substring\n",
        "\n",
        "Search_for_Substring = \"Euryclea\" #@param {type:\"string\"}\n",
        "\n",
        "sentno_matching_ls = corpus_sents_df[corpus_sents_df['sent_raw'].str.contains(Search_for_Substring, regex=False)]['sent_no']\n",
        "\n",
        "for i, asentno in enumerate(sentno_matching_ls):\n",
        "  # sentno, sentraw = asent\n",
        "  print(f\"\\n\\nMatch #{i}: Sentence #{asentno}\\n\\n\")\n",
        "  sent_highlight = re.sub(Search_for_Substring, Search_for_Substring.upper(), corpus_sents_df.iloc[asentno]['sent_raw'])\n",
        "  print(f'    {sent_highlight}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7TRTSm34mnl"
      },
      "source": [
        "**Plot Top-n Crux Peaks/Valleys for selected Model**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Select [Crux_Window_Percent] exclusive zone around Crux Points as a percentage of Corpus length\n",
        "\n",
        "* [Sentiment_Model] Select a Sentiment Analysis model\n",
        "\n",
        "* Select [Anomaly_Detction] to plot raw Sentiment values to detect outlier/anomaly Sentences. Leave unchecked to plot SMA smoothed Sentiment arc and detect Crux points\n",
        "\n",
        "* Select [Save_to_File] to also save plot to external *.png file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fc4KP-oz-y4z"
      },
      "source": [
        "corpus_sentimentr_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8SRc-bSKZiO"
      },
      "source": [
        "Crux_Window_Percent = 5 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "SentimentR_SMA_Model = \"Jockers-Rinker\" #@param [\"Jockers-Rinker\", \"Jockers\", \"Hu-Liu\", \"SenticNet\", \"SentiWord\", \"NRC\", \"Loughan-McDonald\"]\n",
        "Anomaly_Detection = False #@param {type:\"boolean\"}\n",
        "Vertical_Labels = True #@param {type:\"boolean\"}\n",
        "Vertical_Labels_Height = -0.2 #@param {type:\"slider\", min:-5, max:5, step:0.05}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "if SentimentR_SMA_Model == 'Jockers-Rinker':\n",
        "  model_selected = f'jockers_rinker'\n",
        "if SentimentR_SMA_Model == 'Jockers':\n",
        "  model_selected = f'jockers_rinker'\n",
        "if SentimentR_SMA_Model == 'Hu-Liu':\n",
        "  model_selected = f'huliu'\n",
        "if SentimentR_SMA_Model == 'SenticNet':\n",
        "  model_selected = f'senticnet'\n",
        "if SentimentR_SMA_Model == 'SentiWord':\n",
        "  model_selected = f'sentiword'\n",
        "if SentimentR_SMA_Model == 'NRC':\n",
        "  model_selected = f'nrc'\n",
        "if SentimentR_SMA_Model == 'Loughran-McDonald':\n",
        "  model_selected = f'lmcd'\n",
        "\n",
        "if Anomaly_Detection == False:\n",
        "  # (a) Use Sentence SMA smoothed Sentiment models to detect Crux Points\n",
        "  model_selected_fullname = f'{model_selected}_stdscaler_{roll_str}'\n",
        "else:\n",
        "  # (b)Use Sentence Raw Sentiment models to detect outliers\n",
        "  model_selected_fullname = f'{model_selected}'\n",
        "\n",
        "\n",
        "\n",
        "# TODO: enable multiple overlay crux points with underlying mean/median arc\n",
        "corpus_models_selected_ls = [model_selected_fullname]\n",
        "print(f'corpus_models_selected_ls: {corpus_models_selected_ls}')\n",
        "\n",
        "# Warning: requires definitions of: x, section_sents_df\n",
        "#          so Baseline models must be run first\n",
        "\n",
        "\n",
        "for amodel in corpus_models_selected_ls:\n",
        "  corpus_cruxes_all_dt[amodel] = get_crux_points(ts_df=corpus_sentimentr_df, \n",
        "                                         col_series=corpus_models_selected_ls, \n",
        "                                         text_type='sentence', \n",
        "                                         win_per=Crux_Window_Percent, \n",
        "                                         sec_y_labels=Vertical_Labels,\n",
        "                                         sec_y_height=Vertical_Labels_Height, \n",
        "                                         subtitle_str='5% Crux - ', \n",
        "                                         do_plot=True, \n",
        "                                         save2file=False)\n",
        "  \n",
        "model_crux_ls = corpus_cruxes_all_dt[amodel]\n",
        "# model_crux_ls;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_FRnxmUtRIY"
      },
      "source": [
        "**Get Top-n Crux Peaks/Valleys with surrounding Context**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Select [Get_Peak_Cruxes] to retrieve Peaks (if unchecked Valleys are retrieved)\n",
        "\n",
        "* [Get_n_Cruxes] determines how many Top-n Cruxes to retrieve\n",
        "\n",
        "* Enter [No_Paragraphs_on_Each_Side] to retrieve this many Paragraphs before and after the Paragraph containing your Crux Sentence (e.g. 2 will bring back 5 paragraphs centered around the Paragraph containing the Crux Sentence)\n",
        "\n",
        "* Select [Highlight_Crux_Sentence] to have the Crux Sentence converted to ALL CAPS for easier identification. The Paragraph containing the Crux Sentence will be prefaced with a '<*>' as well.\n",
        "\n",
        "* Select [Save_to_File] to also save output to external *.txt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U74EzFO7848r"
      },
      "source": [
        "noisy_str = make_printable(corpus_sentimentr_df.iloc[2504]['sent_raw'])\n",
        "print(noisy_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wPbBI0T66cI"
      },
      "source": [
        "corpus_sentimentr_df.iloc[2503:2506]\n",
        "corpus_sentimentr_df.iloc[2560:2563]\n",
        "corpus_sentimentr_df.iloc[2561]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FeWNQLqscUy"
      },
      "source": [
        "corpus_sentimentr_df['sent_raw'].isna().any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyeQ7Jpfszhq"
      },
      "source": [
        "# Crux Details\n",
        "Get_Peak_Cruxes = False #@param {type:\"boolean\"}\n",
        "Get_n_Cruxes = 20 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "Sort_by_SentenceNo = True #@param {type:\"boolean\"}\n",
        "\n",
        "# Context Details\n",
        "No_Paragraphs_on_Each_Side = 1 #@param {type:\"slider\", min:0, max:5, step:1}\n",
        "Highlight_Sentence = False #@param {type:\"boolean\"}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "if Sort_by_SentenceNo == True:\n",
        "  sort_on = 'sent_no'\n",
        "else:\n",
        "  sort_on = 'sentiment_val'\n",
        "  \n",
        "if Save_to_Report == False:\n",
        "  crux_sortsents_report(model_crux_ls, \n",
        "                        ts_df = corpus_sentimentr_df,\n",
        "                        library_type='sentimentr',\n",
        "                        top_n=Get_n_Cruxes, \n",
        "                        get_peaks=Get_Peak_Cruxes, \n",
        "                        sort_by = sort_on, # sent_no, or abs(polarity)\n",
        "                        n_sideparags=No_Paragraphs_on_Each_Side,\n",
        "                        sentence_highlight=Highlight_Sentence)\n",
        "\n",
        "else:\n",
        "  # https://www.kite.com/python/answers/how-to-get-stdout-and-stderr-from-a-process-as-a-string-in-python\n",
        "  # process = subprocess.run([\"echo\", \"This goes to stdout\"], capture_output=True)\n",
        "  # stdout_as_str = process.stdout.decode(\"utf-8\")\n",
        "  # print(stdout_as_str)\n",
        "  temp_out = StringIO()\n",
        "  sys.stdout = temp_out\n",
        "  crux_sortsents_report(model_crux_ls, top_n=Get_n_Cruxes, get_peaks=Get_Peak_Cruxes, n_sideparags=No_Paragraphs_on_Each_Side)\n",
        "  print(temp_out)\n",
        "  # attempt to save temp_out to generated filename\n",
        "  sys.stdout = sys.__stdout__\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rK7kMax60GN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fHyY7YBsbcn"
      },
      "source": [
        "**Zoom in on Context surrounding a particular Crux Point**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Enter [Crux_Sentence_No] that matches a Crux point/Sentence No you want to explore\n",
        "\n",
        "* Enter [No_Paragraphs_on_Each_Side] to retrieve this many Paragraphs before and after the Paragraph containing your Crux Sentence (e.g. 2 will bring back 5 paragraphs centered around the Paragraph containing the Crux Sentence)\n",
        "\n",
        "* Select [Highlight_Crux_Sentence] to have the Crux Sentence converted to ALL CAPS for easier identification. The Paragraph containing the Crux Sentence will be prefaced with a '<*>' as well.\n",
        "\n",
        "* Select [Save_to_File] to also save output to external *.txt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4W7iWQErsbco"
      },
      "source": [
        "# Select details about the Crux Point Context to Retrieve\n",
        "\n",
        "# print(f'Last Sentence No: {corpus_sents_df.shape[0]}')\n",
        "Crux_Sentence_No =  2400#@param {type:\"number\"}\n",
        "No_Paragraphs_on_Each_Side = 0 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "Highlight_Crux_Sentence = True #@param {type:\"boolean\"}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "corpus_sents_len = corpus_sents_df.shape[0]\n",
        "\n",
        "# if (Crux_Sentence_No >= No_Paragraphs_on_Each_Side) & (Crux_Sentence_No+No_Paragraphs_on_Each_Side <= corpus_parag_len):\n",
        "# get_sentnocontext_report()\n",
        "# try:\n",
        "get_sentnocontext_report(the_sent_no=Crux_Sentence_No, \n",
        "                         the_n_sideparags=No_Paragraphs_on_Each_Side, \n",
        "                         the_sent_highlight=Highlight_Crux_Sentence)\n",
        "# except:\n",
        "#   print('ERROR')\n",
        "# else:\n",
        "#   print(f'ERROR: The combination of your [Crux_Sentence_No] and [No_Pargraphs_on_Each_Side]\\n       results in a window outside the range of the Corpus Paragraphs.\\n\\n       Try again with different values.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Lbzxj1zwdC6"
      },
      "source": [
        "## **EDA Syuzhet Plots**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1d2Q3zqSES1"
      },
      "source": [
        "#### **Import SyuzhetR Sentiment Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npwz74KeliXE"
      },
      "source": [
        "# Verify SentimentR Sentiment Files exported from RStudio\n",
        "!pwd\n",
        "!ls -altr sum_sentiments*syuzhet*.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVZB9Iff0_Nh"
      },
      "source": [
        "# Get SyuzhetR Sentiment Datafile (with data on 4 Models)\n",
        "\n",
        "SyuzhetR_sentiment_datafile = 'sum_sentiments_syuzhetR_4models_vwoolf_tothelighthouse.csv' #@param {type:\"string\"}\n",
        "\n",
        "sum_sentiments_syuzhetr_filename = SyuzhetR_sentiment_datafile\n",
        "\n",
        "!head -n 3 $sum_sentiments_syuzhetr_filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrxrUOf0w4o7"
      },
      "source": [
        "# (Optional) Read Sentiment Series generated in RStudio by SyuzhetR into DataFrame: corpus_syuzhetr_df\n",
        "#            SKIP if no SyuzhetR sentiment datafile to read in\n",
        "\n",
        "corpus_syuzhetr_df = pd.read_csv(sum_sentiments_syuzhetr_filename, encoding = 'unicode_escape', engine ='python')\n",
        "\n",
        "# Rename columns if necessary\n",
        "\"\"\"\n",
        "col_rename_map = {'Unnamed: 0' : 'sent_no'}\n",
        "                  'ttl_sents_syuzhet_vec' : 'syuzhet',\n",
        "                  'ttl_sents_bing_vec' : 'bing',\n",
        "                  'ttl_sents_afinn_vec' : 'afinn',\n",
        "                  'ttl_sents_nrc_vec' : 'nrc'}\n",
        "\"\"\";\n",
        "# corpus_syuzhetr_df.rename(columns=col_rename_map,inplace=True)\n",
        "corpus_syuzhetr_df.rename(columns={'Unnamed: 0':'sent_no'}, inplace=True)\n",
        "corpus_syuzhetr_df['sent_raw'] = corpus_syuzhetr_df['sent_raw'].astype('string')\n",
        "\n",
        "# create a clean version of Sentence in sent_clean column\n",
        "corpus_syuzhetr_df['sent_clean'] = corpus_syuzhetr_df['sent_raw'].apply(lambda x : clean_text(x))\n",
        "corpus_syuzhetr_df['sent_clean'] = corpus_syuzhetr_df['sent_clean'].astype('string')\n",
        "\n",
        "corpus_syuzhetr_df.head(2)\n",
        "corpus_syuzhetr_df.info()\n",
        "corpus_syuzhetr_df.columns\n",
        "\n",
        "corpus_syuzhetr_len = corpus_syuzhetr_df.shape[0]\n",
        "\n",
        "if corpus_syuzhetr_len != corpus_sents_df.shape[0]:\n",
        "  print('\\n\\n\\n======================================================================\\n')\n",
        "  print(f'ERROR: sentence sentiment values read into corpus_syuzhetr (len={corpus_syuzhetr_len})')\n",
        "  print(f'       is not the same length as corpus_sents_df (len={corpus_sents_df.shape[0]}) ')\n",
        "  print(f'\\nRECOMMENDATION: Use the preprocessed corpus output created by this notebook ')\n",
        "  print(f'                as input to SyuzhetR in RStudio to generate sentiment series')\n",
        "  print(f'                and then retry importing')\n",
        "  print('\\n======================================================================\\n');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfJkHlYp4XGZ"
      },
      "source": [
        "# Add summary statistics\n",
        "\n",
        "corpus_syuzhetr_df['char_len'] = corpus_syuzhetr_df['sent_raw'].apply(lambda x: len(x))\n",
        "corpus_syuzhetr_df['token_len'] = corpus_syuzhetr_df['sent_raw'].apply(lambda x: len(x.split())) \n",
        "\n",
        "corpus_syuzhetr_df.head(2)\n",
        "corpus_syuzhetr_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlJ6MvuOEV5o"
      },
      "source": [
        "roll_str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLjXnXsV4XGc"
      },
      "source": [
        "# Standardize all values with MedianIQR\n",
        "\n",
        "# model_syuzhetr_ls = ['syuzhet', 'bing', 'afinn', 'nrc']\n",
        "\n",
        "for model_syuzehtr in models_syuzhetr_ls:\n",
        "\n",
        "  # Normalize the Sentence Sentiment by dividing Sentiment by Sentence Length\n",
        "  sents_len_ls = list(corpus_syuzhetr_df['token_len'])\n",
        "  sents_sentiment_ls = list(corpus_syuzhetr_df[model_syuzehtr])\n",
        "  sents_sentiment_norm_ls = [sents_sentiment_ls[i]/(sents_len_ls[i]+0.01) for i in range(len(sents_len_ls))]\n",
        "\n",
        "  # RobustStandardize Sentence sentiment values\n",
        "  # corpus_syuzhetr_df[col_lnorm_meanstd]  = mean_std_scaler.fit_transform(np.array(pd.Series(sents_sentiment_norm_ls)).reshape(-1, 1))\n",
        "  col_medianiqr = f'{model_syuzehtr}_medianiqr'\n",
        "  corpus_syuzhetr_df[col_medianiqr]  = median_iqr_scaler.fit_transform(np.array(corpus_syuzhetr_df[model_syuzehtr]).reshape(-1, 1))\n",
        "  col_lnorm_medianiqr = f'{model_syuzehtr}_lnorm_medianiqr'\n",
        "  corpus_syuzhetr_df[col_lnorm_medianiqr]  = median_iqr_scaler.fit_transform(np.array(pd.Series(sents_sentiment_norm_ls)).reshape(-1, 1))\n",
        "\n",
        "# Verify\n",
        "\n",
        "corpus_syuzhetr_df.head(2)\n",
        "corpus_syuzhetr_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgqSba8FKcMd"
      },
      "source": [
        "# Create 4 Standardized versions of each Model: stdscaler, medianiqr both lnormed and not\n",
        "\n",
        "print('\\nBefore Standardization ----------')\n",
        "corpus_syuzhetr_df.columns\n",
        "\n",
        "standardize_ts_ls(corpus_syuzhetr_df, models_syuzhetr_ls)\n",
        "\n",
        "print('\\nAfter Standardization ----------')\n",
        "corpus_syuzhetr_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjq8yt2I_x0u"
      },
      "source": [
        "# Create SMA roll=10% for all models_stdscaler as baseline\n",
        "\n",
        "win_s1per = int(corpus_syuzhetr_df.shape[0] * 1/100)\n",
        "\n",
        "col_stdscaler_roll_ls = []\n",
        "for amodel in models_syuzhetr_ls:\n",
        "  col_stdscaler = f'{amodel}_stdscaler'\n",
        "  col_stdscaler_roll = f'{amodel}_stdscaler_{roll_str}'\n",
        "  corpus_sents_df[col_stdscaler_roll] = corpus_sents_df[col_stdscaler].rolling(10*win_s1per, center=True).mean()\n",
        "  col_stdscaler_roll_ls.append(col_stdscaler_roll)\n",
        "\n",
        "col_stdscaler_roll_mean = col_stdscaler_roll + '_mean'\n",
        "corpus_sents_df[col_stdscaler_roll_mean] = corpus_sents_df[col_stdscaler_roll_ls].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AoBKOFwKD7r"
      },
      "source": [
        "# Create SMA roll=10% for all models_stdscaler as baseline\n",
        "\"\"\"\n",
        "win_s1per = int(corpus_syuzhetr_df.shape[0] * 1/100)\n",
        "\n",
        "col_stdscaler_roll_ls = []\n",
        "for amodel in models_syuzhetr_ls:\n",
        "  col_stdscaler = f'{amodel}_stdscaler'\n",
        "  col_stdscaler_roll = f'{amodel}_stdscaler_{roll_str}'\n",
        "  corpus_syuzhetr_df[col_stdscaler_roll] = corpus_syuzhetr_df[col_stdscaler].rolling(10*win_s1per, center=True).mean()\n",
        "  col_stdscaler_roll_ls.append(col_stdscaler_roll)\n",
        "\n",
        "col_stdscaler_roll_mean = col_stdscaler_roll + '_mean'\n",
        "corpus_syuzhetr_df[col_stdscaler_roll_mean] = corpus_syuzhetr_df[col_stdscaler_roll_ls].mean()\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IDpH20z3lhu"
      },
      "source": [
        "#### **Sentence Syuzhet SMA Plots**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Rb2-8evEaxt"
      },
      "source": [
        "roll_str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acNruMABNvte"
      },
      "source": [
        "# Plotly Interactive/Zoom Sentiment Plots\n",
        "\n",
        "SMA_Window_Percent = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "# display(corpus_sentimentr_df.head())\n",
        "\n",
        "win_per = SMA_Window_Percent             \n",
        "win_roll = int(win_per/100 * corpus_sentimentr_df.shape[0])\n",
        "\n",
        "model_syuzhetr_ls = ['syuzhet', 'bing', 'afinn', 'nrc']\n",
        "\n",
        "\n",
        "col_name_roll_ls = []\n",
        "# fig, ax = plt.subplots()\n",
        "for amodel in model_syuzhetr_ls:\n",
        "  # if not(amodel.endswith('roll050')):\n",
        "  if len(str(win_per)) == 1:\n",
        "    roll_str = 'roll0' + str(win_per)\n",
        "  else:\n",
        "    roll_str = 'roll' + str(win_per)\n",
        "  col_name_roll = f'{amodel}_{roll_str}'\n",
        "  col_name_roll_ls.append(col_name_roll)\n",
        "  # else:\n",
        "  #   col_name_roll_ls.append(amodel)\n",
        "  corpus_syuzhetr_df[col_name_roll] = corpus_syuzhetr_df[amodel].rolling(win_roll, center=True).mean()\n",
        "\n",
        "col_mean_roll = 'mean_' + roll_str\n",
        "corpus_syuzhetr_df[col_mean_roll] = corpus_syuzhetr_df[col_name_roll_ls].mean(axis=1)\n",
        "\n",
        "\n",
        "palette = cycle(px.colors.qualitative.Bold)\n",
        "# palette = cycle(px.colors.sequential.PuBu)\n",
        "\n",
        "my_layout = go.Layout(\n",
        "    autosize=False,\n",
        "    width=1600,\n",
        "    height=800,\n",
        "    margin=go.layout.Margin(\n",
        "        l=10,\n",
        "        r=50,\n",
        "        b=100,\n",
        "        t=100,\n",
        "        pad = 1\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "fig = go.Figure(layout=my_layout)\n",
        "\n",
        "# add traces\n",
        "\n",
        "model = 'mean_' + roll_str\n",
        "fig.add_traces(go.Line(x=corpus_syuzhetr_df['sent_no'],\n",
        "                       y = corpus_syuzhetr_df[model],\n",
        "                       line=dict(\n",
        "                            color='#000000',\n",
        "                            width=5\n",
        "                            ),\n",
        "                       text = corpus_syuzhetr_df.index.values,\n",
        "                       name = model,\n",
        "                       hovertemplate = \"Model <b>Mean: \"+str(win_per)+\"%</b><br>Sentence #<b>%{x}</b><br>Polarity <b>%{y}</b>\", \n",
        "                       marker_color=next(palette)))\n",
        "\n",
        "\n",
        "for amodel in model_syuzhetr_ls:\n",
        "  model_roll = f'{amodel}_' + roll_str\n",
        "  fig.add_traces(go.Line(x=corpus_syuzhetr_df['sent_no'],\n",
        "                        y = corpus_syuzhetr_df[model_roll],\n",
        "                        text = corpus_syuzhetr_df['sent_raw'],\n",
        "                        name = model_roll,\n",
        "                        hovertemplate = \"Model <b>\"+model_roll+\"</b><br>Sentence #<b>%{x}</b><br>Polarity <b>%{y:.4f}</b><br>Index: <b><i>%{text}</i></b>\", \n",
        "                        marker_color=next(palette)))\n",
        "\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"SyuzhetR Sentence Sentiment Models <b><i>\" + roll_str.upper() + '</i></b>',\n",
        "    xaxis_title=\"Sentence Number\",\n",
        "    # yaxis_title=\"Sentiment Value\",\n",
        "    hoverlabel=dict(\n",
        "        bgcolor=\"white\",\n",
        "        font_size=16,\n",
        "        font_family=\"Rockwell\"\n",
        "    ),\n",
        "    font=dict(\n",
        "        family=\"Courier New, monospace\",\n",
        "        size=18,\n",
        "        color=\"RebeccaPurple\"\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aUtGZvXd406"
      },
      "source": [
        "#### **(ABOVE) Plotly SMA Sentence Syuzhet**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMIE4UF_PlxL"
      },
      "source": [
        "#### **Comparison of Sentence SyuzhetR Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crwKAbkgEdYr"
      },
      "source": [
        "roll_str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0iHrpqpmnuE"
      },
      "source": [
        "# Compare Sentence SyuzhetR Standardized Sentiment Values\n",
        "\n",
        "# model_syuzhetr_ls = ['syuzhet', 'bing', 'afinn', 'nrc']\n",
        "\n",
        "model_syuzhetr_standardized_roll_ls = []\n",
        "for amodel in models_syuzhetr_ls:\n",
        "  col_roll_name = f'{amodel}_{roll_str}'  # TODO: drop lnorm_medianiqr earlier and just Standardize here\n",
        "                                                     # NOTE: Simple SciPy StandardScaler works on SMA Series that don't have outliers like Raw Series\n",
        "  # print(f'col_name: {col_name}')\n",
        "  model_syuzhetr_standardized_roll_ls.append(col_roll_name)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "for i,arollmodel in enumerate(model_syuzhetr_standardized_roll_ls):\n",
        "  print(f'Processing model: {arollmodel}')\n",
        "  col_name_roll_stand = f'{arollmodel}_stdscale'\n",
        "  # print(f'col_name_roll_stand: {col_name_roll_stand}')\n",
        "  model_roll_stand_np = np.array(corpus_syuzhetr_df[arollmodel])\n",
        "  # .apply(lambda x: Scale_SentimentR*x))\n",
        "  \n",
        "  model_roll_stand_np = model_roll_stand_np.reshape((len(model_roll_stand_np), 1))\n",
        "\n",
        "  scaler = scaler.fit(model_roll_stand_np)\n",
        "  print('Mean: %f, StandardDeviation: %f' % (scaler.mean_, np.sqrt(scaler.var_)))\n",
        "  model_roll_stand_xform_np = scaler.transform(model_roll_stand_np)\n",
        "\n",
        "  print(f'  Adding StdScaler Column: {col_name_roll_stand}')\n",
        "  corpus_syuzhetr_df[col_name_roll_stand] = pd.Series(model_roll_stand_xform_np.flatten())\n",
        "\n",
        "  # Plot\n",
        "  corpus_syuzhetr_df[col_name_roll_stand].plot(label=arollmodel) # label=col_name_roll_stand))\n",
        "\n",
        "plt.grid()\n",
        "plt.title(f'{CORPUS_FULL} Compare Sentence SyuzhetR Sentiments\\nMean Length-Normed MedianIQR Sentiments SMA ({roll_str.capitalize()})')\n",
        "plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Onf1ah-vPlAT"
      },
      "source": [
        "# Create a comparison DataFrame of SentimentR Sentence Models\n",
        "# Sentence Heatmap Correlation of StdScaler Roll100 Sentiments\n",
        "# Depends on 'col_stdscaler_rollwin_ls' defined in prior code cell\n",
        "\n",
        "Correlation_Algo = \"kendall\" #@param [\"pearson\", \"spearman\", \"kendall\"]\n",
        "\n",
        "# syuzhetr_corr_models_ls = ['syuzhet', 'bing', 'afinn', 'nrc']\n",
        "\n",
        "corr_df = corpus_syuzhetr_df[models_syuzhetr_ls].corr(method=Correlation_Algo)\n",
        "\n",
        "# Customize the heatmap of the corr_meat correlation matrix and rotate the x-axis labels\n",
        "fig = sns.clustermap(corr_df,\n",
        "                     row_cluster=True,\n",
        "                     col_cluster=True,\n",
        "                     figsize=(10, 10))\n",
        "\n",
        "plt.setp(fig.ax_heatmap.xaxis.get_majorticklabels(), rotation=90)\n",
        "plt.setp(fig.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
        "plt.title(f'{CORPUS_FULL} Sentence Sentiment for SyuzhetR Model Sentiments\\n {Correlation_Algo.capitalize()} Correlation - StdScale Sentiments SMA ({roll_str.capitalize()})')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OemcAFXd6JD5"
      },
      "source": [
        "#### **Explore Crux Points and Contexts**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oGL8mXZNBUw"
      },
      "source": [
        "**Search Corpus for Substring**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* In [Search_for_Substring] enter a Substring to search for in the Corpus\n",
        "\n",
        "* Enter a Substring long enough/unique enough so only a reasonable number of Sentences will be returned\n",
        "\n",
        "* Substring can contain spaces/punctuation, for example: 'in the garden'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMelwTuTNBUx"
      },
      "source": [
        "# Search Corpus Sentences for Substring\n",
        "\n",
        "Search_for_Substring = \"death.\" #@param {type:\"string\"}\n",
        "\n",
        "sentno_matching_ls = corpus_sents_df[corpus_sents_df['sent_raw'].str.contains(Search_for_Substring, regex=False)]['sent_no']\n",
        "\n",
        "for i, asentno in enumerate(sentno_matching_ls):\n",
        "  # sentno, sentraw = asent\n",
        "  print(f\"\\n\\nMatch #{i}: Sentence #{asentno}\\n\\n\")\n",
        "  sent_highlight = re.sub(Search_for_Substring, Search_for_Substring.upper(), corpus_sents_df.iloc[asentno]['sent_raw'])\n",
        "  print(f'    {sent_highlight}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "262TERB06JD8"
      },
      "source": [
        "**Plot Top-n Crux Peaks/Valleys for selected Model**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Select [Crux_Window_Percent] exclusive zone around Crux Points as a percentage of Corpus length\n",
        "\n",
        "* [Sentiment_Model] Select a Sentiment Analysis model\n",
        "\n",
        "* Select [Anomaly_Detction] to plot raw Sentiment values to detect outlier/anomaly Sentences. Leave unchecked to plot SMA smoothed Sentiment arc and detect Crux points\n",
        "\n",
        "* Select [Save_to_File] to also save plot to external *.png file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRnCoDR_Btgd"
      },
      "source": [
        "roll_str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhmPgogw6JEA"
      },
      "source": [
        "Crux_Window_Percent = 5 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "SyuzhetR_SMA_Model = \"Syuzhet\" #@param [\"Syuzhet\", \"Bing\", \"AFINN\", \"NRC\"]\n",
        "Anomaly_Detection = False #@param {type:\"boolean\"}\n",
        "Vertical_Labels = True #@param {type:\"boolean\"}\n",
        "Vertical_Labels_Height = -0.15 #@param {type:\"slider\", min:-5.0, max:5.0, step:0.05}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "if SyuzhetR_SMA_Model == 'Syuzhet':\n",
        "  model_selected = f'syuzhet'\n",
        "if SyuzhetR_SMA_Model == 'Bing':\n",
        "  model_selected = f'bing'\n",
        "if SyuzhetR_SMA_Model == 'AFINN':\n",
        "  model_selected = f'afinn'\n",
        "if SyuzhetR_SMA_Model == 'NRC':\n",
        "  model_selected = f'nrc'\n",
        "\n",
        "if Anomaly_Detection == False:\n",
        "  # (a) Use Sentence SMA smoothed Sentiment models to detect Crux Points\n",
        "  model_selected_fullname = f'{model_selected}_{roll_str}'\n",
        "  print(f'model_selected_fullname: {model_selected_fullname}')\n",
        "else:\n",
        "  # (b)Use Sentence Raw Sentiment models to detect outliers\n",
        "  model_selected_fullname = f'{model_selected}'\n",
        "\n",
        "\n",
        "# TODO: enable multiple overlay crux points with underlying mean/median arc\n",
        "corpus_models_selected_ls = [model_selected_fullname]\n",
        "print(f'corpus_models_selected_ls: {corpus_models_selected_ls}')\n",
        "\n",
        "# Warning: requires definitions of: x, section_sents_df\n",
        "#          so Baseline models must be run first\n",
        "\n",
        "for amodel in corpus_models_selected_ls:\n",
        "  corpus_cruxes_all_dt[amodel] = get_crux_points(ts_df=corpus_syuzhetr_df, \n",
        "                                         col_series=corpus_models_selected_ls, \n",
        "                                         text_type='sentence', \n",
        "                                         win_per=Crux_Window_Percent, \n",
        "                                         sec_y_labels=Vertical_Labels,\n",
        "                                         sec_y_height=Vertical_Labels_Height, \n",
        "                                         subtitle_str='5% Crux - ', \n",
        "                                         do_plot=True, \n",
        "                                         save2file=False)\n",
        "  \n",
        "model_crux_ls = corpus_cruxes_all_dt[amodel]\n",
        "print(f'model_crux_ls: {model_crux_ls}');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jhx-E08q6JEF"
      },
      "source": [
        "**Get Top-n Crux Peaks/Valleys with surrounding Context**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Select [Get_Peak_Cruxes] to retrieve Peaks (if unchecked Valleys are retrieved)\n",
        "\n",
        "* [Get_n_Cruxes] determines how many Top-n Cruxes to retrieve\n",
        "\n",
        "* Enter [No_Paragraphs_on_Each_Side] to retrieve this many Paragraphs before and after the Paragraph containing your Crux Sentence (e.g. 2 will bring back 5 paragraphs centered around the Paragraph containing the Crux Sentence)\n",
        "\n",
        "* Select [Highlight_Crux_Sentence] to have the Crux Sentence converted to ALL CAPS for easier identification. The Paragraph containing the Crux Sentence will be prefaced with a '<*>' as well.\n",
        "\n",
        "* Select [Save_to_File] to also save output to external *.txt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sx47zojLBr6f"
      },
      "source": [
        "roll_str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxq3Irr36JEK"
      },
      "source": [
        "# Crux Details\n",
        "Get_Peak_Cruxes = True #@param {type:\"boolean\"}\n",
        "Get_n_Cruxes = 20 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "Sort_by_SentenceNo = True #@param {type:\"boolean\"}\n",
        "\n",
        "# Context Details\n",
        "No_Paragraphs_on_Each_Side = 2 #@param {type:\"slider\", min:0, max:5, step:1}\n",
        "Highlight_Sentence = True #@param {type:\"boolean\"}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "\n",
        "if Sort_by_SentenceNo == True:\n",
        "  sort_on = 'sent_no'\n",
        "else:\n",
        "  sort_on = 'sentiment_val'\n",
        "\n",
        "\n",
        "if Save_to_Report == False:\n",
        "  crux_sortsents_report(model_crux_ls, \n",
        "                        ts_df = corpus_syuzhetr_df,\n",
        "                        library_type='syuzhetr',\n",
        "                        top_n=Get_n_Cruxes, \n",
        "                        get_peaks=Get_Peak_Cruxes, \n",
        "                        sort_by = sort_on, # sent_no, or abs(polarity)\n",
        "                        n_sideparags=No_Paragraphs_on_Each_Side,\n",
        "                        sentence_highlight=Highlight_Sentence)\n",
        "\n",
        "else:\n",
        "  # https://www.kite.com/python/answers/how-to-get-stdout-and-stderr-from-a-process-as-a-string-in-python\n",
        "  # process = subprocess.run([\"echo\", \"This goes to stdout\"], capture_output=True)\n",
        "  # stdout_as_str = process.stdout.decode(\"utf-8\")\n",
        "  # print(stdout_as_str)\n",
        "  temp_out = StringIO()\n",
        "  sys.stdout = temp_out\n",
        "  crux_sortsents_report(model_crux_ls, top_n=Get_n_Cruxes, get_peaks=Get_Peak_Cruxes, n_sideparags=No_Paragraphs_on_Each_Side)\n",
        "  print(temp_out)\n",
        "  # attempt to save temp_out to generated filename\n",
        "  sys.stdout = sys.__stdout__\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FE5BtcJ6JEN"
      },
      "source": [
        "**Zoom in on Context surrounding a particular Crux Point**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Enter [Crux_Sentence_No] that matches a Crux point/Sentence No you want to explore\n",
        "\n",
        "* Enter [No_Paragraphs_on_Each_Side] to retrieve this many Paragraphs before and after the Paragraph containing your Crux Sentence (e.g. 2 will bring back 5 paragraphs centered around the Paragraph containing the Crux Sentence)\n",
        "\n",
        "* Select [Highlight_Crux_Sentence] to have the Crux Sentence converted to ALL CAPS for easier identification. The Paragraph containing the Crux Sentence will be prefaced with a '<*>' as well.\n",
        "\n",
        "* Select [Save_to_File] to also save output to external *.txt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsfMfACJ6JES"
      },
      "source": [
        "# Select details about the Crux Point Context to Retrieve\n",
        "\n",
        "# print(f'Last Sentence No: {corpus_sents_df.shape[0]}')\n",
        "Crux_Sentence_No =  200#@param {type:\"number\"}\n",
        "No_Paragraphs_on_Each_Side = 5 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "Highlight_Crux_Sentence = True #@param {type:\"boolean\"}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "corpus_sents_len = corpus_sents_df.shape[0]\n",
        "\n",
        "# if (Crux_Sentence_No >= No_Paragraphs_on_Each_Side) & (Crux_Sentence_No+No_Paragraphs_on_Each_Side <= corpus_parag_len):\n",
        "# get_sentnocontext_report()\n",
        "# try:\n",
        "\n",
        "get_sentnocontext_report(the_sent_no=Crux_Sentence_No, \n",
        "                         the_n_sideparags=No_Paragraphs_on_Each_Side, \n",
        "                         the_sent_highlight=Highlight_Crux_Sentence)\n",
        "\n",
        "get_sentnocontext_report(the_sent_no=Crux_Sentence_No, \n",
        "                         the_n_sideparags=No_Paragraphs_on_Each_Side, \n",
        "                         the_sent_highlight=Highlight_Crux_Sentence)\n",
        "# except:\n",
        "#   print('ERROR')\n",
        "# else:\n",
        "#   print(f'ERROR: The combination of your [Crux_Sentence_No] and [No_Pargraphs_on_Each_Side]\\n       results in a window outside the range of the Corpus Paragraphs.\\n\\n       Try again with different values.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpHVFidu7whr"
      },
      "source": [
        "#### **Compare Sentence SentimentR vs Syuzhet Sentiment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdtWV6ViKnWH"
      },
      "source": [
        "roll_str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzzmTp93CTiE"
      },
      "source": [
        "corpus_syuzhetr_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLwVnxNdBx-W"
      },
      "source": [
        "corpus_sentimentr_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lb8TqPsEN4A"
      },
      "source": [
        "roll_str = 'roll10'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXY05cztTMl_"
      },
      "source": [
        "# Compare Sentence SentimentR vs SyuzhetR SMA smoothed series\n",
        "\"\"\"\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Standardize SentimentR Mean Rolling\n",
        "sentimentr_mean_roll_np = np.array(corpus_sentimentr_df[f'mean_{roll_str}'])\n",
        "sentimentr_mean_roll_np = sentimentr_mean_roll_np.reshape((len(sentimentr_mean_roll_np), 1))\n",
        "\n",
        "scaler = scaler.fit(sentimentr_mean_roll_np)\n",
        "print('Mean: %f, StandardDeviation: %f' % (scaler.mean_, np.sqrt(scaler.var_)))\n",
        "# standardization the dataset and print the first 5 rows\n",
        "sentimentr_mean_roll_norm_np = scaler.transform(sentimentr_mean_roll_np)\n",
        "\n",
        "# Standardize SyuzhetR Mean Rolling\n",
        "syuzhetr_mean_roll_np = np.array(corpus_syuzhetr_df[f'mean_{roll_str}'])\n",
        "syuzhetr_mean_roll_np = syuzhetr_mean_roll_np.reshape((len(syuzhetr_mean_roll_np), 1))\n",
        "\n",
        "scaler = scaler.fit(syuzhetr_mean_roll_np)\n",
        "print('Mean: %f, StandardDeviation: %f' % (scaler.mean_, np.sqrt(scaler.var_)))\n",
        "# standardization the dataset and print the first 5 rows\n",
        "syuzhetr_mean_roll_norm_np = scaler.transform(syuzhetr_mean_roll_np)\n",
        "\n",
        "\n",
        "# Plot normalized Series\n",
        "plt.plot(sentimentr_mean_roll_norm_np, label=\"SentimentR\")\n",
        "plt.plot(syuzhetr_mean_roll_norm_np, label=\"SyuzhetR\")\n",
        "# plt.plot(transformer_mean_roll_norm_np, label=\"SyuzhetR\")\n",
        "\"\"\";\n",
        "\n",
        "# corpus_syuzhetr_df[f'mean_{roll_str}'].apply(lambda x: Scale_SyuzhetR*x).plot(label='SyuzhetR')\n",
        "col_mean_stdscaler_roll = f'mean_stdscaler_{roll_str}'\n",
        "\n",
        "col_all_sentimentr_stdscaler_roll_ls = []\n",
        "for x in models_sentimentr_ls:\n",
        "  col_name = f'{x}_stdscaler_{roll_str}'\n",
        "  col_all_sentimentr_stdscaler_roll_ls.append(col_name)\n",
        "corpus_sentimentr_df[col_mean_stdscaler_roll] = corpus_sentimentr_df[col_all_sentimentr_stdscaler_roll_ls].mean()\n",
        "\n",
        "col_all_syuzhetr_stdscaler_roll_ls = []\n",
        "for x in models_syuzhetr_ls:\n",
        "  col_name = f'{x}_stdscaler_{roll_str}'\n",
        "  col_all_syuzhetr_stdscaler_roll_ls.append(col_name)\n",
        "corpus_syuzhetr_df[col_mean_stdscaler_roll] = corpus_syuzhetr_df[col_all_syuzhetr_stdscaler_roll_ls].mean()\n",
        "\n",
        "# Plot\n",
        "plt.plot(corpus_sentimentr_df[col_mean_stdscaler_roll], label=f\"SentimentR Mean StdScaler {roll_str}\")\n",
        "plt.plot(corpus_syuzhetr_df[col_mean_stdscaler_roll], label=f\"SyuzhetR Mean StdScaler {roll_str}\")\n",
        "\n",
        "\n",
        "plt.grid()\n",
        "plt.title(f'{CORPUS_FULL} Sentence SentimentR vs Syuzhet Sentiments\\nMean Length-Normed MedianIQR Sentiments SMA ({roll_str.capitalize()})')\n",
        "plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzAonJx6FDna"
      },
      "source": [
        "roll_str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twq2IuGz7vlR"
      },
      "source": [
        "# Compare Sentence SentimentR vs SyuzhetR SMA smoothed series\n",
        "# TODO: Delete or convert to fine grained/multi-model DTW/correlation\n",
        "\n",
        "# Create a unified DataFrame of Mean Roll_{win_per} from\n",
        "#     SentimentR and SyuzhetR\n",
        "\n",
        "col_mean_roll = f'mean_{roll_str}'\n",
        "\n",
        "compare_sentimentr_syuzhetr_df = pd.concat([\n",
        "    corpus_sentimentr_df[col_mean_roll],\n",
        "    corpus_syuzhetr_df[col_mean_roll]],\n",
        "    axis=1)\n",
        "\n",
        "col_sentimentr_mean_roll = f'sentimentr_{col_mean_roll}'\n",
        "col_syuzhetr_mean_roll = f'syuzhet_{col_mean_roll}'\n",
        "\n",
        "col_mapping = {\n",
        "    compare_sentimentr_syuzhetr_df.columns[0]:'sentimentr_mean_roll', \n",
        "    compare_sentimentr_syuzhetr_df.columns[1]:'syuzhet_mean_roll'\n",
        "}\n",
        "\n",
        "compare_sentimentr_syuzhetr_df.rename(columns=col_mapping,\n",
        "                                      inplace=True)\n",
        "\n",
        "# compare_sentimentr_syuzhetr_df.iloc[1000:1005]\n",
        "\n",
        "\n",
        "# Get correlation matrix of the comparison DataFrame\n",
        "corr_df = compare_sentimentr_syuzhetr_df.corr(method='spearman')\n",
        "\n",
        "# Customize the heatmap of the corr_meat correlation matrix and rotate the x-axis labels\n",
        "fig = sns.clustermap(corr_df,\n",
        "                     row_cluster=True,\n",
        "                     col_cluster=True,\n",
        "                     figsize=(10, 10))\n",
        "\n",
        "plt.setp(fig.ax_heatmap.xaxis.get_majorticklabels(), rotation=90)\n",
        "plt.setp(fig.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yF6RbP2wegA"
      },
      "source": [
        "## **EDA Transformer Plots**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8wOUSyOSIVs"
      },
      "source": [
        "#### **Import Transformer Sentiment Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5Trl2jZ1Yi8"
      },
      "source": [
        "# Verify SentimentR Sentiment Files exported from RStudio\n",
        "!pwd\n",
        "!ls -altr sum_sentiments*trans*.csv\n",
        "# sum_sentiments_sents_trans_vwoolf_tothelighthouse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnyvNjy91YjF"
      },
      "source": [
        "# Get SyuzhetR Sentiment Datafile (with data on 4 Models)\n",
        "\n",
        "Transformer_sentiment_datafile = 'sum_sentiments_sents_trans_vwoolf_tothelighthouse.csv' #@param {type:\"string\"}\n",
        "\n",
        "sum_sentiments_transformer_filename = Transformer_sentiment_datafile\n",
        "\n",
        "!head -n 3 $sum_sentiments_transformer_filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vp_L394e1ngv"
      },
      "source": [
        "# (Optional) Read Sentiment Series generated in RStudio by SyuzhetR into DataFrame: corpus_transformer_df\n",
        "#            SKIP if no SyuzhetR sentiment datafile to read in\n",
        "\n",
        "corpus_transformer_df = pd.read_csv(sum_sentiments_transformer_filename, encoding = 'unicode_escape', engine ='python')\n",
        "\n",
        "# Rename columns if necessary\n",
        "\"\"\"\n",
        "col_rename_map = {'Unnamed: 0' : 'sent_no'}\n",
        "                  'ttl_sents_syuzhet_vec' : 'syuzhet',\n",
        "                  'ttl_sents_bing_vec' : 'bing',\n",
        "                  'ttl_sents_afinn_vec' : 'afinn',\n",
        "                  'ttl_sents_nrc_vec' : 'nrc'}\n",
        "\"\"\";\n",
        "# corpus_transformer_df.rename(columns=col_rename_map,inplace=True)\n",
        "corpus_transformer_df['sent_raw'] = corpus_transformer_df['sent_raw'].astype('string')\n",
        "# corpus_transformer_df['sent_clean'] = corpus_transformer_df['sent_clean'].astype('string')\n",
        "corpus_transformer_df.drop(columns=['Unnamed: 0'],inplace=True)\n",
        "\n",
        "corpus_transformer_df.head(2)\n",
        "corpus_transformer_df.info()\n",
        "corpus_transformer_df.columns\n",
        "\n",
        "corpus_transformer_len = corpus_transformer_df.shape[0]\n",
        "\n",
        "if corpus_transformer_len != corpus_transformer_df.shape[0]:\n",
        "  print('\\n\\n\\n======================================================================\\n')\n",
        "  print(f'ERROR: sentence sentiment values read into corpus_syuzhetr (len={corpus_transformer_len})')\n",
        "  print(f'       is not the same length as corpus_transformer_df (len={corpus_transformer_df.shape[0]}) ')\n",
        "  print(f'\\nRECOMMENDATION: Use the preprocessed corpus output created by this notebook ')\n",
        "  print(f'                as input to SyuzhetR in RStudio to generate sentiment series')\n",
        "  print(f'                and then retry importing')\n",
        "  print('\\n======================================================================\\n');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYZ7xFFDQrzD"
      },
      "source": [
        "# Add summary statistics\n",
        "\n",
        "corpus_transformer_df['sent_clean'] = corpus_transformer_df['sent_raw'].apply(lambda x: clean_text(x))\n",
        "corpus_transformer_df['char_len'] = corpus_transformer_df['sent_raw'].apply(lambda x: len(x))\n",
        "corpus_transformer_df['token_len'] = corpus_transformer_df['sent_clean'].apply(lambda x: len(x.split())) \n",
        "\n",
        "corpus_transformer_df.head(2)\n",
        "corpus_transformer_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgzWVkAYKqS-"
      },
      "source": [
        "# Create 4 Standardized versions of each Model: stdscaler, medianiqr both lnormed and not\n",
        "\n",
        "print('\\nBefore Standardization ----------')\n",
        "corpus_transformer_df.columns\n",
        "\n",
        "standardize_ts_ls(corpus_transformer_df, models_transformer_ls)\n",
        "\n",
        "print('\\nAfter Standardization ----------')\n",
        "corpus_transformer_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP5laVK8Ee9a"
      },
      "source": [
        "# Create SMA roll=10% for all models_stdscaler as baseline\n",
        "\n",
        "win_s1per = int(corpus_transformer_df.shape[0] * 1/100)\n",
        "\n",
        "col_stdscaler_roll_ls = []\n",
        "for amodel in models_transformer_ls:\n",
        "  col_stdscaler = f'{amodel}_stdscaler'\n",
        "  col_stdscaler_roll = f'{amodel}_stdscaler_{roll_str}'\n",
        "  corpus_transformer_df[col_stdscaler_roll] = corpus_transformer_df[col_stdscaler].rolling(10*win_s1per, center=True).mean()\n",
        "  col_stdscaler_roll_ls.append(col_stdscaler_roll)\n",
        "\n",
        "col_stdscaler_roll_mean = col_stdscaler_roll + '_mean'\n",
        "corpus_transformer_df[col_stdscaler_roll_mean] = corpus_transformer_df[col_stdscaler_roll_ls].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_iGanTXZSGB"
      },
      "source": [
        "# Standardize all values with MedianIQR\n",
        "\"\"\"\n",
        "model_transformers_ls = ['nlptown', 'roberta15lg', 'yelp', 'hinglish', 'imdb2way', 'huggingface', 't5imdb50k', 'robertaxml8lang']\n",
        "\n",
        "for model_transformer in model_transformers_ls:\n",
        "\n",
        "  # Normalize the Sentence Sentiment by dividing Sentiment by Sentence Length\n",
        "  sents_len_ls = list(corpus_transformer_df['token_len'])\n",
        "  sents_sentiment_ls = list(corpus_transformer_df[model_transformer])\n",
        "  sents_sentiment_norm_ls = [sents_sentiment_ls[i]/(sents_len_ls[i]+0.01) for i in range(len(sents_len_ls))]\n",
        "\n",
        "  # RobustStandardize Sentence sentiment values\n",
        "  # corpus_transformer_df[col_lnorm_meanstd]  = mean_std_scaler.fit_transform(np.array(pd.Series(sents_sentiment_norm_ls)).reshape(-1, 1))\n",
        "  col_medianiqr = f'{model_transformer}_medianiqr'\n",
        "  corpus_transformer_df[col_medianiqr]  = median_iqr_scaler.fit_transform(np.array(corpus_transformer_df[model_transformer]).reshape(-1, 1))\n",
        "  col_lnorm_medianiqr = f'{model_transformer}_lnorm_medianiqr'\n",
        "  corpus_transformer_df[col_lnorm_medianiqr]  = median_iqr_scaler.fit_transform(np.array(pd.Series(sents_sentiment_norm_ls)).reshape(-1, 1))\n",
        "\n",
        "  # Verify\n",
        "\n",
        "corpus_transformer_df.head()\n",
        "corpus_transformer_df.info()\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNeuepF33Zyu"
      },
      "source": [
        "#### **Sentence Transformers SMA Plots**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfwwefDOXqq8"
      },
      "source": [
        "RoBERTaLg15_Arc = True #@param {type:\"boolean\"}\n",
        "T5IMDB50k_Arc = True #@param {type:\"boolean\"}\n",
        "Huggingface_Arc = True #@param {type:\"boolean\"}\n",
        "NLPTown_Arc = True #@param {type:\"boolean\"}\n",
        "RoBERTaXML8lang_Arc = True #@param {type:\"boolean\"}\n",
        "IMDB2way_Arc = True #@param {type:\"boolean\"}\n",
        "Hinglish_Arc = True #@param {type:\"boolean\"}\n",
        "Yelp_Arc = True #@param {type:\"boolean\"}\n",
        "Mean_Subset_Arc = False #@param {type:\"boolean\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqYU6I5uWeGc"
      },
      "source": [
        "# Plotly Interactive/Zoom Sentiment Plots\n",
        "\n",
        "SMA_Window_Percent = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "win_per = SMA_Window_Percent\n",
        "win_roll = int(win_per/100 * corpus_transformer_df.shape[0])\n",
        "\n",
        "if len(str(win_per)) == 1:\n",
        "  roll_str = 'roll0' + str(win_per)\n",
        "else:\n",
        "  roll_str = 'roll' + str(win_per)\n",
        "\n",
        "# display(corpus_transformer_df.head())\n",
        "\n",
        "model_transformers_ls = ['nlptown', 'roberta15lg',\n",
        "                         'yelp', 'hinglish',\n",
        "                         'imdb2way', 'huggingface',\n",
        "                         't5imdb50k', 'robertaxml8lang']\n",
        "\n",
        "# list of (scale, center) adjustments for each model so they can be compared on same graph\n",
        "# Scaling Dictionary for each plot in form of tuple (scale, center) \n",
        "#     so they can be compared on same graph\n",
        "model_transformers_scale_dt = {'nlptown' : (0.5, -1),\n",
        "                               'roberta15lg' : (1,0),\n",
        "                               'yelp' : (1.0, 0.5),\n",
        "                               'hinglish' : (1.0, 0.5),\n",
        "                               'imdb2way' : (1.0, 0.5),\n",
        "                               'huggingface' : (1.0, 0.5),\n",
        "                               't5imdb50k' : (1.0, 0.5),\n",
        "                               'robertxml8lang' : (1.0, 0.5)}\n",
        "col_name_roll_ls = []\n",
        "# fig, ax = plt.subplots()\n",
        "for amodel in model_transformers_ls:\n",
        "  # if not(amodel.endswith('roll050')):\n",
        "  # col_name_roll = f'{amodel}_lnorm_medianiqr_{roll_str}'\n",
        "  col_name_roll = f'{amodel}_{roll_str}'\n",
        "  col_name_roll_ls.append(col_name_roll)\n",
        "  # else:\n",
        "  #   col_name_roll_ls.append(amodel)\n",
        "  # print(f'creating: {col_name_roll}')\n",
        "  corpus_transformer_df[col_name_roll] = corpus_transformer_df[amodel].rolling(win_roll, center=True).mean()\n",
        "\n",
        "  col_name_roll_stdscale = f'{col_name_roll}_stdscale'\n",
        "  corpus_transformer_df[col_name_roll_stdscale] = get_standardscaler(col_name_roll, corpus_transformer_df[col_name_roll])\n",
        "\n",
        "\n",
        "col_mean_roll = 'mean_lnorm_medianiqr_' + roll_str\n",
        "# model_transformers_lnorm_medianiqr_ls = []\n",
        "corpus_transformer_df[col_mean_roll] = corpus_transformer_df[col_name_roll_ls].mean(axis=1)\n",
        "\n",
        "col_mean_lnorm_median_roll = 'mean_lnorm_medianiqr_' + roll_str\n",
        "model_transformers_lnorm_medianiqr_ls = []\n",
        "for acol_name in model_transformers_ls:\n",
        "  # model_transformers_lnorm_medianiqr_ls.append(acol_name+'_lnorm_medianiqr_'+roll_str)\n",
        "  model_transformers_lnorm_medianiqr_ls.append(acol_name+ '_' +roll_str + '_stdscale')\n",
        "corpus_transformer_df[col_mean_lnorm_median_roll] = corpus_transformer_df[model_transformers_lnorm_medianiqr_ls].mean(axis=1)\n",
        "\n",
        "\n",
        "# display(corpus_transformer_df.head())\n",
        "\n",
        "\n",
        "model_transformers_subset_ls = []\n",
        "\n",
        "if NLPTown_Arc == True:\n",
        "  model_transformers_subset_ls.append(f'nlptown_{roll_str}_stdscale')\n",
        "if T5IMDB50k_Arc == True:\n",
        "  model_transformers_subset_ls.append(f't5imdb50k_{roll_str}_stdscale')\n",
        "if Huggingface_Arc == True:\n",
        "  model_transformers_subset_ls.append(f'huggingface_{roll_str}_stdscale')\n",
        "if RoBERTaLg15_Arc == True:\n",
        "  model_transformers_subset_ls.append(f'roberta15lg_{roll_str}_stdscale')\n",
        "if RoBERTaXML8lang_Arc == True:\n",
        "  model_transformers_subset_ls.append(f'robertaxml8lang_{roll_str}_stdscale')\n",
        "  #                                     robertaxml8lang_roll100_stdscale\n",
        "if IMDB2way_Arc == True:\n",
        "  model_transformers_subset_ls.append(f'imdb2way_{roll_str}_stdscale')\n",
        "if Hinglish_Arc == True:\n",
        "  model_transformers_subset_ls.append(f'hinglish_{roll_str}_stdscale')\n",
        "if Yelp_Arc == True:\n",
        "  model_transformers_subset_ls.append(f'yelp_{roll_str}_stdscale')\n",
        "\n",
        "for i,amodel in enumerate(model_transformers_subset_ls):\n",
        "  print(f'Plot model: {amodel}')\n",
        "  # corpus_transformer_df[amodel].plot()\n",
        "\n",
        "print(f'model_transformers_subset_ls: {model_transformers_subset_ls}')\n",
        "\n",
        "\"\"\"\n",
        "col_mean_subset_roll = f'mean_subset_{roll_str}'\n",
        "corpus_transformer_df[col_mean_subset_roll] = corpus_transformer_df[model_transformers_subset_ls].mean(axis=1)\n",
        "if Mean_Subset_Arc == True:\n",
        "  model_transformers_subset_ls.append(col_mean_subset_roll)\n",
        "\"\"\";\n",
        "\n",
        "palette = cycle(px.colors.qualitative.Bold)\n",
        "# palette = cycle(px.colors.sequential.PuBu)\n",
        "\n",
        "my_layout = go.Layout(\n",
        "    autosize=False,\n",
        "    width=1600,\n",
        "    height=800,\n",
        "    margin=go.layout.Margin(\n",
        "        l=10,\n",
        "        r=50,\n",
        "        b=100,\n",
        "        t=100,\n",
        "        pad = 1\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "fig = go.Figure(layout=my_layout)\n",
        "\n",
        "# add traces\n",
        "# old: y = model_transformers_subset_ls[i][0]*corpus_transformer_df[amodel]+model_baselines_scale_ls[i][1],\n",
        "for amodel in model_transformers_subset_ls:\n",
        "  # print(f'Plot model: {amodel}')\n",
        "  # corpus_transformer_df[amodel].plot()\n",
        "  fig.add_traces(go.Line(x = corpus_transformer_df['sent_no'],\n",
        "                        y = corpus_transformer_df[amodel],\n",
        "                        text = corpus_transformer_df['sent_raw'],\n",
        "                        name = amodel,\n",
        "                        hovertemplate = \"Model: <b>\"+amodel+\"</b><br>Sentence #<b>%{x}</b><br>Polarity <b>%{y}</b><br>Text: <b><i>%{text}</i></b>\", \n",
        "                        marker_color=next(palette)))\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "if Mean_Subset_Arc == True:\n",
        "  mean_subset_col = 'mean_subset_'+roll_str\n",
        "  corpus_transformer_df[mean_subset_col] = corpus_transformer_df[model_transformers_subset_ls].mean(axis=1)\n",
        "  fig.add_traces(go.Line(x=corpus_transformer_df['sent_no'],\n",
        "                        y = 0.1*corpus_transformer_df[mean_subset_col],\n",
        "                        line=dict(\n",
        "                              # color='#000000',\n",
        "                              width=5\n",
        "                              ),\n",
        "                        text = 'NA', # corpus_transformer_df['sent_raw'],\n",
        "                        name = amodel,\n",
        "                        hovertemplate = \"Model <b>%{mean_subset_col}</b><br>Sentence #<b>%{x}</b><br>Polarity <b>%{y}</b>\", \n",
        "                        marker_color=next(palette)))\n",
        "\"\"\";\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Transformer Sentence Sentiment Models <b><i>\" + roll_str.upper() + '</i></b>',\n",
        "    xaxis_title=\"Sentence Number\",\n",
        "    # yaxis_title=\"Sentiment Value\",\n",
        "    hoverlabel=dict(\n",
        "        bgcolor=\"white\",\n",
        "        font_size=16,\n",
        "        font_family=\"Rockwell\"\n",
        "    ),\n",
        "    font=dict(\n",
        "        family=\"Courier New, monospace\",\n",
        "        size=18,\n",
        "        color=\"RebeccaPurple\"\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16QqsYHTdYqY"
      },
      "source": [
        "#### **(ABOVE) Plotly SMA Sentence Transformers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UWlGJ1IQG9t"
      },
      "source": [
        "#### **Comparison of Sentence Transformer Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr0GPiwjKGuD"
      },
      "source": [
        "corpus_transformer_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzDn0Z83FQXi"
      },
      "source": [
        "roll_str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hD3H_yQcLu8O"
      },
      "source": [
        "# Create a comparison DataFrame of Transformer Sentence Models\n",
        "# Create a comparison DataFrame of Transformer Sentence Models\n",
        "# Sentence Heatmap Correlation of StdScaler Roll100 Sentiments\n",
        "# Depends on 'col_stdscaler_rollwin_ls' defined in prior code cell\n",
        "\n",
        "Correlation_Algo = \"kendall\" #@param [\"pearson\", \"spearman\", \"kendall\"]\n",
        "\n",
        "Correlation_Algo\n",
        "\n",
        "corr_df = corpus_transformer_df[models_transformer_ls].corr(method=Correlation_Algo)\n",
        "\n",
        "# Customize the heatmap of the corr_meat correlation matrix and rotate the x-axis labels\n",
        "fig = sns.clustermap(corr_df,\n",
        "                     row_cluster=True,\n",
        "                     col_cluster=True,\n",
        "                     figsize=(10, 10))\n",
        "\n",
        "plt.setp(fig.ax_heatmap.xaxis.get_majorticklabels(), rotation=90)\n",
        "plt.setp(fig.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
        "plt.title(f'{CORPUS_FULL} Sentence Sentiment for Transformer Model Sentiments\\n {Correlation_Algo.capitalize()} Correlation - StdScale Sentiments SMA ({roll_str.capitalize()})')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqnwt6ygQJws"
      },
      "source": [
        "# Compare Sentence Transformer Standardized Sentiment Values\n",
        "\"\"\"\n",
        "model_transformers_ls = ['nlptown', 'roberta15lg',\n",
        "                         'yelp', 'hinglish',\n",
        "                         'imdb2way', 'huggingface',\n",
        "                         't5imdb50k', 'robertaxml8lang']\n",
        "\n",
        "model_trans_standardized_roll_ls = []\n",
        "for amodel in model_transformers_ls:\n",
        "  col_name = f'{amodel}_{roll_str}_stdscale'  # TODO: drop lnorm_medianiqr earlier and just Standardize here\n",
        "                                                     # NOTE: Simple SciPy StandardScaler works on SMA Series that don't have outliers like Raw Series\n",
        "  # print(f'col_name: {col_name}')\n",
        "  model_trans_standardized_roll_ls.append(col_name)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "for i,amodel in enumerate(model_trans_standardized_roll_ls):\n",
        "  col_name_roll_stand = f'{col_name}_stand'\n",
        "  # print(f'col_name_roll_stand: {col_name_roll_stand}')\n",
        "  model_roll_stand_np = np.array(corpus_transformer_df[amodel])\n",
        "  # .apply(lambda x: Scale_SentimentR*x))\n",
        "  \n",
        "  model_roll_stand_np = model_roll_stand_np.reshape((len(model_roll_stand_np), 1))\n",
        "\n",
        "  scaler = scaler.fit(model_roll_stand_np)\n",
        "  print('Mean: %f, StandardDeviation: %f' % (scaler.mean_, np.sqrt(scaler.var_)))\n",
        "  model_roll_stand_xform_np = scaler.transform(model_roll_stand_np)\n",
        "\n",
        "  corpus_transformer_df[col_name_roll_stand] = pd.Series(model_roll_stand_xform_np.flatten())\n",
        "\n",
        "  # Plot\n",
        "  corpus_transformer_df[col_name_roll_stand].plot(label=amodel) # label=col_name_roll_stand))\n",
        "\n",
        "plt.grid()\n",
        "plt.title(f'{CORPUS_FULL} Compare Sentence Transformer Sentiments\\nMean Length-Normed MedianIQR Sentiments SMA ({roll_str.capitalize()})')\n",
        "plt.legend(loc='best');\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhnAu46O7aq_"
      },
      "source": [
        "#### **Explore Sentence Crux Points and Contexts**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpKbmbsCNFI7"
      },
      "source": [
        "**Search Corpus for Substring**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* In [Search_for_Substring] enter a Substring to search for in the Corpus\n",
        "\n",
        "* Enter a Substring long enough/unique enough so only a reasonable number of Sentences will be returned\n",
        "\n",
        "* Substring can contain spaces/punctuation, for example: 'in the garden'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b35u0YDONFI9"
      },
      "source": [
        "# Search Corpus Sentences for Substring\n",
        "\n",
        "Search_for_Substring = \"love\" #@param {type:\"string\"}\n",
        "\n",
        "sentno_matching_ls = corpus_sents_df[corpus_sents_df['sent_raw'].str.contains(Search_for_Substring, regex=False)]['sent_no']\n",
        "\n",
        "for i, asentno in enumerate(sentno_matching_ls):\n",
        "  # sentno, sentraw = asent\n",
        "  print(f\"\\n\\nMatch #{i}: Sentence #{asentno}\\n\\n\")\n",
        "  sent_highlight = re.sub(Search_for_Substring, Search_for_Substring.upper(), corpus_sents_df.iloc[asentno]['sent_raw'])\n",
        "  print(f'    {sent_highlight}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTFCZI667arB"
      },
      "source": [
        "**Plot Top-n Crux Peaks/Valleys for selected Model**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Select [Crux_Window_Percent] exclusive zone around Crux Points as a percentage of Corpus length\n",
        "\n",
        "* [Sentiment_Model] Select a Sentiment Analysis model\n",
        "\n",
        "* Select [Anomaly_Detction] to plot raw Sentiment values to detect outlier/anomaly Sentences. Leave unchecked to plot SMA smoothed Sentiment arc and detect Crux points\n",
        "\n",
        "* Select [Save_to_File] to also save plot to external *.png file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plR_75zVglhY"
      },
      "source": [
        "models_transformer_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xeZ5Qhb7arB"
      },
      "source": [
        "Crux_Window_Percent = 5 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "SentimentR_SMA_Model = \"RoBERTa Large 15 Databases\" #@param [\"RoBERTa Large 15 Databases\", \"NLPTown\", \"Yelp\", \"Hinglish\", \"IMDB 2 Sentiment\", \"Huggingface\", \"T5 IMDB 50k\", \"RoBERTa XML 8 Languages\"]\n",
        "Anomaly_Detection = False #@param {type:\"boolean\"}\n",
        "Vertical_Labels = False #@param {type:\"boolean\"}\n",
        "Vertical_Labels_Height = 5.4 #@param {type:\"slider\", min:-50, max:50, step:0.1}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "if SentimentR_SMA_Model == 'RoBERTa Large 15 Databases':\n",
        "  model_selected = f'roberta15lg'\n",
        "if SentimentR_SMA_Model == 'NLPTown':\n",
        "  model_selected = f'nlptown'\n",
        "if SentimentR_SMA_Model == 'Yelp':\n",
        "  model_selected = f'yelp'\n",
        "if SentimentR_SMA_Model == 'Hinglish':\n",
        "  model_selected = f'hinglish'\n",
        "if SentimentR_SMA_Model == 'IMDB 2 Sentiment':\n",
        "  model_selected = f'imdb2way'\n",
        "if SentimentR_SMA_Model == 'Huggingface':\n",
        "  model_selected = f'huggingface'\n",
        "if SentimentR_SMA_Model == 'T5 IMDB 50k':\n",
        "  model_selected = f't5imdb50k'\n",
        "if SentimentR_SMA_Model == 'RoBERTa XML 8 Languages':\n",
        "  model_selected = f'robertaxml8lang'\n",
        "\n",
        "if Anomaly_Detection == False:\n",
        "  # (a) Use Sentence SMA smoothed Sentiment models to detect Crux Points\n",
        "  model_selected_fullname = f'{model_selected}_{roll_str}_stdscale'\n",
        "else:\n",
        "  # (b)Use Sentence Raw Sentiment models to detect outliers\n",
        "  model_selected_fullname = f'{model_selected}'\n",
        "\n",
        "# TODO: enable multiple overlay crux points with underlying mean/median arc\n",
        "corpus_models_selected_ls = [model_selected_fullname]\n",
        "print(f'corpus_models_selected_ls: {corpus_models_selected_ls}')\n",
        "\n",
        "# Warning: requires definitions of: x, section_sents_df\n",
        "#          so Baseline models must be run first\n",
        "\n",
        "\n",
        "for amodel in corpus_models_selected_ls:\n",
        "  corpus_cruxes_all_dt[amodel] = get_crux_points(ts_df=corpus_transformer_df, \n",
        "                                         col_series=corpus_models_selected_ls, \n",
        "                                         text_type='sentence', \n",
        "                                         win_per=Crux_Window_Percent, \n",
        "                                         sec_y_labels=Vertical_Labels,\n",
        "                                         sec_y_height=Vertical_Labels_Height, \n",
        "                                         subtitle_str='5% Crux - ', \n",
        "                                         do_plot=True, \n",
        "                                         save2file=False)\n",
        "  \n",
        "model_crux_ls = corpus_cruxes_all_dt[amodel]\n",
        "# model_crux_ls;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P34IC3Kh7arD"
      },
      "source": [
        "**Get Top-n Crux Peaks/Valleys with surrounding Context**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Select [Get_Peak_Cruxes] to retrieve Peaks (if unchecked Valleys are retrieved)\n",
        "\n",
        "* [Get_n_Cruxes] determines how many Top-n Cruxes to retrieve\n",
        "\n",
        "* Enter [No_Paragraphs_on_Each_Side] to retrieve this many Paragraphs before and after the Paragraph containing your Crux Sentence (e.g. 2 will bring back 5 paragraphs centered around the Paragraph containing the Crux Sentence)\n",
        "\n",
        "* Select [Highlight_Crux_Sentence] to have the Crux Sentence converted to ALL CAPS for easier identification. The Paragraph containing the Crux Sentence will be prefaced with a '<*>' as well.\n",
        "\n",
        "* Select [Save_to_File] to also save output to external *.txt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99RhVdHc7arE"
      },
      "source": [
        "Get_Peak_Cruxes = False #@param {type:\"boolean\"}\n",
        "Get_n_Cruxes = 20 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "No_Paragraphs_on_Each_Side = 0 #@param {type:\"slider\", min:0, max:5, step:1}\n",
        "Highlight_Sentence = True #@param {type:\"boolean\"}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "if Sort_by_SentenceNo == True:\n",
        "  sort_on = 'sent_no'\n",
        "else:\n",
        "  sort_on = 'sentiment_val'\n",
        "  \n",
        "if Save_to_Report == False:\n",
        "  crux_sortsents_report(model_crux_ls, \n",
        "                        ts_df = corpus_transformer_df,\n",
        "                        library_type='transformer',\n",
        "                        top_n=Get_n_Cruxes, \n",
        "                        get_peaks=Get_Peak_Cruxes, \n",
        "                        sort_by = sort_on, # sent_no, or abs(polarity)\n",
        "                        n_sideparags=No_Paragraphs_on_Each_Side,\n",
        "                        sentence_highlight=Highlight_Sentence)\n",
        "\n",
        "\n",
        "else:\n",
        "  # https://www.kite.com/python/answers/how-to-get-stdout-and-stderr-from-a-process-as-a-string-in-python\n",
        "  # process = subprocess.run([\"echo\", \"This goes to stdout\"], capture_output=True)\n",
        "  # stdout_as_str = process.stdout.decode(\"utf-8\")\n",
        "  # print(stdout_as_str)\n",
        "  temp_out = StringIO()\n",
        "  sys.stdout = temp_out\n",
        "  crux_sortsents_report(model_crux_ls, top_n=Get_n_Cruxes, get_peaks=Get_Peak_Cruxes, n_sideparags=No_Paragraphs_on_Each_Side)\n",
        "  print(temp_out)\n",
        "  # attempt to save temp_out to generated filename\n",
        "  sys.stdout = sys.__stdout__\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Y90bCSB7arF"
      },
      "source": [
        "**Zoom in on Context surrounding a particular Crux Point**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Enter [Crux_Sentence_No] that matches a Crux point/Sentence No you want to explore\n",
        "\n",
        "* Enter [No_Paragraphs_on_Each_Side] to retrieve this many Paragraphs before and after the Paragraph containing your Crux Sentence (e.g. 2 will bring back 5 paragraphs centered around the Paragraph containing the Crux Sentence)\n",
        "\n",
        "* Select [Highlight_Crux_Sentence] to have the Crux Sentence converted to ALL CAPS for easier identification. The Paragraph containing the Crux Sentence will be prefaced with a '<*>' as well.\n",
        "\n",
        "* Select [Save_to_File] to also save output to external *.txt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFi5kyx-7arG"
      },
      "source": [
        "# Select details about the Crux Point Context to Retrieve\n",
        "\n",
        "# print(f'Last Sentence No: {corpus_sents_df.shape[0]}')\n",
        "Crux_Sentence_No =  1047#@param {type:\"number\"}\n",
        "No_Paragraphs_on_Each_Side = 3 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "Highlight_Crux_Sentence = True #@param {type:\"boolean\"}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "corpus_sents_len = corpus_sents_df.shape[0]\n",
        "\n",
        "# if (Crux_Sentence_No >= No_Paragraphs_on_Each_Side) & (Crux_Sentence_No+No_Paragraphs_on_Each_Side <= corpus_parag_len):\n",
        "# get_sentnocontext_report()\n",
        "# try:\n",
        "get_sentnocontext_report(the_sent_no=Crux_Sentence_No, the_n_sideparags=No_Paragraphs_on_Each_Side, the_sent_highlight=Highlight_Crux_Sentence)\n",
        "# except:\n",
        "#   print('ERROR')\n",
        "# else:\n",
        "#   print(f'ERROR: The combination of your [Crux_Sentence_No] and [No_Pargraphs_on_Each_Side]\\n       results in a window outside the range of the Corpus Paragraphs.\\n\\n       Try again with different values.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Xv7Ah7zVpux"
      },
      "source": [
        "### **Stop Here (Paragraph Under Construction)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRjHsOIpXovL"
      },
      "source": [
        "##### **Paragraph Transformers SMA Plots**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBrSjSA4Qytu"
      },
      "source": [
        "# (Optional) Read Paragraph Sentiment Data generated by Transformers into DataFrame: corpus_parags_trans_df\n",
        "#            SKIP if no Transformer Paragraph Sentiment datafile to read in\n",
        "\n",
        "sum_sentiment_parags_transformers_filename = 'sum_sentiments_sents_transformers_ianmcewan_machineslikeme.csv'\n",
        "corpus_parags_trans_df = pd.read_csv(sum_sentiment_parags_transformers_filename)\n",
        "\n",
        "# Optional columns to drop\n",
        "corpus_parags_trans_df.drop(columns=['bertsst_pol', 'bertsst_prob'], axis=1, inplace=True)\n",
        "\n",
        "corpus_parags_trans_df.head(2)\n",
        "corpus_parags_trans_df.info()\n",
        "corpus_parags_trans_df.columns\n",
        "\n",
        "\"\"\"\n",
        "corpus_parags_trans_len = corpus_parags_trans_df.shape[0]\n",
        "\n",
        "if corpus_parags_trans_len != corpus_sents_df.shape[0]:\n",
        "  print('\\n\\n\\n======================================================================\\n')\n",
        "  print(f'ERROR: sentence sentiment values read into corpus_syuzhetr (len={corpus_transformers_len})')\n",
        "  print(f'       is not the same length as corpus_parags_trans_df (len={corpus_parags_trans_df.shape[0]}) ')\n",
        "  print(f'\\nRECOMMENDATION: Use the preprocessed corpus output created by this notebook ')\n",
        "  print(f'                as input to SyuzhetR in RStudio to generate sentiment series')\n",
        "  print(f'                and then retry importing')\n",
        "  print('\\n======================================================================\\n')\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h1hIcSobYfQ"
      },
      "source": [
        "# Standardize all values with MedianIQR\n",
        "\n",
        "model_transformers_ls = ['nlptown', 'robertalg15', 'distillbertsst', 'bertsst']\n",
        "\n",
        "for model_transformer in model_transformers_ls:\n",
        "\n",
        "  # Normalize the Sentence Sentiment by dividing by Chapter Length\n",
        "  parags_len_ls = list(corpus_parags_trans_df['token_len'])\n",
        "  parags_sentiment_ls = list(corpus_parags_trans_df[model_transformer])\n",
        "  parags_sentiment_norm_ls = [parags_sentiment_ls[i]/parags_len_ls[i] for i in range(len(parags_len_ls))]\n",
        "\n",
        "  # RobustStandardize Sentence sentiment values\n",
        "  # corpus_parags_trans_df[col_lnorm_meanstd]  = mean_std_scaler.fit_transform(np.array(pd.Series(parags_sentiment_norm_ls)).reshape(-1, 1))\n",
        "  col_medianiqr = f'{model_transformer}_medianiqr'\n",
        "  corpus_parags_trans_df[col_medianiqr]  = median_iqr_scaler.fit_transform(np.array(corpus_parags_trans_df[model_transformer]).reshape(-1, 1))\n",
        "  col_lnorm_medianiqr = f'{model_transformer}_lnorm_medianiqr'\n",
        "  corpus_parags_trans_df[col_lnorm_medianiqr]  = median_iqr_scaler.fit_transform(np.array(pd.Series(parags_sentiment_norm_ls)).reshape(-1, 1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2ee-U3HUbre"
      },
      "source": [
        "# Calculate Transformer Rolling Windows = win_per of Corpus (default 5%)\n",
        "\n",
        "\n",
        "\n",
        "win_per = 10           \n",
        "win_roll = int(win_per/100 * corpus_parags_trans_df.shape[0])\n",
        "\n",
        "# model_transformers_ls = ['nlptown', 'robertalg15', 'distillbertsst', 'bertsst']\n",
        "model_transformers_ls = ['nlptown_lnorm_medianiqr', 'robertalg15_lnorm_medianiqr', 'distillbertsst_lnorm_medianiqr', 'bertsst_lnorm_medianiqr']\n",
        "\n",
        "col_name_roll_ls = []\n",
        "# fig, ax = plt.subplots()\n",
        "for amodel in model_transformers_ls:\n",
        "  # if not(amodel.endswith('roll050')):\n",
        "  col_name_roll = f'{amodel}_roll050'\n",
        "  col_name_roll_ls.append(col_name_roll)\n",
        "  # else:\n",
        "  #   col_name_roll_ls.append(amodel)\n",
        "  corpus_parags_trans_df[col_name_roll] = corpus_parags_trans_df[amodel].rolling(win_roll, center=True).mean()\n",
        "\n",
        "corpus_parags_trans_df['mean_all_roll050'] = corpus_parags_trans_df[col_name_roll_ls].mean(axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Kh--NklUbmp"
      },
      "source": [
        "NLPTown_Arc = True #@param {type:\"boolean\"}\n",
        "RoBERTaLg15_Arc = True #@param {type:\"boolean\"}\n",
        "DistillBERTSST_Arc = True #@param {type:\"boolean\"}\n",
        "BERTSST_Arc = True #@param {type:\"boolean\"}\n",
        "Mean_Subset_Arc = True #@param {type:\"boolean\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr4Wqoh36V29"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "col_name_roll_ls = []\n",
        "# fig, ax = plt.subplots()\n",
        "for amodel in model_transformers_ls:\n",
        "  # if not(amodel.endswith('roll050')):\n",
        "  if len(str(win_per)) == 1:\n",
        "    roll_str = 'roll0' + str(win_per) + '0'\n",
        "  else:\n",
        "    roll_str = 'roll' + str(win_per) + '0'\n",
        "  col_name_roll = f'{amodel}_lnorm_medianiqr_{roll_str}'\n",
        "  col_name_roll_ls.append(col_name_roll)\n",
        "  # else:\n",
        "  #   col_name_roll_ls.append(amodel)\n",
        "  corpus_sents_trans_df[col_name_roll] = corpus_sents_trans_df[amodel].rolling(win_roll, center=True).mean()\n",
        "\n",
        "col_mean_roll = 'mean_' + roll_str\n",
        "model_transformers_lnorm_medianiqr_ls = []\n",
        "corpus_sents_trans_df[col_mean_roll] = corpus_sents_trans_df[model_transformers_lnorm_medianiqr_ls].mean(axis=1)\n",
        "\n",
        "col_mean_lnorm_median_roll = 'mean_lnorm_medianiqr_' + roll_str\n",
        "model_transformers_lnorm_medianiqr_ls = []\n",
        "for acol_name in model_transformers_ls:\n",
        "  model_transformers_lnorm_medianiqr_ls.append(acol_name+'_lnorm_medianiqr_'+roll_str)\n",
        "corpus_sents_trans_df[col_mean_lnorm_median_roll] = corpus_sents_trans_df[model_transformers_lnorm_medianiqr_ls].mean(axis=1)\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IVvASZFUbdJ"
      },
      "source": [
        "# Plotly Interactive/Zoom Sentiment Plots\n",
        "\n",
        "SMA_Window_Percent = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "win_per = SMA_Window_Percent\n",
        "win_roll = int(win_per/100 * corpus_parags_trans_df.shape[0])\n",
        "\n",
        "if len(str(win_per)) == 1:\n",
        "  roll_str = 'roll0' + str(win_per)\n",
        "else:\n",
        "  roll_str = 'roll' + str(win_per)\n",
        "\n",
        "# display(corpus_sents_df.head())\n",
        "\n",
        "model_transformers_ls = ['nlptown', 'robertalg15', 'distillbertsst', 'bertsst']\n",
        "\n",
        "# list of (scale, center) adjustments for each model so they can be compared on same graph\n",
        "model_transformers_scale_ls = [(0.3, -0.6), (1,0.1), (1,0.1), (1,0.1)]\n",
        "\n",
        "col_name_roll_ls = []\n",
        "# fig, ax = plt.subplots()\n",
        "for amodel in model_transformers_ls:\n",
        "  # if not(amodel.endswith('roll050')):\n",
        "  col_name_roll = f'{amodel}_lnorm_medianiqr_{roll_str}'\n",
        "  col_name_roll_ls.append(col_name_roll)\n",
        "  # else:\n",
        "  #   col_name_roll_ls.append(amodel)\n",
        "  print(f'creating: {col_name_roll}')\n",
        "  corpus_parags_trans_df[col_name_roll] = corpus_parags_trans_df[amodel].rolling(win_roll, center=True).mean()\n",
        "\n",
        "col_mean_roll = 'mean_lnorm_medianiqr_' + roll_str\n",
        "# model_transformers_lnorm_medianiqr_ls = []\n",
        "corpus_parags_trans_df[col_mean_roll] = corpus_parags_trans_df[col_name_roll_ls].mean(axis=1)\n",
        "\n",
        "\"\"\"\n",
        "col_mean_lnorm_median_roll = 'mean_lnorm_medianiqr_' + roll_str\n",
        "# model_transformers_lnorm_medianiqr_ls = []\n",
        "for acol_name in model_transformers_ls:\n",
        "  model_transformers_lnorm_medianiqr_ls.append(acol_name)\n",
        "corpus_parags_trans_df[col_mean_lnorm_median_roll] = corpus_parags_trans_df[model_transformers_lnorm_medianiqr_ls].mean(axis=1)\n",
        "\"\"\";\n",
        "\n",
        "\n",
        "model_transformers_subset_ls = []\n",
        "if NLPTown_Arc == True:\n",
        "  # model_transformers_subset_ls.append('nlptown_lnorm_medianiqr_roll050')\n",
        "  model_transformers_subset_ls.append('nlptown_lnorm_medianiqr' + '_' + roll_str)\n",
        "if RoBERTaLg15_Arc == True:\n",
        "  model_transformers_subset_ls.append('robertalg15_lnorm_medianiqr' +'_' + roll_str)\n",
        "if DistillBERTSST_Arc == True:\n",
        "  model_transformers_subset_ls.append('distillbertsst_lnorm_medianiqr' + '_' + roll_str)\n",
        "if BERTSST_Arc == True:\n",
        "  model_transformers_subset_ls.append('bertsst_lnorm_medianiqr' + '_' + roll_str)\n",
        "\n",
        "\n",
        "palette = cycle(px.colors.qualitative.Safe)\n",
        "# palette = cycle(px.colors.sequential.PuBu)\n",
        "\n",
        "my_layout = go.Layout(\n",
        "    autosize=False,\n",
        "    width=1600,\n",
        "    height=800,\n",
        "    margin=go.layout.Margin(\n",
        "        l=10,\n",
        "        r=50,\n",
        "        b=100,\n",
        "        t=100,\n",
        "        pad = 1\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "fig = go.Figure(layout=my_layout)\n",
        "\n",
        "# add traces\n",
        "for i,amodel in enumerate(model_transformers_subset_ls):\n",
        "  fig.add_traces(go.Line(x = corpus_parags_trans_df['sent_no'],\n",
        "                        y = model_transformers_scale_ls[i][0]*corpus_parags_trans_df[amodel]+model_transformers_scale_ls[i][1],\n",
        "                        text = corpus_parags_trans_df['sent_raw'],\n",
        "                        name = amodel,\n",
        "                        hovertemplate = \"Model: <b>\"+amodel+\"</b><br>Sentence #<b>%{x}</b><br>Polarity <b>%{y:.4f}</b><br>Text: <b><i>%{text}</i></b>\", \n",
        "                        marker_color=next(palette)))\n",
        "\n",
        "if Mean_Subset_Arc == True:\n",
        "  mean_subset_col = 'mean_subset_roll050'\n",
        "  corpus_parags_trans_df[mean_subset_col] = corpus_parags_trans_df[model_transformers_subset_ls].mean(axis=1)\n",
        "  fig.add_traces(go.Line(x=corpus_parags_trans_df['sent_no'],\n",
        "                        y = corpus_parags_trans_df[mean_subset_col],\n",
        "                        line=dict(\n",
        "                              # color='#000000',\n",
        "                              width=5\n",
        "                              ),\n",
        "                        text = 'NA', # corpus_parags_trans_df['sent_raw'],\n",
        "                        name = mean_subset_col,\n",
        "                        hovertemplate = \"Model <b>%{mean_subset_col}</b><br>Sentence #<b>%{x}</b><br>Polarity <b>%{y:.4f}</b>\", \n",
        "                        marker_color=next(palette)))\n",
        "\n",
        "\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Paragraph Transformer Sentiment Models<b><i> \" + roll_str.upper() + \"</i></b>\",\n",
        "    xaxis_title=\"Paragraph Number\",\n",
        "    # yaxis_title=\"Sentiment Value\",\n",
        "    hoverlabel=dict(\n",
        "        bgcolor=\"white\",\n",
        "        font_size=16,\n",
        "        font_family=\"Rockwell\"\n",
        "    ),\n",
        "    font=dict(\n",
        "        family=\"Courier New, monospace\",\n",
        "        size=18,\n",
        "        color=\"RebeccaPurple\"\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89X8Sz2QdMn-"
      },
      "source": [
        "##### **(ABOVE) Plotly SMA Paragraph Transformers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmbxdtyvQo3K"
      },
      "source": [
        "##### **Comparison of Paragraph Transformer Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIaxX1dEbvkE"
      },
      "source": [
        "# Compare Paragraph Transformer Standardized Sentiment Values\n",
        "\n",
        "model_trans_ls = ['nlptown', 'robertalg15', 'distillbertsst', 'bertsst']\n",
        "\n",
        "model_trans_standardized_roll_ls = []\n",
        "for amodel in model_trans_ls:\n",
        "  col_name = f'{amodel}_lnorm_medianiqr_{roll_str}'  # TODO: drop lnorm_medianiqr earlier and just Standardize here\n",
        "                                                     # NOTE: Simple SciPy StandardScaler works on SMA Series that don't have outliers like Raw Series\n",
        "  # print(f'col_name: {col_name}')\n",
        "  model_trans_standardized_roll_ls.append(col_name)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "for i,amodel in enumerate(model_trans_standardized_roll_ls):\n",
        "  col_name_roll_stand = f'{col_name}_stand'\n",
        "  # print(f'col_name_roll_stand: {col_name_roll_stand}')  # sent\n",
        "  model_roll_stand_np = np.array(corpus_parags_trans_df[amodel])\n",
        "  # .apply(lambda x: Scale_SentimentR*x))\n",
        "  \n",
        "  model_roll_stand_np = model_roll_stand_np.reshape((len(model_roll_stand_np), 1))\n",
        "\n",
        "  scaler = scaler.fit(model_roll_stand_np)\n",
        "  print('Mean: %f, StandardDeviation: %f' % (scaler.mean_, np.sqrt(scaler.var_)))\n",
        "  model_roll_stand_xform_np = scaler.transform(model_roll_stand_np)\n",
        "\n",
        "  corpus_parags_trans_df[col_name_roll_stand] = pd.Series(model_roll_stand_xform_np.flatten())\n",
        "\n",
        "  # Plot\n",
        "  corpus_parags_trans_df[col_name_roll_stand].plot(label=amodel) # label=col_name_roll_stand))\n",
        "\n",
        "plt.grid()\n",
        "plt.title(f'{CORPUS_FULL} Compare Paragraph Transformer Sentiments\\nMean Length-Normed MedianIQR Sentiments SMA ({roll_str.capitalize()})')\n",
        "plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtxzLN7CQo3R"
      },
      "source": [
        "# Create a comparison DataFrame of SentimentR Paragraph Models\n",
        "\n",
        "corr_transformers_models_ls = ['nlptown','robertalg15', 'distillbertsst','bertsst']\n",
        "\n",
        "corr_transformers_df = corpus_parags_trans_df[corr_transformers_models_ls].corr(method='spearman')\n",
        "\n",
        "# Customize the heatmap of the corr_meat correlation matrix and rotate the x-axis labels\n",
        "fig = sns.clustermap(corr_df,\n",
        "                     row_cluster=True,\n",
        "                     col_cluster=True,\n",
        "                     figsize=(10, 10))\n",
        "\n",
        "plt.setp(fig.ax_heatmap.xaxis.get_majorticklabels(), rotation=90)\n",
        "plt.setp(fig.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dowF8jrw67W7"
      },
      "source": [
        "# Quick Sentence vs Paragraph Transformer Sentiment SMA Comparison\n",
        "\n",
        "plt.close()\n",
        "\n",
        "# Colab Jupyter wouldn't plot pd.Series from 2 different DataFrames on the same graph\n",
        "#   so combine into temporary DataFrame as a workaround\n",
        "\n",
        "temp_df = pd.DataFrame(columns = ['Sentences', 'Paragraphs'])\n",
        "\n",
        "y_col = f'mean_lnorm_medianiqr_{roll_str}'\n",
        "temp_df['Sentences'] = corpus_sents_trans_df[y_col]\n",
        "temp_df['Paragraphs'] = corpus_parags_trans_df[y_col]\n",
        "\n",
        "temp_df['Sentences'].plot(linewidth=10)\n",
        "temp_df['Paragraphs'].plot()\n",
        "\n",
        "\n",
        "# plt.plot(corpus_sents_trans_df[y_col], label='Sentences')\n",
        "\n",
        "# y_col = f'mean_lnorm_medianiqr_{roll_str}'\n",
        "# plt.plot(corpus_parags_trans_df[y_col], label='Paragraphs')\n",
        "\n",
        "# plt.grid()\n",
        "plt.title(f'{CORPUS_FULL} Paragraph Transformer Sentiments\\nMean Length-Normed MedianIQR Sentiments SMA ({roll_str.capitalize()})')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJIK_j3wbx97"
      },
      "source": [
        "corpus_sents_trans_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZorifAHe7ye"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5CazR5rY_u2"
      },
      "source": [
        "##### **Explore Paragraph Crux Points and Contexts**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHihplfSY_u4"
      },
      "source": [
        "**Plot Top-n Crux Peaks/Valleys for selected Model**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Select [Crux_Window_Percent] exclusive zone around Crux Points as a percentage of Corpus length\n",
        "\n",
        "* [Sentiment_Model] Select a Sentiment Analysis model\n",
        "\n",
        "* Select [Anomaly_Detction] to plot raw Sentiment values to detect outlier/anomaly Sentences. Leave unchecked to plot SMA smoothed Sentiment arc and detect Crux points\n",
        "\n",
        "* Select [Save_to_File] to also save plot to external *.png file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvndYD2CY_u6"
      },
      "source": [
        "Crux_Window_Percent = 2 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "SentimentR_SMA_Model = \"RoBERTa Large 15 Databases\" #@param [\"NLPTown\", \"RoBERTa Large 15 Databases\", \"Distilled BERT SST\", \"BERT SST\"]\n",
        "Anomaly_Detection = False #@param {type:\"boolean\"}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "if SentimentR_SMA_Model == 'NLPTown':\n",
        "  model_selected = f'nlptown'\n",
        "if SentimentR_SMA_Model == 'RoBERTa Large 15 Databases':\n",
        "  model_selected = f'robertalg15'\n",
        "if SentimentR_SMA_Model == 'Distilled BERT SST':\n",
        "  model_selected = f'distillbertsst'\n",
        "if SentimentR_SMA_Model == 'BERT SST':\n",
        "  model_selected = f'bertsst'\n",
        "\n",
        "if Anomaly_Detection == False:\n",
        "  # (a) Use Sentence SMA smoothed Sentiment models to detect Crux Points\n",
        "  model_selected_fullname = f'{model_selected}_lnorm_medianiqr_{roll_str}'\n",
        "else:\n",
        "  # (b)Use Sentence Raw Sentiment models to detect outliers\n",
        "  model_selected_fullname = f'{model_selected}'\n",
        "\n",
        "\n",
        "# TODO: enable multiple overlay crux points with underlying mean/median arc\n",
        "corpus_models_stand_ls = [model_selected_fullname]\n",
        "\n",
        "# Warning: requires definitions of: x, section_sents_df\n",
        "#          so Baseline models must be run first\n",
        "\n",
        "for amodel in corpus_models_stand_ls:\n",
        "  corpus_cruxes_all_dt[amodel] = get_crux_points(ts_df=corpus_sents_trans_df, \n",
        "                                         col_series=corpus_models_stand_ls, \n",
        "                                         text_type='sentence', \n",
        "                                         win_per=Crux_Window_Percent, \n",
        "                                         sec_y_height=0, \n",
        "                                         subtitle_str=' ', \n",
        "                                         do_plot=True, \n",
        "                                         save2file=False)\n",
        "  \n",
        "model_crux_ls = corpus_cruxes_all_dt[amodel]\n",
        "# model_crux_ls;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KR0h5f7bY_u8"
      },
      "source": [
        "**Get Top-n Crux Peaks/Valleys with surrounding Context**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Select [Get_Peak_Cruxes] to retrieve Peaks (if unchecked Valleys are retrieved)\n",
        "\n",
        "* [Get_n_Cruxes] determines how many Top-n Cruxes to retrieve\n",
        "\n",
        "* Enter [No_Paragraphs_on_Each_Side] to retrieve this many Paragraphs before and after the Paragraph containing your Crux Sentence (e.g. 2 will bring back 5 paragraphs centered around the Paragraph containing the Crux Sentence)\n",
        "\n",
        "* Select [Highlight_Crux_Sentence] to have the Crux Sentence converted to ALL CAPS for easier identification. The Paragraph containing the Crux Sentence will be prefaced with a '<*>' as well.\n",
        "\n",
        "* Select [Save_to_File] to also save output to external *.txt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beSU4keNY_u-"
      },
      "source": [
        "# Crux Details\n",
        "Get_Peak_Cruxes = True #@param {type:\"boolean\"}\n",
        "Get_n_Cruxes = 6 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "Sort_by_SentenceNo = True #@param {type:\"boolean\"}\n",
        "\n",
        "# Context Details\n",
        "No_Paragraphs_on_Each_Side = 3 #@param {type:\"slider\", min:0, max:5, step:1}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "if Save_to_Report == False:\n",
        "  crux_sortsents_report(model_crux_ls, \n",
        "                        library_type='transformers',\n",
        "                        top_n=Get_n_Cruxes, \n",
        "                        get_peaks=Get_Peak_Cruxes, \n",
        "                        sort_by = sort_on, # sent_no, or abs(polarity)\n",
        "                        n_sideparags=No_Paragraphs_on_Each_Side,\n",
        "                        sentence_highlight=Highlight_Sentence)\n",
        "else:\n",
        "  # https://www.kite.com/python/answers/how-to-get-stdout-and-stderr-from-a-process-as-a-string-in-python\n",
        "  # process = subprocess.run([\"echo\", \"This goes to stdout\"], capture_output=True)\n",
        "  # stdout_as_str = process.stdout.decode(\"utf-8\")\n",
        "  # print(stdout_as_str)\n",
        "  temp_out = StringIO()\n",
        "  sys.stdout = temp_out\n",
        "  crux_sortsents_report(model_crux_ls, top_n=Get_n_Cruxes, get_peaks=Get_Peak_Cruxes, n_sideparags=No_Paragraphs_on_Each_Side)\n",
        "  print(temp_out)\n",
        "  # attempt to save temp_out to generated filename\n",
        "  sys.stdout = sys.__stdout__\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zG8t02zqY_vA"
      },
      "source": [
        "**Zoom in on Context surrounding a particular Crux Point**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Enter [Crux_Sentence_No] that matches a Crux point/Sentence No you want to explore\n",
        "\n",
        "* Enter [No_Paragraphs_on_Each_Side] to retrieve this many Paragraphs before and after the Paragraph containing your Crux Sentence (e.g. 2 will bring back 5 paragraphs centered around the Paragraph containing the Crux Sentence)\n",
        "\n",
        "* Select [Highlight_Crux_Sentence] to have the Crux Sentence converted to ALL CAPS for easier identification. The Paragraph containing the Crux Sentence will be prefaced with a '<*>' as well.\n",
        "\n",
        "* Select [Save_to_File] to also save output to external *.txt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2Sm942CY_vB"
      },
      "source": [
        "# Select details about the Crux Point Context to Retrieve\n",
        "\n",
        "# print(f'Last Sentence No: {corpus_sents_df.shape[0]}')\n",
        "Crux_Sentence_No =  4494#@param {type:\"number\"}\n",
        "No_Paragraphs_on_Each_Side = 3 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "Highlight_Crux_Sentence = True #@param {type:\"boolean\"}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "corpus_sents_len = corpus_sents_df.shape[0]\n",
        "\n",
        "# if (Crux_Sentence_No >= No_Paragraphs_on_Each_Side) & (Crux_Sentence_No+No_Paragraphs_on_Each_Side <= corpus_parag_len):\n",
        "# get_sentnocontext_report()\n",
        "# try:\n",
        "get_sentnocontext_report(the_sent_no=Crux_Sentence_No, the_n_sideparags=No_Paragraphs_on_Each_Side, the_sent_highlight=Highlight_Crux_Sentence)\n",
        "# except:\n",
        "#   print('ERROR')\n",
        "# else:\n",
        "#   print(f'ERROR: The combination of your [Crux_Sentence_No] and [No_Pargraphs_on_Each_Side]\\n       results in a window outside the range of the Corpus Paragraphs.\\n\\n       Try again with different values.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISIf0aUPxe6y"
      },
      "source": [
        "# **Compare All Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAx6TUxysYoG"
      },
      "source": [
        "## **Review, Processes and Combine into Unified DataFrame**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWDd_5inFgMq"
      },
      "source": [
        "corpus_sents_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiG9p1S20Bu_"
      },
      "source": [
        "corpus_sentimentr_df.columns\n",
        "\n",
        "# jockers_rinker_roll100_stdscale"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFAQOy4fr-vs"
      },
      "source": [
        "corpus_syuzhetr_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYoIb-jVr-3k"
      },
      "source": [
        "corpus_transformer_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zURjifUsh3t"
      },
      "source": [
        "**Process**\n",
        "\n",
        "NOTE: Assume only base_model Raw Sentiment Series exist in each of the 4 Library DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCHRu2RwsW5l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml635x83yFUp"
      },
      "source": [
        "**Baseline Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk86ubNB_Hzn"
      },
      "source": [
        "# StandardScaler SMA for Baseline Models\n",
        "\n",
        "SMA_Window_Percentage = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "# Convert the SMA Window from Percentage of Corpus to No of Sentences\n",
        "win_per = SMA_Window_Percentage\n",
        "win_sents = int(corpus_sents_df.shape[0]*win_per/100)\n",
        "\n",
        "# Loop over every Group and within each Group, loop over each Model\n",
        "for amodel in models_baseline_ls:\n",
        "\n",
        "  # Print the current Group/Model that is being used\n",
        "  # print(f'Processing Model: {amodel:>15} in Group: Baselines')\n",
        "\n",
        "  # Generate new SMA col name\n",
        "  if len(str(win_per)) < 2:\n",
        "    col_sma_winper = f'{amodel}_roll0{str(win_per)}0'\n",
        "  else:\n",
        "    col_sma_winper = f'{amodel}_roll{str(win_per)}0'\n",
        "\n",
        "  # Create new SMA Column\n",
        "  # print(f'creating roll col: {col_sma_winper}')\n",
        "  corpus_sents_df[col_sma_winper] = corpus_sents_df[amodel].rolling(win_sents, center=True).mean()\n",
        "\n",
        "  # Standardize SMA Column\n",
        "  col_sma_winper_stdscale = f'{col_sma_winper}_stdscale'\n",
        "  # print(f'creating stdscale col of roll: {col_sma_winper_stdscale}')\n",
        "  series_stdscale_ls = get_standardscaler(amodel, corpus_sents_df[col_sma_winper])\n",
        "  corpus_sents_df[col_sma_winper_stdscale] = pd.Series(series_stdscale_ls)\n",
        "\n",
        "  # Plot\n",
        "  # corpus_sents_df.iloc[200:1000][col_sma_winper_stdscale].plot()\n",
        "  corpus_sents_df[col_sma_winper_stdscale].plot()\n",
        "\n",
        "plt.grid()\n",
        "plt.title(f'{CORPUS_FULL} Compare Sentence Baseline Sentiments\\nStandardScaler of SMA Smoothed Arcs ({roll_str.capitalize()})')\n",
        "plt.legend(loc='best');\n",
        "\n",
        "\"\"\"\n",
        "for agroup in groups_ls:\n",
        "  for amodel in globals()[agroup]:\n",
        "    print(f'Processing Model: {amodel:>15} in Group: {agroup}')\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKyNxuUmyH4z"
      },
      "source": [
        "**SentimentR Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR_fg-dNLNKw"
      },
      "source": [
        "corpus_sentimentr_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPqb0SeVALi5"
      },
      "source": [
        "# StandardScaler SMA for SentimentR Models\n",
        "\n",
        "SMA_Window_Percentage = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "# Convert the SMA Window from Percentage of Corpus to No of Sentences\n",
        "win_per = SMA_Window_Percentage\n",
        "win_sents = int(corpus_sentimentr_df.shape[0]*win_per/100)\n",
        "\n",
        "# Loop over every Group and within each Group, loop over each Model\n",
        "for amodel in models_sentimentr_ls:\n",
        "\n",
        "  # Print the current Group/Model that is being used\n",
        "  # print(f'Processing Model: {amodel:>15} in Group: Baselines')\n",
        "\n",
        "  # Generate new SMA col name\n",
        "  if len(str(win_per)) < 2:\n",
        "    col_sma_winper = f'{amodel}_roll0{str(win_per)}0'\n",
        "  else:\n",
        "    col_sma_winper = f'{amodel}_roll{str(win_per)}0'\n",
        "\n",
        "  # Create new SMA Column\n",
        "  # print(f'creating roll col: {col_sma_winper}')\n",
        "  corpus_sentimentr_df[col_sma_winper] = corpus_sentimentr_df[amodel].rolling(win_sents, center=True).mean()\n",
        "\n",
        "  # Standardize SMA Column\n",
        "  col_sma_winper_stdscale = f'{amodel}_stdscaler_{roll_str}' \n",
        "  # print(f'creating stdscale col of roll: {col_sma_winper_stdscale}')\n",
        "  series_stdscale_ls = get_standardscaler(amodel, corpus_sentimentr_df[col_sma_winper])\n",
        "  corpus_sentimentr_df[col_sma_winper_stdscale] = pd.Series(series_stdscale_ls)\n",
        "\n",
        "  # Plot\n",
        "  # corpus_sentimentr_df.iloc[200:1000][col_sma_winper_stdscale].plot()\n",
        "  corpus_sentimentr_df[col_sma_winper_stdscale].plot()\n",
        "\n",
        "plt.grid()\n",
        "plt.title(f'{CORPUS_FULL} Compare Sentence Baseline Sentiments\\nStandardScaler of SMA Smoothed Arcs ({roll_str.capitalize()})')\n",
        "plt.legend(loc='best');\n",
        "\n",
        "\"\"\"\n",
        "for agroup in groups_ls:\n",
        "  for amodel in globals()[agroup]:\n",
        "    print(f'Processing Model: {amodel:>15} in Group: {agroup}')\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iGbNzPGyK8-"
      },
      "source": [
        "**SyuzhetR Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnUuECApALc9"
      },
      "source": [
        "# StandardScaler SMA for SyuzhetR Models\n",
        "\n",
        "SMA_Window_Percentage = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "# Convert the SMA Window from Percentage of Corpus to No of Sentences\n",
        "win_per = SMA_Window_Percentage\n",
        "win_sents = int(corpus_syuzhetr_df.shape[0]*win_per/100)\n",
        "\n",
        "# Loop over every Group and within each Group, loop over each Model\n",
        "for amodel in models_syuzhetr_ls:\n",
        "\n",
        "  # Print the current Group/Model that is being used\n",
        "  # print(f'Processing Model: {amodel:>15} in Group: Baselines')\n",
        "\n",
        "  # Generate new SMA col name\n",
        "  if len(str(win_per)) < 2:\n",
        "    col_sma_winper = f'{amodel}_roll0{str(win_per)}0'\n",
        "  else:\n",
        "    col_sma_winper = f'{amodel}_roll{str(win_per)}0'\n",
        "\n",
        "  # Create new SMA Column\n",
        "  # print(f'creating roll col: {col_sma_winper}')\n",
        "  corpus_syuzhetr_df[col_sma_winper] = corpus_syuzhetr_df[amodel].rolling(win_sents, center=True).mean()\n",
        "\n",
        "  # Standardize SMA Column\n",
        "  col_sma_winper_stdscale = f'{amodel}_stdscaler_{roll_str}'\n",
        "  # print(f'creating stdscale col of roll: {col_sma_winper_stdscale}')\n",
        "  series_stdscale_ls = get_standardscaler(amodel, corpus_syuzhetr_df[col_sma_winper])\n",
        "  corpus_syuzhetr_df[col_sma_winper_stdscale] = pd.Series(series_stdscale_ls)\n",
        "\n",
        "  # Plot\n",
        "  # corpus_syuzhetr_df.iloc[200:1000][col_sma_winper_stdscale].plot()\n",
        "  corpus_syuzhetr_df[col_sma_winper_stdscale].plot()\n",
        "\n",
        "plt.grid()\n",
        "plt.title(f'{CORPUS_FULL} Compare Sentence Baseline Sentiments\\nStandardScaler of SMA Smoothed Arcs ({roll_str.capitalize()})')\n",
        "plt.legend(loc='best');\n",
        "\n",
        "\"\"\"\n",
        "for agroup in groups_ls:\n",
        "  for amodel in globals()[agroup]:\n",
        "    print(f'Processing Model: {amodel:>15} in Group: {agroup}')\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3iWkOCuyNB3"
      },
      "source": [
        "**Transformer Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SN6gRLJALZP"
      },
      "source": [
        "# StandardScaler SMA for Transformer Models\n",
        "\n",
        "SMA_Window_Percentage = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "models_transformer_ls = ['roberta15lg',\n",
        "                         'nlptown',\n",
        "                         'yelp',\n",
        "                         'hinglish',\n",
        "                         'imdb2way',\n",
        "                         'huggingface',\n",
        "                         't5imdb50k',\n",
        "                         'robertaxml8lang']\n",
        "\n",
        "# Convert the SMA Window from Percentage of Corpus to No of Sentences\n",
        "win_per = SMA_Window_Percentage\n",
        "win_sents = int(corpus_transformer_df.shape[0]*win_per/100)\n",
        "\n",
        "# Loop over every Group and within each Group, loop over each Model\n",
        "for amodel in models_transformer_ls:\n",
        "\n",
        "  # Print the current Group/Model that is being used\n",
        "  # print(f'Processing Model: {amodel:>15} in Group: Baselines')\n",
        "\n",
        "  # Generate new SMA col name\n",
        "  if len(str(win_per)) < 2:\n",
        "    col_sma_winper = f'{amodel}_roll0{str(win_per)}0'\n",
        "  else:\n",
        "    col_sma_winper = f'{amodel}_roll{str(win_per)}0'\n",
        "\n",
        "  # Create new SMA Column\n",
        "  # print(f'creating roll col: {col_sma_winper}')\n",
        "  corpus_transformer_df[col_sma_winper] = corpus_transformer_df[amodel].rolling(win_sents, center=True).mean()\n",
        "\n",
        "  # Standardize SMA Column\n",
        "  col_sma_winper_stdscale = f'{amodel}_stdscaler_{roll_str}'\n",
        "  # print(f'creating stdscale col of roll: {col_sma_winper_stdscale}')\n",
        "  series_stdscale_ls = get_standardscaler(amodel, corpus_transformer_df[col_sma_winper])\n",
        "  corpus_transformer_df[col_sma_winper_stdscale] = pd.Series(series_stdscale_ls)\n",
        "\n",
        "  # Plot\n",
        "  # corpus_transformer_df.iloc[200:1000][col_sma_winper_stdscale].plot()\n",
        "  corpus_transformer_df[col_sma_winper_stdscale].plot()\n",
        "\n",
        "plt.grid()\n",
        "plt.title(f'{CORPUS_FULL} Compare Sentence Transformer Sentiments\\nStandardScaler of SMA Smoothed Arcs ({roll_str.capitalize()})')\n",
        "plt.legend(loc='best');\n",
        "\n",
        "\"\"\"\n",
        "for agroup in groups_ls:\n",
        "  for amodel in globals()[agroup]:\n",
        "    print(f'Processing Model: {amodel:>15} in Group: {agroup}')\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a1CN4OKL-R9"
      },
      "source": [
        "corpus_syuzhetr_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06NwK2PrmIV9"
      },
      "source": [
        "# Vertically Concatenate ALL 4 Sentiment Groups StandardizedScaled SMA Sentence Sentiment Series into 1 Big DataFrame\n",
        "\n",
        "corpus_sents_all_df = pd.DataFrame()\n",
        "\n",
        "# Get Baseline Model StandardScaled SMA column names\n",
        "cols_baseline_stdscaler_ls = []\n",
        "for amodel in models_baseline_ls:\n",
        "  col_roll_stdscale = f'{amodel}_stdscaler_{roll_str}'\n",
        "  cols_baseline_stdscaler_ls.append(col_roll_stdscale)\n",
        "# print(f'\\nBaseline StdScaled SMA Columns:\\n    {cols_baseline_stdscaler_ls}')\n",
        "\n",
        "temp_baseline_df = corpus_sents_df[cols_baseline_stdscaler_ls].copy()\n",
        "temp_baseline_df = temp_baseline_df.add_prefix('baseline_')\n",
        "temp_baseline_df.columns\n",
        "\n",
        "# Get SentimentR Model StandardScaled SMA column names\n",
        "cols_sentimentr_stdscaler_ls = []\n",
        "for amodel in models_sentimentr_ls:\n",
        "  col_roll_stdscale = f'{amodel}_stdscaler_{roll_str}'\n",
        "  cols_sentimentr_stdscaler_ls.append(col_roll_stdscale)\n",
        "# print(f'\\nSentimentR StdScaled SMA Columns:\\n    {cols_sentimentr_stdscaler_ls}')\n",
        "\n",
        "temp_sentimentr_df = corpus_sentimentr_df[cols_sentimentr_stdscaler_ls].copy()\n",
        "temp_sentimentr_df = temp_sentimentr_df.add_prefix('sentimentr_')\n",
        "temp_sentimentr_df.columns\n",
        "\n",
        "# Get SyuzhetR Model StandardScaled SMA column names\n",
        "cols_syuzhetr_stdscaler_ls = []\n",
        "for amodel in models_syuzhetr_ls:\n",
        "  col_roll_stdscaler = f'{amodel}_stdscaler_{roll_str}'\n",
        "  cols_syuzhetr_stdscaler_ls.append(col_roll_stdscaler)\n",
        "# print(f'\\nSyuzhetR StdScaled SMA Columns:\\n    {cols_syuzhetr_stdscaler_ls}')\n",
        "\n",
        "temp_syuzhetr_df = corpus_syuzhetr_df[cols_syuzhetr_stdscaler_ls].copy()\n",
        "temp_syuzhetr_df = temp_syuzhetr_df.add_prefix('syuzhetr_')\n",
        "temp_syuzhetr_df.columns\n",
        "\n",
        "# Get Transformer Model StandardScaled SMA column names\n",
        "cols_transformer_stdscaler_ls = []\n",
        "for amodel in models_transformer_ls:\n",
        "  col_roll_stdscale = f'{amodel}_stdscaler_{roll_str}'\n",
        "  cols_transformer_stdscaler_ls.append(col_roll_stdscale)\n",
        "# print(f'\\nTransformer StdScaled SMA Columns:\\n    {cols_transformer_stdscalerls}')\n",
        "\n",
        "# If Transformers Sentiment DataFrame exists, add it to the Unified DataFrame\n",
        "var_name = 'corpus_transformer_df'\n",
        "if var_name in globals():\n",
        "  # print(f'{var_name} is declared globally')\n",
        "  # print(eval(f'{var_name}.shape[0]'))\n",
        "  corpus_transformer_df_len = eval(f'{var_name}.shape[0]')\n",
        "  print(f'{var_name} has {corpus_transformer_df_len} Sentences')\n",
        "\n",
        "  temp_transformer_df = corpus_transformer_df[cols_transformer_stdscaler_ls].copy()\n",
        "  temp_transformer_df = temp_transformer_df.add_prefix('transformer_')\n",
        "  temp_transformer_df.columns\n",
        "\n",
        "  print(f'\\n\\n{var_name} IS declared\\n    so adding to Unified DataFrame')\n",
        "  corpus_sents_all_df = pd.concat([temp_baseline_df,\n",
        "                                  temp_sentimentr_df,\n",
        "                                  temp_syuzhetr_df,\n",
        "                                  temp_transformer_df],\n",
        "                                  axis=1)\n",
        "\n",
        "  temp_transformer_df = pd.DataFrame()\n",
        "\n",
        "else:\n",
        "  print(f'\\n\\n{var_name} IS NOT declared\\n    so NOT adding to Unified DataFrame')\n",
        "\n",
        "  corpus_sents_all_df = pd.concat([temp_baseline_df,\n",
        "                                  temp_sentimentr_df,\n",
        "                                  temp_syuzhetr_df],\n",
        "                                  axis=1)\n",
        "\n",
        "temp_baseline_df = pd.DataFrame()\n",
        "temp_sentimentr_df = pd.DataFrame()\n",
        "temp_syuzhetr_df = pd.DataFrame()\n",
        "\n",
        "print(f'\\ncorpus_sents_all_df.shape: {corpus_sents_all_df.shape}')\n",
        "# corpus_sents_all_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r34lNnz0oeQN"
      },
      "source": [
        "# Create a Correlation Heatmap for All Sentence Models\n",
        "\n",
        "# Sentence Heatmap Correlation of StdScaler Roll100 Sentiments\n",
        "# Depends on 'col_stdscaler_rollwin_ls' defined in prior code cell\n",
        "\n",
        "Correlation_Algo = \"pearson\" #@param [\"pearson\", \"spearman\", \"kendall\"]\n",
        "# corr_methods_ls = ['pearson', 'spearman', 'kendall']\n",
        "\n",
        "# corr_df = corpus_sents_syuzhetr_df[syuzhetr_corr_models_ls].corr(method='spearman')\n",
        "corr_df = corpus_sents_all_df.filter(like='stdscale').corr(method=Correlation_Algo)\n",
        "\n",
        "# Customize the heatmap of the corr_meat correlation matrix and rotate the x-axis labels\n",
        "fig = sns.clustermap(corr_df,\n",
        "                     row_cluster=True,\n",
        "                     col_cluster=True,\n",
        "                     figsize=(10, 10))\n",
        "\n",
        "plt.setp(fig.ax_heatmap.xaxis.get_majorticklabels(), rotation=90)\n",
        "plt.setp(fig.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
        "# plt.title(f'{CORPUS_FULL} Sentence Sentiment for All Model Sentiments\\n StdScale Sentiments SMA ({roll_str.capitalize()})')\n",
        "plt.title(f'{CORPUS_FULL} Sentence Sentiment for Transformer Model Sentiments\\n {Correlation_Algo.capitalize()} Correlation - StdScale Sentiments SMA ({roll_str.capitalize()})')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nznsrhwwioqq"
      },
      "source": [
        "## **Compare any StandardizedScale Sentence Sentiment Models**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Select any combination of Sentiment Models in order of the following four Groups: Baseline, SentimentR, SyuzhetR and Transformers\n",
        "\n",
        "* All Sentiment Time Series are StandardizedScaled version of SMA created in the notebook above this cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEaMXFw6hayU"
      },
      "source": [
        "Baseline_SentimentR = False #@param {type:\"boolean\"}\n",
        "Baseline_Syuzhet = False #@param {type:\"boolean\"}\n",
        "Baseline_Bing = False #@param {type:\"boolean\"}\n",
        "Baseline_SenticNet = False #@param {type:\"boolean\"}\n",
        "Baseline_SentiWord = True #@param {type:\"boolean\"}\n",
        "Baseline_NRC = False #@param {type:\"boolean\"}\n",
        "Baseline_AFINN = True #@param {type:\"boolean\"}\n",
        "Baseline_VADER = True #@param {type:\"boolean\"}\n",
        "Baseline_TextBlob = True #@param {type:\"boolean\"}\n",
        "Baseline_Flair = True #@param {type:\"boolean\"}\n",
        "Baseline_Pattern = True #@param {type:\"boolean\"}\n",
        "Baseline_Stanza = True #@param {type:\"boolean\"}\n",
        "# Baseline-Mean_All = False #@param {type:\"boolean\"}\n",
        "# Baseline-Mean_Subset = False #@param {type:\"boolean\"}\n",
        "# Baseline-MPQA = False #@param {type:\"boolean\"}\n",
        "# Baseline-SentiStrength = False #@param {type:\"boolean\"}\n",
        "\n",
        "SentimentR_JockersRinker = True #@param {type:\"boolean\"}\n",
        "SentimentR_Jockers = False #@param {type:\"boolean\"}\n",
        "SentimentR_HuLiu = False #@param {type:\"boolean\"}\n",
        "SentimentR_SenticNet = False #@param {type:\"boolean\"}\n",
        "SentimentR_SentiWord = False #@param {type:\"boolean\"}\n",
        "SentimentR_NRC = False #@param {type:\"boolean\"}\n",
        "SentimentR_LoughranMcDonald = True #@param {type:\"boolean\"}\n",
        "\n",
        "SyuzhetR_Syuzhet = True #@param {type:\"boolean\"}\n",
        "SyuzhetR_Bing = False #@param {type:\"boolean\"}\n",
        "SyuzhetR_AFINN = False #@param {type:\"boolean\"}\n",
        "SyuzhetR_NRC = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "Transformer_RoBERTaLg15 = True #@param {type:\"boolean\"}\n",
        "Transformer_T5IMDB50k = True #@param {type:\"boolean\"}\n",
        "Transformer_Huggingface = True #@param {type:\"boolean\"}\n",
        "Transformer_NLPTown = True #@param {type:\"boolean\"}\n",
        "Transformer_RoBERTaXML8lang = True #@param {type:\"boolean\"}\n",
        "Transformer_IMDB2way = False #@param {type:\"boolean\"}\n",
        "Transformer_Hinglish = True #@param {type:\"boolean\"}\n",
        "Transformer_Yelp = False #@param {type:\"boolean\"}\n",
        "# Mean_Subset_Arc = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PtG4UDBNsrn"
      },
      "source": [
        "corpus_sents_all_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkR7gXEehbbf"
      },
      "source": [
        "# Plotly Interactive/Zoom Sentiment Plots\n",
        "\n",
        "# SMA_Window_Percent = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "# win_per = SMA_Window_Percent\n",
        "# win_roll = int(win_per/100 * corpus_sents_all_df.shape[0])\n",
        "\n",
        "# NOTE: all 4 Groups need to be run with the same SMA roll_per (usually 5 or 10%)\n",
        "#       to compare Models from the 4 different Groups\n",
        "\n",
        "\n",
        "model_all_subset_ls = []\n",
        "\n",
        "if Baseline_SentimentR == True:\n",
        "  model_all_subset_ls.append('baseline_sentimentr_stdscaler_roll10')\n",
        "if Baseline_Syuzhet == True:\n",
        "  model_all_subset_ls.append('baseline_syuzhet_stdscaler_roll10')\n",
        "if Baseline_Bing == True:\n",
        "  model_all_subset_ls.append('baseline_bing_stdscaler_roll10')\n",
        "if Baseline_SenticNet == True:\n",
        "  model_all_subset_ls.append('baseline_senticnet_stdscaler_roll10')\n",
        "if Baseline_SentiWord == True:\n",
        "  model_all_subset_ls.append('baseline_sentiword_stdscaler_roll10')\n",
        "if Baseline_NRC == True:\n",
        "  model_all_subset_ls.append('baseline_nrc_stdscaler_roll10')\n",
        "if Baseline_AFINN == True:\n",
        "  model_all_subset_ls.append('baseline_afinn_stdscaler_roll10')\n",
        "if Baseline_VADER == True:\n",
        "  model_all_subset_ls.append('baseline_vader_stdscaler_roll10')\n",
        "if Baseline_TextBlob == True:\n",
        "  model_all_subset_ls.append('baseline_stanza_stdscaler_roll10')\n",
        "if Baseline_Flair == True:\n",
        "  model_all_subset_ls.append('baseline_flair_stdscaler_roll10')\n",
        "if Baseline_Pattern == True:\n",
        "  model_all_subset_ls.append('baseline_pattern_stdscaler_roll10')\n",
        "if Baseline_Stanza == True:\n",
        "  model_all_subset_ls.append('baseline_stanza_stdscaler_roll10')\n",
        "\n",
        "if SentimentR_JockersRinker == True:\n",
        "  model_all_subset_ls.append('sentimentr_jockers_rinker_stdscaler_roll10')\n",
        "if SentimentR_Jockers == True:\n",
        "  model_all_subset_ls.append('sentimentr_jockers_stdscaler_roll10')\n",
        "if SentimentR_HuLiu == True:\n",
        "  model_all_subset_ls.append('sentimentr_huliu_stdscaler_roll10_')\n",
        "if SentimentR_SenticNet == True:\n",
        "  model_all_subset_ls.append('sentimentr_senticnet_stdscaler_roll10')\n",
        "if SentimentR_SentiWord == True:\n",
        "  model_all_subset_ls.append('sentimentr_sentiword_stdscaler_roll10le')\n",
        "if SentimentR_NRC == True:\n",
        "  model_all_subset_ls.append('sentimentr_nrc_stdscaler_roll10')\n",
        "if SentimentR_LoughranMcDonald == True:\n",
        "  model_all_subset_ls.append('sentimentr_lmcd_stdscaler_roll10')\n",
        "\n",
        "\n",
        "if SyuzhetR_Syuzhet == True:\n",
        "  model_all_subset_ls.append('syuzhetr_syuzhet_stdscaler_roll10')\n",
        "if SyuzhetR_Bing == True:\n",
        "  model_all_subset_ls.append('syuzhetr_bing_stdscaler_roll10')\n",
        "if SyuzhetR_AFINN == True:\n",
        "  model_all_subset_ls.append('syuzhetr_afinn_stdscaler_roll10')\n",
        "if SyuzhetR_NRC == True:\n",
        "  model_all_subset_ls.append('syuzhetr_nrc_stdscaler_roll10')\n",
        "\n",
        "# Exclude Transformer Models if not loaded/defined\n",
        "var_name = 'corpus_transformer_df'\n",
        "if var_name in globals():\n",
        "  # print(f'{var_name} is declared globally')\n",
        "  # print(eval(f'{var_name}.shape[0]'))\n",
        "  corpus_transformer_df_len = eval(f'{var_name}.shape[0]')\n",
        "  print(f'{var_name} has {corpus_transformer_df_len} Sentences')\n",
        "\n",
        "  if Transformer_RoBERTaLg15 == True:\n",
        "    model_all_subset_ls.append('transformer_roberta15lg_stdscaler_roll10')\n",
        "  if Transformer_T5IMDB50k == True:\n",
        "    model_all_subset_ls.append('transformer_t5imdb50k_stdscaler_roll10')\n",
        "  if Transformer_Huggingface == True:\n",
        "    model_all_subset_ls.append('transformer_huggingface_stdscaler_roll10')\n",
        "  if Transformer_NLPTown == True:\n",
        "    model_all_subset_ls.append('transformer_nlptown_stdscaler_roll10')\n",
        "  if Transformer_RoBERTaXML8lang == True:\n",
        "    model_all_subset_ls.append('transformer_robertaxml8lang_stdscaler_roll10')\n",
        "  if Transformer_IMDB2way == True:\n",
        "    model_all_subset_ls.append('transformer_imdb2way_stdscaler_roll10')\n",
        "  if Transformer_Hinglish == True:\n",
        "    model_all_subset_ls.append('transformer_hinglish_stdscaler_roll10')\n",
        "  if Transformer_Yelp == True:\n",
        "    model_all_subset_ls.append('transformer_yelp_stdscaler_roll10')\n",
        "\n",
        "\n",
        "else:\n",
        "  print(f'ERROR: {var_name} IS NOT declared\\n    Go back and load Transformer Sentiment Datafile\\n    and re-run this code cell')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "palette = cycle(px.colors.qualitative.Safe)\n",
        "# palette = cycle(px.colors.sequential.PuBu)\n",
        "\n",
        "my_layout = go.Layout(\n",
        "    autosize=False,\n",
        "    width=1600,\n",
        "    height=800,\n",
        "    margin=go.layout.Margin(\n",
        "        l=10,\n",
        "        r=50,\n",
        "        b=100,\n",
        "        t=100,\n",
        "        pad = 1\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "fig = go.Figure(layout=my_layout)\n",
        "\n",
        "\n",
        "# Add Sentiment Arc Plot Traces\n",
        "for i,amodel in enumerate(model_all_subset_ls):\n",
        "  print(f'Processing Model: {amodel}')\n",
        "  fig.add_traces(go.Line(x = corpus_sents_all_df.index.values,\n",
        "                        y = corpus_sents_all_df[amodel],\n",
        "                        text = corpus_sents_df['sent_raw'], # corpus_sents_df.iloc[x]['sent_raw'],\n",
        "                        name = amodel,\n",
        "                        hovertemplate = \"Model: <b>\"+amodel+\"</b><br>Sentence #<b>%{x}</b><br>Polarity <b>%{y}</b><br>Text: <b><i>%{text}</i></b>\", \n",
        "                        marker_color=next(palette)))\n",
        "\n",
        "\n",
        "fig.update_layout(\n",
        "    title=CORPUS_FULL + \"<br>Compare Sentence StandardizedScaled SMA Sentiment Models<b><i> \" + roll_str.upper() + \"</i></b>\",\n",
        "    xaxis_title=\"Sentence Number\",\n",
        "    # yaxis_title=\"Sentiment Value\",\n",
        "    hoverlabel=dict(\n",
        "        bgcolor=\"white\",\n",
        "        font_size=16,\n",
        "        font_family=\"Rockwell\"\n",
        "    ),\n",
        "    font=dict(\n",
        "        family=\"Courier New, monospace\",\n",
        "        size=18,\n",
        "        color=\"RebeccaPurple\"\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxQtrH196gl3"
      },
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def my_css():\n",
        "   display(HTML(\"\"\"<style>table.dataframe td{white-space: nowrap;}</style>\"\"\"))\n",
        "\n",
        "get_ipython().events.register('pre_run_cell', my_css)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIPzbt5Ikldp"
      },
      "source": [
        "with pd.option_context('display.max_colwidth', None):\n",
        "  display(corpus_transformer_df['sent_raw'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDR54Pbg5zqz"
      },
      "source": [
        "with pd.option_context('display.max_colwidth', None):\n",
        "  display(corpus_sentimentr_df.iloc[:10]['sent_raw'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7WUuj1j4XW7"
      },
      "source": [
        "## **Save Checkpoint**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SIJZk6f2ccm"
      },
      "source": [
        "# Save Preprocessed Corpus Sentences DataFrame\n",
        "\n",
        "# author_str = ''.join(CORPUS_AUTHOR.split()).lower()\n",
        "title_str = ''.join(CORPUS_TITLE.split()).lower()\n",
        "datetime_now = datetime.utcnow().strftime(\"%Y%m%d_%H%M\")\n",
        "\n",
        "\n",
        "# Save the Sentences in the original Raw and Cleaned Corpus \n",
        "corpus_text_sentences_raw_filename = f'corpus_text_sentences_raw_{author_abbr_str}_{title_str}.txt' # _{datetime_now}.txt'\n",
        "print(f'Saving Corpus text raw sentences to file: {corpus_text_sentences_raw_filename}')\n",
        "corpus_sents_df['sent_raw'].to_csv(corpus_text_sentences_raw_filename)\n",
        "\n",
        "corpus_text_sentences_clean_filename = f'corpus_text_sentences_clean_{author_abbr_str}_{title_str}.txt' # _{datetime_now}.txt'\n",
        "print(f'Saving Corpus text clean sentences to file: {corpus_text_sentences_clean_filename}')\n",
        "corpus_sents_df['sent_clean'].to_csv(corpus_text_sentences_clean_filename)\n",
        "\n",
        "\n",
        "# Save the Paragraphs in the original Raw and Cleaned Corpus\n",
        "corpus_text_paragraphs_raw_filename = f'corpus_text_paragraphs_raw_{author_abbr_str}_{title_str}.txt' # _{datetime_now}.txt'\n",
        "print(f'Saving Corpus text raw paragraphs to file: {corpus_text_paragraphs_raw_filename}')\n",
        "corpus_parags_df['parag_raw'].to_csv(corpus_text_paragraphs_raw_filename)\n",
        "\n",
        "corpus_text_paragraphs_clean_filename = f'corpus_text_sentences_clean_{author_abbr_str}_{title_str}.txt' # _{datetime_now}.txt'\n",
        "print(f'Saving Corpus text clean sentences to file: {corpus_text_paragraphs_clean_filename}')\n",
        "corpus_parags_df['parag_clean'].to_csv(corpus_text_paragraphs_clean_filename)\n",
        "\n",
        "\n",
        "# Save the Sentences of each of the 4 Groups DataFrames NOTE: The Baseline role is fulfilled by the default corpus_sents_df DataFrame\n",
        "# corpus_sents_filename = f'sum_sentiments_sents_baseline_{author_abbr_str}_{title_str}.csv' # _{datetime_now}.csv'\n",
        "# print(f'Saving Sentence Baselines to file: {corpus_sents_filename}')\n",
        "# corpus_sents_df.to_csv(corpus_sents_filename)\n",
        "\n",
        "corpus_sentimentr_filename = f'sum_sentiments_sents_sentimentr_{author_abbr_str}_{title_str}.csv' # _{datetime_now}.csv'\n",
        "print(f'Saving Sentence SentimentR to file: {corpus_sentimentr_filename}')\n",
        "corpus_sentimentr_df.to_csv(corpus_sentimentr_filename)\n",
        "\n",
        "corpus_syuzhetr_filename = f'sum_sentiments_sents_syuzhetr_{author_abbr_str}_{title_str}.csv' # _{datetime_now}.csv'\n",
        "print(f'Saving Sentence SyuzhetR to file: {corpus_syuzhetr_filename}')\n",
        "corpus_syuzhetr_df.to_csv(corpus_syuzhetr_filename)\n",
        "\n",
        "corpus_transformer_filename = f'sum_sentiments_sents_transformer_{author_abbr_str}_{title_str}.csv' # _{datetime_now}.csv'\n",
        "print(f'Saving Sentence Transformer to file: {corpus_transformer_filename}')\n",
        "corpus_transformer_df.to_csv(corpus_transformer_filename)\n",
        "\n",
        "\n",
        "# Save StandardizedScaled SMA Sentences of ALL Models from the Unified DataFrame\n",
        "corpus_sents_all_filename = f'sum_sentiments_sents_all_{author_abbr_str}_{title_str}.csv' # _{datetime_now}.csv'\n",
        "print(f'Saving Sentence ALL Models to file: {corpus_sents_all_filename}')\n",
        "# corpus_sents_all_df.to_csv(corpus_sents_all_filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k80YU4ZoHCs2"
      },
      "source": [
        "## **Calculate Lexical Statistics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CokfceWPtfD"
      },
      "source": [
        "# TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9cZmIkx7Too"
      },
      "source": [
        "# **EDA (Repeat for each Sentiment Model)** (Auto)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJRV2n0M_xN6"
      },
      "source": [
        "#### **Histograms**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJTcj9faMh61"
      },
      "source": [
        "**Sentiment Histogram Plots**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Histograms are provided for the (a) Length-Normed and (b) Scaled (Median Interquartile Range) Sentiment values for Sentences, Paragraphs and Sections. \n",
        "\n",
        "* There we used extensively early on to compare which Sentiment Time series preprocessing techniques worked best with our various Novel corpora according to two criteria: \n",
        "\n",
        "* (a) Vertical Scaling Method with the ability to transform histograms of sentiment values to well-behaved near-gaussian distributions and clipping outliers. After experimenting with various techniques including: mean/STD, median/MAD, and various two stage outlier/normalization methods median/IQR proved best (define).\n",
        "\n",
        "* (b) Horizontal Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPEv0DsBRhhQ"
      },
      "source": [
        "plot_histogram(model_name=model_name, text_unit='sentence', save2file=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU46yaCPPdSm"
      },
      "source": [
        "# col_medianiqr = f'{model_name}_medianiqr'\n",
        "plot_histogram(model_name=col_medianiqr, text_unit='sentence', save2file=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYs2V2ILENaZ"
      },
      "source": [
        "corpus_sents_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8b4CjTYwlgP"
      },
      "source": [
        "# Plot Histogram of Sentence lengths\n",
        "\n",
        "# col_lnorm_medianiqr = f'{model_name}_lnorm_medianiqr'\n",
        "plot_histogram(model_name=col_lnorm_medianiqr, text_unit='sentence', save2file=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuwVO3Q4Rmu4"
      },
      "source": [
        "plot_histogram(model_name=model_name, text_unit='paragraph', save2file=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MhJ4T18PjTM"
      },
      "source": [
        "# col_medianiqr = f'{model_name}_medianiqr'\n",
        "plot_histogram(model_name=col_medianiqr, text_unit='paragraph', save2file=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SajUdBthwlgR"
      },
      "source": [
        "# Plot Histogram of Paragraph lengths\n",
        "\n",
        "# col_lnorm_medianiqr = f'{model_name}_lnorm_medianiqr'\n",
        "plot_histogram(model_name=col_lnorm_medianiqr, text_unit='paragraph', save2file=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nuOQ7cZRrue"
      },
      "source": [
        "plot_histogram(model_name=model_name, text_unit='section', save2file=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfhjLMdjRwZX"
      },
      "source": [
        "# col_medianiqr = f'{model_name}_medianiqr'\n",
        "plot_histogram(model_name=col_medianiqr, text_unit='section', save2file=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBFb-SLywlgS"
      },
      "source": [
        "# Plot Histogram of Section lengths\n",
        "\n",
        "# col_lnorm_medianiqr = f'{model_name}_lnorm_medianiqr'\n",
        "plot_histogram(model_name=col_lnorm_medianiqr, text_unit='section', save2file=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43YL_Iuf0JHZ"
      },
      "source": [
        "#### **Raw Sentiment Plots**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AHHijpONvpt"
      },
      "source": [
        "plot_raw_sentiments(model_name=model_name, semantic_type='sentence', save2file=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GorGKbFbR28W"
      },
      "source": [
        "# col_medianiqr = f'{model_name}_medianiqr'\n",
        "plot_raw_sentiments(model_name=col_medianiqr, semantic_type='sentence', save2file=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN27M4WlwlgT"
      },
      "source": [
        "# Plot Raw Sentence Sentiments\n",
        "\n",
        "# col_lnorm_medianiqr = f'{model_name}_lnorm_medianiqr'\n",
        "plot_raw_sentiments(model_name=col_lnorm_medianiqr, semantic_type='sentence', save2file=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0QCx2OMN_jm"
      },
      "source": [
        "plot_raw_sentiments(model_name=model_name, semantic_type='paragraph', save2file=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxL5FryPR-ln"
      },
      "source": [
        "# col_medianiqr = f'{model_name}_medianiqr'\n",
        "plot_raw_sentiments(model_name=col_medianiqr, semantic_type='paragraph', save2file=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d8uXvYJwlgU"
      },
      "source": [
        "# Plot Raw Paragraph Sentiments\n",
        "\n",
        "# col_lnorm_medianiqr = f'{model_name}_lnorm_medianiqr'\n",
        "plot_raw_sentiments(model_name=model_name, semantic_type='paragraph', save2file=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vp7xjR7GvxkT"
      },
      "source": [
        "# TODO: Add Section Crux Nos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2hFkRQHSLVE"
      },
      "source": [
        "plot_raw_sentiments(model_name=model_name, semantic_type='section', save2file=False)\n",
        "\n",
        "plt.legend(loc='best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adhoCpB5SFQv"
      },
      "source": [
        "# col_medianiqr = f'{model_name}_medianiqr'\n",
        "# col_meanstd = f'{model_name}_meanstd'\n",
        "\n",
        "plot_raw_sentiments(model_name=col_medianiqr, semantic_type='section', save2file=False)\n",
        "plot_raw_sentiments(model_name=col_meanstd, semantic_type='section', save2file=False)\n",
        "\n",
        "plt.legend(loc='best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjZZqY6cwlgW"
      },
      "source": [
        "# Plot Raw Standardized Section Sentiments\n",
        "\n",
        "# NOTE: Compared with Length-Normed, the Raw Standardizations lose most SATS features\n",
        "\n",
        "# col_lnorm_medianiqr = f'{model_name}_lnorm_medianiqr'\n",
        "# col_lnorm_meanstd = f'{model_name}_lnorm_meanstd'\n",
        "\n",
        "plot_raw_sentiments(model_name=col_lnorm_medianiqr, semantic_type='section', save2file=False)\n",
        "plot_raw_sentiments(model_name=col_lnorm_meanstd, semantic_type='section', save2file=False)\n",
        "\n",
        "plt.legend(loc='best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDF_-tZhr44H"
      },
      "source": [
        "# Plot Raw Standardized Chapter Sentiments\n",
        "\n",
        "# col_lnorm_medianiqr = f'{model_name}_lnorm_medianiqr'\n",
        "# col_lnorm_meanstd = f'{model_name}_lnorm_meanstd'\n",
        "\n",
        "plot_raw_sentiments(model_name=col_lnorm_medianiqr, semantic_type='chapter', save2file=False)\n",
        "plot_raw_sentiments(model_name=col_lnorm_meanstd, semantic_type='chapter', save2file=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1tIJZepmvLu"
      },
      "source": [
        "#### **Crux Points and Surrounding Contexts**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FBWrNEJyit6"
      },
      "source": [
        "# Veify all the model sentiment variations\n",
        "\n",
        "[x for x in corpus_sects_df.columns if x.startswith(model_base)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKazAFV_qpCn"
      },
      "source": [
        "**Compare Chapters vs Sections Crux Points**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* At the highest level, the Corpus is divided into Chapters which may then futher subdivided into Sections (e.g. extra spaces, punctuation like '* * *' or special printer glyph/fleuron).  Horizonal dark blue lines indicate Chapter divisions while Section boundries lie at both dark and light blue vertical lines.\n",
        "\n",
        "* Since each Chapter may contain multiple Sections, the Section Sentiment plot is more detailed/jagged than the Chapter Sentiment plots. By plotting both together, the smoother Chapter Sentiment plot gives a more general sense of the Corpus Sentiment Arc while the next, more-detailed Section Sentiment plot enables a more detailed investigation/localization of Crux Point neighborhoods.\n",
        "\n",
        "* At this early stage both the Chapter and Section Sentiment plots are too general to provide accurate/fixed Crux localization. As such, only aggregrate Sentiment values for each Chapter/Section are assigned to the mid-point of each Chapter/Section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sme-1HVRZOGs"
      },
      "source": [
        "# col_lnorm_medianiqr = 'pattern_lnorm_medianiqr'\n",
        "col_lnorm_medianiqr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08xDu5WgkGAg"
      },
      "source": [
        "# col_lnorm_medianiqr = 'vader_lnorm_medianiqr'\n",
        "\n",
        "# corpus_chaps_df.drop(columns=['textblob_lnorm_medianiqr_lnorm_medianiqr', 'textblob_lnorm_medianiqr_medianiqr', 'textblob_lnorm_medianiqr_lnorm_meanstd'], inplace=True, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06m1xDRzmWbq"
      },
      "source": [
        "corpus_chaps_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tojSdIGkPDz"
      },
      "source": [
        "corpus_chaps_df.columns\n",
        "# corpus_chaps_df.iloc[:20][['chap_no','sent_no_start','sent_no_mid','char_len','token_len','vader', 'vader_lnorm_medianiqr', 'textblob', 'textblob_lnorm_medianiqr']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu6F5kWerAPZ"
      },
      "source": [
        "corpus_chaps_df.vader_lnorm_medianiqr.min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLgGy3HgO9--"
      },
      "source": [
        "col_lnorm_medianiqr = 'syuzhet_lnorm_medianiqr'\n",
        "model_name = 'syuzhet_lnorm_medianiqr'\n",
        "model_base = 'syuzhet'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M1bg8RcPH_2"
      },
      "source": [
        "# Plot Annotated Section Cruxes of Raw Sentiment Time Series\n",
        "\n",
        "sec_y_ht = 0\n",
        "\n",
        "corpus_cruxes_dt[col_lnorm_medianiqr] = plot_crux_sections(model_names_ls=[model_base], semantic_type='chapter', label_token_ct=3, title_xpos=0.8, title_ypos=1.05, sec_y_height=sec_y_ht, save2file=False)\n",
        "\n",
        "corpus_cruxes_dt[col_lnorm_medianiqr] = plot_crux_sections(model_names_ls=[model_base], semantic_type='section', label_token_ct=-1, title_xpos=0.8, title_ypos=1.05, sec_y_height=sec_y_ht, save2file=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jku9ZQ9v9Wg"
      },
      "source": [
        "# Plot Annotated Section Cruxes of Standardized Sentiment Time Series\n",
        "\n",
        "sec_y_ht = 0\n",
        "\n",
        "corpus_cruxes_dt[col_lnorm_medianiqr] = plot_crux_sections(model_names_ls=[col_lnorm_medianiqr], semantic_type='chapter', label_token_ct=3, title_xpos=0.8, title_ypos=1.05, sec_y_height=sec_y_ht, save2file=False)\n",
        "\n",
        "corpus_cruxes_dt[col_lnorm_medianiqr] = plot_crux_sections(model_names_ls=[col_lnorm_medianiqr], semantic_type='section', label_token_ct=-1, title_xpos=0.8, title_ypos=1.05, sec_y_height=sec_y_ht, save2file=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxA0sDvlcdLx"
      },
      "source": [
        "**Sections Crux Points in Detail**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2tKXTD8v9RH"
      },
      "source": [
        "# Corpus Section Standardized Sentiment Time Series\n",
        "\n",
        "sec_y_ht = 0\n",
        "\n",
        "corpus_cruxes_dt[col_lnorm_medianiqr] = plot_crux_sections(model_names_ls=[col_lnorm_medianiqr], semantic_type='section', label_token_ct=5, title_xpos=0.8, title_ypos=1.05, sec_y_height=sec_y_ht, save2file=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSw-wARBF2fW"
      },
      "source": [
        "**Verify Crux Point Sentence Number and Text Match**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* At [Crux_Sentence_Text] enter the first few words that uniquely identify the Crux Sentence and confirm the Sentence No matches the information in the plot above. (NOTE: Search is for an exact match including case and puncutation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PU6l4UaPdmAF"
      },
      "source": [
        "Crux_Sentence_Text = \"haiku\" #@param {type:\"string\"}\n",
        "\n",
        "# Verify individual Crux Sentence Numbers matches Content\n",
        "\n",
        "crux_sent_no = int(corpus_sents_df[corpus_sents_df['sent_raw'].str.contains(Crux_Sentence_Text)]['sent_no'])\n",
        "\n",
        "print(f'The Sentence:\\n\\n    {Crux_Sentence_Text}\\n\\nMatches Sentence #{crux_sent_no}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5Q_weR3H5Qu"
      },
      "source": [
        "**Review Context Around Any Crux Point**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Enter [Crux_Sentence_No] that matches a Crux point/Sentence No you want to explore\n",
        "\n",
        "* Enter [No_Paragraphs_on_Each_Side] to retrieve this many Paragraphs before and after the Paragraph containing your Crux Sentence (e.g. 2 will bring back 5 paragraphs centered around the Paragraph containing the Crux Sentence)\n",
        "\n",
        "* Select [Highlight_Crux_Sentence] to have the Crux Sentence converted to ALL CAPS for easier identification. The Paragraph containing the Crux Sentence will be prefaced with a '<*>' as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYAqkxi2FSw1"
      },
      "source": [
        "# Select details about the Crux Point Context to Retrieve\n",
        "\n",
        "# print(f'Last Sentence No: {corpus_sents_df.shape[0]}')\n",
        "Crux_Sentence_No =  4494#@param {type:\"number\"}\n",
        "No_Paragraphs_on_Each_Side = 3 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "Highlight_Crux_Sentence = True #@param {type:\"boolean\"}\n",
        "\n",
        "corpus_sents_len = corpus_sents_df.shape[0]\n",
        "\n",
        "# if (Crux_Sentence_No >= No_Paragraphs_on_Each_Side) & (Crux_Sentence_No+No_Paragraphs_on_Each_Side <= corpus_parag_len):\n",
        "# get_sentnocontext_report()\n",
        "# try:\n",
        "get_sentnocontext_report(the_sent_no=Crux_Sentence_No, the_n_sideparags=No_Paragraphs_on_Each_Side, the_sent_highlight=Highlight_Crux_Sentence)\n",
        "# except:\n",
        "#   print('ERROR')\n",
        "# else:\n",
        "#   print(f'ERROR: The combination of your [Crux_Sentence_No] and [No_Pargraphs_on_Each_Side]\\n       results in a window outside the range of the Corpus Paragraphs.\\n\\n       Try again with different values.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7-PoXAcq4S4"
      },
      "source": [
        "**Compare Paragraph vs Section Crux Points**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rzgfs-U9QZeq"
      },
      "source": [
        "# Verify the valid ranges for Sentences and Paragraphs\n",
        "\n",
        "corpus_sents_len = corpus_sents_df.shape[0]\n",
        "print(f'There are {corpus_sents_len} Sentences in the Corpus')\n",
        "corpus_parags_len = corpus_parags_df.shape[0]\n",
        "print(f'There are {corpus_parags_len} Paragraphs in the Corpus')\n",
        "\n",
        "# Create a new Corpus Paragraph DataFrame (corpus_parags_zoom_df) that is streteched out to have as many sample points as there are Sentences\n",
        "#   That is, go from an original corpus_parags_df of #Paragraph datapoints to an expanded corpus_parags_zoom_df of #Sentences datapoints using scipy.ndimage.interpolation.zoom\n",
        "\n",
        "corpus_parags_zoom_df = pd.DataFrame()\n",
        "\n",
        "resample_ratio = corpus_sents_df.shape[0]/corpus_parags_df.shape[0]   # ratio = no_sents/no_parags\n",
        "\n",
        "corpus_parags_df_numcols_ls = corpus_parags_df.select_dtypes(include=['number']).columns\n",
        "\n",
        "for acol in corpus_parags_df_numcols_ls:\n",
        "  parags_zoom_temp_np = zoom(np.array(corpus_parags_df[acol]), resample_ratio)\n",
        "  corpus_parags_zoom_df[acol] = pd.Series(parags_zoom_temp_np)\n",
        "\n",
        "print('\\n')\n",
        "print(f'New expanded corpus_parags_zoom_df.shape = {corpus_parags_zoom_df.shape}')\n",
        "print(f'           matches corpus_sents_df.shape = {corpus_sents_df.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wskHXVNSmjfQ"
      },
      "source": [
        "**Adjust the Paragraph Sentiment Plot to compare it with the Section Sentiment Plot for this Corpus**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Adjust [Scale_Vertical_Rolling_Paragraph] until the vertical min/max spans of the two plots are approximately equal\n",
        "\n",
        "* Adjust [Set_Paragraph_Rolling_Window_Percent] to set horizonal smoothness of Rolling Paragraph (typically 5,10 or 20%)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9P9k98ibh4n"
      },
      "source": [
        "col_lnorm_medianiqr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgaBEAVCTMRt"
      },
      "source": [
        "Scale_Vertical_Rolling_Paragraph = 2.7 #@param {type:\"slider\", min:0, max:20, step:0.1}\n",
        "Set_Paragraph_Rolling_Window_Percent = 3 #@param {type:\"slider\", min:0, max:30, step:1}\n",
        "\n",
        "# Compare Section Midpoints vs Sentence SMA Sentiment Values\n",
        "\n",
        "scale_sma_paragraph = Scale_Vertical_Rolling_Paragraph\n",
        "sentence_count = corpus_sents_df.shape[0]\n",
        "if Set_Paragraph_Rolling_Window_Percent == 0:\n",
        "  sma_parag_win = 1\n",
        "else:\n",
        "  sma_parag_win = int((Set_Paragraph_Rolling_Window_Percent/100)*sentence_count)\n",
        "\n",
        "\n",
        "# corpus_parags_zoom_df['vader_lnorm_medianiqr'].rolling(window=sma_parag_win, center=True).mean().apply(lambda x: x*scale_sma_paragraph).plot(label=f'{model_base} Paragraphs', alpha=0.3)\n",
        "corpus_parags_zoom_df[col_lnorm_medianiqr].rolling(window=sma_parag_win, center=True).mean().apply(lambda x: x*scale_sma_paragraph).plot(label=f'{model_base} Paragraphs', alpha=0.3)\n",
        "\n",
        "_ = plot_crux_sections(model_names_ls=[col_lnorm_medianiqr], semantic_type='section', label_token_ct=0, title_xpos=0.5, title_ypos=1.0, sec_y_height=0, save2file=False)\n",
        "plt.title(f'{CORPUS_FULL} \\n SMA vs midpoint Paragraph MedianIQR Sentiment with Crux Points via SciPy.peaks')\n",
        "plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUyZF6tE1rL0"
      },
      "source": [
        "#### **Zoom into a Section**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* At [Select_Section_No] pick a Section of the Corpus to zoom into\n",
        "\n",
        "* Adjust [Scale_Vertical_Rolling_Sentences] until the vertical min/max spans of the two plots are approximately equal \n",
        "\n",
        "* Adjust [Set_Sentence_Rolling_Window_Percent] to set horizonal smoothness of Rolling Paragraph (typically 5,10 or 20%)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hu7DYRELQBoH"
      },
      "source": [
        "# Explore a Corpus Section Up-Close\n",
        "\n",
        "section_count = corpus_sects_df.shape[0]\n",
        "print(f'There are {section_count} Sections in this corpus,\\n  pick one numbered between 0 and {section_count-1}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3Q2a854Zxl1"
      },
      "source": [
        "Select_Section_No =  24#@param {type:\"integer\"}\n",
        "Scale_Vertical_Rolling_Sentences = 0.2 #@param {type:\"slider\", min:0, max:20, step:0.1}\n",
        "Set_Sentence_Rolling_Window_Percent = 3 #@param {type:\"slider\", min:0, max:30, step:1}\n",
        "\n",
        "# Make Copies instead of just using References / Only Reference, not copy()\n",
        "# section_sents_df = pd.DataFrame()\n",
        "# section_parags_df = pd.DataFrame()\n",
        "\n",
        "section_sents_df, section_parags_df = get_section_timeseries(Select_Section_No)\n",
        "\n",
        "# section_sents_df.head()\n",
        "\n",
        "print(f'section_sents_df.shape: {section_sents_df.shape}')\n",
        "print(f'section_parags_df.shape: {section_parags_df.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MbSPmp2dN9Z"
      },
      "source": [
        "model_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qE-CDUmvFDOe"
      },
      "source": [
        "# Add expanded Paragraph sentiment to corpus_sents_df\n",
        "# section_sents_parags_df['vader_lnorm_medianiqr_parag'] = expand_parags2sents(parags_df='corpus_parags_df', sents_df='corpus_sents_df')\n",
        "\n",
        "# NOTE: Define section_sents_df, MUST BE EXECUTED BEFORE ANY CRUX POINT DETECTION!!!\n",
        "\n",
        "parags_midpoint_ls = []\n",
        "col_name_parag = f'{model_name}_parag'\n",
        "section_sents_df[col_name_parag], parags_midpoint_ls = expand_parags2sents(parags_df='corpus_parags_df', sents_df='corpus_sents_df', model_name=model_name)\n",
        "\n",
        "# Verify Sentences and Expanded Paragraph lengths match\n",
        "print(f'\\nIn Section #{Select_Section_No}\\n')\n",
        "print(f'            Sentence Count: {section_sents_df.shape[0]}')\n",
        "print(f\"(expanded) Paragraph Count: {str(section_sents_df['parag_no'].unique().shape[0])}\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOBqRxQz3gbh"
      },
      "source": [
        "##### **Section Histograms**\n",
        "\n",
        "EDA Unbalanced Paragraph and Sentence Features within selected Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MoMM3l8Px2R"
      },
      "source": [
        "# Verify the non-uniform distribution of Paragraph lengths within selected Section (thus necessity for noralizing Paragraph Sentiment by Paragraph length)\n",
        "\n",
        "section_sents_df['parag_no'].value_counts().hist(bins=30)\n",
        "plt.title(f'{CORPUS_FULL} (Model: {model_base})\\nHistogram of Number of Sentences per Paragraph in Section #{Select_Section_No}')\n",
        "plt.xlabel('Number of Sentences per Paragraph')\n",
        "plt.ylabel('Frequency');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5eC0i5KO9cm"
      },
      "source": [
        "section_parags_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoVdCaReDJvl"
      },
      "source": [
        "section_sents_df[model_name].hist(bins=30)\n",
        "plt.title(f'{CORPUS_FULL} (Model: {model_base})\\nHistogram of Sentence Sentiment in Section #{Select_Section_No}')\n",
        "plt.xlabel('Sentence Sentiment')\n",
        "plt.ylabel('Frequency');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSrXWnnEEm00"
      },
      "source": [
        "# Histogram of Paragraph Sentiments within selected Section\n",
        " \n",
        "# create a unified Section DataFrame with equal length Sentences and (expanded) Paragraphs Sentiment Series\n",
        "# section_sents_parags_df = section_sents_df.copy()\n",
        "# section_sents_parags_df['vader_lnorm_medianiqr_parag_approx'] = parag_sentiment_expanded_ls\n",
        "\n",
        "\n",
        "section_sents_df[col_name_parag].hist(bins=30)\n",
        "plt.title(f'{CORPUS_FULL} (Model: {model_base})\\nHistogram of Length-Normed Paragraph Sentiment in Section #{Select_Section_No}')\n",
        "plt.xlabel('Length-Normed Sentiment of Paragraph')\n",
        "plt.ylabel('Frequency');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcao3RNuyCr_"
      },
      "source": [
        "**Naive Raw and LOWESS Smoothed Paragraph Sentiment plots within selected Section**\n",
        "\n",
        "NOTE: Horizonal x-axis narrative time axis not adjusted for variable paragraph lengths - simply used midpoints assuming equal length Paragraphs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ag47-b4EEO6k"
      },
      "source": [
        "**Raw and SMA Sentence Sentiment Plot within selected Section**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkpQiVCoZTJ0"
      },
      "source": [
        "# section_crux_sents_dt\n",
        "\n",
        "# type(section_crux_sents_dt['vader_lnorm_medianiqr_roll50_frac14_win10'][0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mB4fEZzJQPkg"
      },
      "source": [
        "##### **Section SMA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAIAX2OhW2k0"
      },
      "source": [
        "# SMA with Raw Sentiment values over entire Corpus\n",
        "\n",
        "sec_y_ht = -0.06\n",
        "\n",
        "plot_smas(section_view=False, model_name=model_base, text_unit='sentence', wins_ls=[5,10,15,20], alpha=0.5, y_height=sec_y_ht, subtitle_str=f'(Model: {model_base.capitalize()})', save2file=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8xWHqNAYV_p"
      },
      "source": [
        "# SMA with Length-Normed MedianIQR Sentiment values over entire Corpus\n",
        "\n",
        "sec_y_ht = -0.11\n",
        "\n",
        "plot_smas(section_view=False, model_name=model_name, text_unit='sentence', wins_ls=[5,10,15,20], alpha=0.5, y_height=sec_y_ht, subtitle_str=f'(Model: {model_base.capitalize()})', save2file=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nA285mHvM4T"
      },
      "source": [
        "# Within the Selected_Section_No, plot Sentence SMA with vertical Paragraph boundries indicated\n",
        "\n",
        "sec_y_ht = 0.65\n",
        "\n",
        "# At Section boundries draw blue vertical lines \n",
        "paragraph_boundries_ls = list(section_sents_df['parag_no'].unique())\n",
        "for i, aparag in enumerate(paragraph_boundries_ls):\n",
        "  if i%5 == 0:\n",
        "    # Plot every 5th paragraph\n",
        "    sent_no = section_sents_df[section_sents_df['parag_no'] == aparag]['sent_no'].min()\n",
        "    plt.text(sent_no, sec_y_ht, f'Paragraph #{aparag}', alpha=0.2, rotation=90)\n",
        "    plt.axvline(sent_no, color='blue', alpha=0.1)\n",
        "  # 'BigNews1', xy=(sent_no, 0.5), xytext=(-10, 25), textcoords='offset points',                   rotation=90, va='bottom', ha='center', annotation_clip=True)\n",
        "\n",
        "  # plt.text(sent_no, -.5, 'goodbye',rotation=90, zorder=0)\n",
        "      \n",
        "for win_size in range(50,250,25):\n",
        "  section_sents_df[model_name].rolling(win_size, center=True).mean().plot(alpha=0.5, label=f'SMA win={win_size}')\n",
        "plt.title(f'{CORPUS_FULL} (Model: {model_base.capitalize()})\\nSMA Length-Normed Sentence Sentiment in Section #{Select_Section_No}')\n",
        "plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfZiEeDhWJJM"
      },
      "source": [
        "# Within the Selected_Section_No, compare Sentence SMA with vertical Paragraph boundries indicated\n",
        "#    3 Sentence SMAs: (a)Raw vs (b)Standardized MedianIQR vs (c)Length-Normed Standardized MedianIQR\n",
        "\n",
        "sec_y_ht = -0.5\n",
        "\n",
        "paragraph_boundries_ls = list(section_sents_df['parag_no'].unique())\n",
        "for i, aparag in enumerate(paragraph_boundries_ls):\n",
        "  if i%5 == 0:\n",
        "    # Plot every 5th paragraph\n",
        "    sent_no = section_sents_df[section_sents_df['parag_no'] == aparag]['sent_no'].min()\n",
        "    plt.text(sent_no, sec_y_ht, f'Paragraph #{aparag}', alpha=0.2, rotation=90)\n",
        "    plt.axvline(sent_no, color='blue', alpha=0.1)\n",
        "\n",
        "awins_ls = [10]\n",
        "get_smas(section_sents_df, model_name=model_name, text_unit='sentence', wins_ls=awins_ls, alpha=0.5, scale_factor=1., subtitle_str=f'Section #{Select_Section_No}', mean_adj=0., do_plot=True, save2file=False)\n",
        "get_smas(section_sents_df, model_name=col_medianiqr, text_unit='sentence', wins_ls=awins_ls, alpha=0.5, scale_factor=1.8, subtitle_str='', mean_adj=0., do_plot=True, save2file=False)\n",
        "get_smas(section_sents_df, model_name=model_base, text_unit='sentence', wins_ls=awins_ls, alpha=0.5, scale_factor=8., subtitle_str=f'Section #{Select_Section_No}', mean_adj=0., do_plot=True, save2file=False);\n",
        "plt.title(f'{CORPUS_FULL} (Model: {model_base})\\nSMA Length-Normed Sentence Sentiment in Section #{Select_Section_No} (win={awins_ls[0]}%)')\n",
        "plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqlsQS-RYT7x"
      },
      "source": [
        "# Within the Selected_Section_No, compare Paragraph SMA: (a)Raw vs (b)Standardized MedianIQR vs (c)Length-Normed Standardized MedianIQR\n",
        "#     Plot Paragraph by Sentence Sentiment within selected Section\n",
        "\n",
        "get_smas(section_sents_df, model_name=model_name, text_unit='paragraph', wins_ls=[5], alpha=0.5, scale_factor=1., subtitle_str=f'Section #{Select_Section_No}', mean_adj=0., do_plot=True, save2file=False)\n",
        "get_smas(section_sents_df, model_name=col_medianiqr, text_unit='paragraph', wins_ls=[5], alpha=0.5, scale_factor=1.8, subtitle_str='', mean_adj=0., do_plot=True, save2file=False)\n",
        "get_smas(section_sents_df, model_name=model_base, text_unit='paragraph', wins_ls=[5], alpha=0.5, scale_factor=8., subtitle_str=f'Section #{Select_Section_No}', mean_adj=0., do_plot=True, save2file=False)\n",
        "plt.title(f'{CORPUS_FULL} (Model: {model_base})\\nSMA Length-Normed Sentence Sentiment in Section #{Select_Section_No} (win={awins_ls[0]}%)')\n",
        "plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTHlWyjzYf7C"
      },
      "source": [
        "# Within the Selected_Section_No, compare Paragraph SMA: (a)Raw vs (b)Standardized MedianIQR vs (c)Length-Normed Standardized MedianIQR\n",
        "#     Plot Paragraph by Paragraph Sentiment within selected Section\n",
        "\n",
        "\"\"\"\n",
        "# TODO: Fix ValueError: Image size of 1311x82731 pixels is too large. It must be less than 2^16 in each direction.\n",
        "\n",
        "\n",
        "sec_y_ht = -15\n",
        "\n",
        "paragraph_boundries_ls = list(section_sents_df['parag_no'].unique())\n",
        "for i, aparag_no in enumerate(paragraph_boundries_ls):\n",
        "  if i%5 == 0:\n",
        "    # Plot every 5th paragraph\n",
        "    sent_no = section_sents_df[section_sents_df['parag_no'] == aparag]['sent_no'].min()\n",
        "    plt.text(aparag_no, sec_y_ht, f'Paragraph #{aparag_no}', alpha=0.2, rotation=90)\n",
        "    plt.axvline(aparag_no, color='blue', alpha=0.1)\n",
        "\n",
        "awins_ls = [5]\n",
        "get_smas(section_parags_df, model_name=model_name, text_unit='paragraph', wins_ls=awins_ls, alpha=0.5, scale_factor=1., subtitle_str=f'Section #{Select_Section_No}', mean_adj=0., do_plot=True, save2file=False)\n",
        "get_smas(section_parags_df, model_name=col_medianiqr, text_unit='paragraph', wins_ls=awins_ls, alpha=0.5, scale_factor=8., subtitle_str='', mean_adj=0., do_plot=True, save2file=False)\n",
        "get_smas(section_parags_df, model_name=model_base, text_unit='paragraph', wins_ls=awins_ls, alpha=0.5, scale_factor=10., subtitle_str=f'Section #{Select_Section_No}', mean_adj=0., do_plot=True, save2file=False)\n",
        "plt.title(f'{CORPUS_FULL} (Model: {model_base})\\nSMA Length-Normed Paragraph Sentiment in Section #{Select_Section_No} (win={awins_ls[0]}%)')\n",
        "plt.legend(loc='best');\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhIM7zwuQUBq"
      },
      "source": [
        "##### **Raw Sentiments**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp0JvXFrV-B4"
      },
      "source": [
        "# Within the Selected_Section_No, compare Sentence Sentiment: (a)Raw vs (b)Standardized MedianIQR vs (c)Length-Normed Standardized MedianIQR\n",
        "#     Plot Raw vs MedianIQR Sentence Sentiment within selected Section\n",
        "\n",
        "sec_y_ht = -4.0\n",
        "\n",
        "paragraph_boundries_ls = list(section_sents_df['parag_no'].unique())\n",
        "for i, aparag in enumerate(paragraph_boundries_ls):\n",
        "  if i%5 == 0:\n",
        "    # Plot every 5th paragraph\n",
        "    sent_no = section_sents_df[section_sents_df['parag_no'] == aparag]['sent_no'].min()\n",
        "    plt.text(sent_no, sec_y_ht, f'Paragraph #{aparag}', alpha=0.2, rotation=90)\n",
        "    plt.axvline(sent_no, color='blue', alpha=0.1)\n",
        "\n",
        "plt.plot(model_base, data=section_sents_df, alpha=0.3, label=f'Raw Sentence Sentiment ({model_base})')\n",
        "plt.plot(col_medianiqr, data=section_sents_df, alpha=0.5, label=f'MedianIQR Sentence Sentiment ({model_base})')\n",
        "plt.plot(col_lnorm_medianiqr, data=section_sents_df, alpha=0.5, label=f'MedianIQR Sentence Sentiment ({model_base})')\n",
        "plt.title(f'{CORPUS_FULL} (Model: {model_base})\\nRaw vs MedianIQR Sentence Sentiment in Section #{Select_Section_No}')\n",
        "plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzoXo8mVZMq_"
      },
      "source": [
        "# Within the Selected_Section_No, compare Sentence Sentiment: \n",
        "#     MedianIQR vs Length-Normed MedianIQR Sentence Sentiment within selected Section\n",
        "\n",
        "sec_y_ht = 0\n",
        "\n",
        "paragraph_boundries_ls = list(section_sents_df['parag_no'].unique())\n",
        "for i, aparag in enumerate(paragraph_boundries_ls):\n",
        "  if i%5 == 0:\n",
        "    # Plot every 5th paragraph\n",
        "    sent_no = section_sents_df[section_sents_df['parag_no'] == aparag]['sent_no'].min()\n",
        "    plt.text(sent_no, sec_y_ht, f'Paragraph #{aparag}', alpha=0.2, rotation=90)\n",
        "    plt.axvline(sent_no, color='blue', alpha=0.1)\n",
        "\n",
        "plt.plot(model_name, data=section_sents_df, alpha=0.3, label=f'Length-Normed MedianIQR Sentence Sentiment ({model_base})')\n",
        "plt.plot(col_medianiqr, data=section_sents_df, alpha=0.3, label=f'MedianIQR Sentence Sentiment ({model_base})')\n",
        "plt.title(f'{CORPUS_FULL} (Model: {model_base})\\nLength-Normed vs non-Normed Sentence Sentiment in Section #{Select_Section_No}')\n",
        "plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tag3LC8Y9Is"
      },
      "source": [
        "# Within the Selected_Section_No, compare Paragraph Sentiment\n",
        "#    Standardized MedianIQR vs Length-Normed Standardized MedianIQR\n",
        "\n",
        "sec_y_ht = 0\n",
        "\n",
        "paragraph_boundries_ls = list(section_sents_df['parag_no'].unique())\n",
        "for i, aparag_no in enumerate(paragraph_boundries_ls):\n",
        "  if i%5 == 0:\n",
        "    # Plot every 5th paragraph\n",
        "    sent_no = section_sents_df[section_sents_df['parag_no'] == aparag]['sent_no'].min()\n",
        "    plt.text(aparag_no, sec_y_ht, f'Paragraph #{aparag_no}', alpha=0.2, rotation=90)\n",
        "    plt.axvline(aparag_no, color='blue', alpha=0.1)\n",
        "\n",
        "plt.plot(model_name, data=section_parags_df, alpha=0.3, label=f'Length-Normed MedianIQR Paragraph Sentiment ({model_base})')\n",
        "plt.plot(col_medianiqr, data=section_parags_df, alpha=0.3, label=f'MedianIQR Paragraph Sentiment ({model_base})')\n",
        "plt.title(f'{CORPUS_FULL} (Model: {model_base})\\nLength-Normed vs non-Normed Paragraph Sentiment in Section #{Select_Section_No}')\n",
        "plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKJmDFQeH6gI"
      },
      "source": [
        "##### **LOWESS Smoothed**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhYnx-MgH_G0"
      },
      "source": [
        "model_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0bylmqBf7Js"
      },
      "source": [
        "# Within the Selected_Section_No, use Lowess Smoothing and SciPy find_peaks()\n",
        "#    to get Sentence Crux Points \n",
        "\n",
        "win_lowess_start = 20\n",
        "win_lowess_end = 50\n",
        "win_lowess_step = 10\n",
        "\n",
        "win_lowess_no = 10\n",
        "sec_y_ht = 0\n",
        "\n",
        "for win_lowess_no in range(win_lowess_start, win_lowess_end, win_lowess_step):\n",
        "  section_crux_ls = get_lowess_cruxes(ts_df=section_sents_df, col_series=model_name, text_type='sentence', win_lowess=win_lowess_no, sec_y_height=sec_y_ht, subtitle_str=f'win={win_lowess_no}', do_plot=True, save2file=False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DQ4zGtRizlM"
      },
      "source": [
        "# TODO: Only printing sentiment for first crux point\n",
        "\n",
        "section_sents_df.iloc[62]['sent_raw']\n",
        "print('\\n')\n",
        "section_sents_df.iloc[62]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4B0vm5RjgCLS"
      },
      "source": [
        "Get_Peak_Cruxes = True #@param {type:\"boolean\"}\n",
        "Get_n_Cruxes = 5 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "No_Paragraphs_on_Each_Side = 3 #@param {type:\"slider\", min:0, max:5, step:1}\n",
        "\n",
        "\n",
        "crux_sortsents_report(section_crux_ls, top_n=Get_n_Cruxes, get_peaks=Get_Peak_Cruxes, n_sideparags=No_Paragraphs_on_Each_Side)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa124qbuKzzH"
      },
      "source": [
        "# LOWESS Smoothed Sentences within chosen Selection No\n",
        "\n",
        "my_afrac = 1./12   # 1./12 ~ 0.08\n",
        "\n",
        "temp_df = get_lowess(section_sents_df, [model_name], plot_subtitle='LOWESS Smoothed MedianIRQ Sentence Sentiment', alabel=f'LOWESS (afrac={my_afrac})', \n",
        "                afrac=my_afrac, ait=7, alpha=0.8, do_plot=True, save2file=False)\n",
        "temp_df.columns\n",
        "col_lowess = f'{model_name}_{my_afrac:2.3f}lowess'\n",
        "col_lowess_clean = col_lowess.replace('_0.','_')\n",
        "section_sents_df[col_lowess_clean] = temp_df['median']\n",
        "\n",
        "plt.title(f'{CORPUS_FULL} (Model: {model_base})\\nRaw Sentence Sentiments with selected Section #{Select_Section_No} (LOWESS frac={my_afrac:.2f})')\n",
        "plt.xlabel(f'Sentence No within selected Section #{Select_Section_No}')\n",
        "plt.ylabel(f'Sentiment Value')\n",
        "plt.legend('',frameon=False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLeyWMtMaEqZ"
      },
      "source": [
        "# LOWESS Smoothed Paragraphs within chosen Selection No\n",
        "\n",
        "my_afrac = 1./8 # 1./8 ~ 0.125\n",
        "\n",
        "temp_df = get_lowess(section_parags_df, [model_name], plot_subtitle='LOWESS Smoothed Mean Rolling Sentence Sentiment', alabel=f'LOWESS Smoothed (afrac={my_afrac})', \n",
        "                afrac=my_afrac, ait=7, alpha=0.8, do_plot=True, save2file=False)\n",
        "\n",
        "section_parags_df[f'{model_name}_{my_afrac:.2f}_lowess'] = temp_df['median']\n",
        "\n",
        "plt.title(f'{CORPUS_FULL} (Model: {model_base})\\nRaw Sentence Sentiments with selected Section #{Select_Section_No} (LOWESS frac={my_afrac:.2f})')\n",
        "plt.xlabel(f'Paragraph No within selected Section #{Select_Section_No}')\n",
        "plt.ylabel(f'Sentiment Value')\n",
        "plt.legend('',frameon=False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GfIuHNNmu-H"
      },
      "source": [
        "section_sents_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEMWOxr7m2cl"
      },
      "source": [
        "section_crux_sents_dt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zouNSYD9Yloj"
      },
      "source": [
        "section_sents_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vVdmcTcYb40"
      },
      "source": [
        "model_name = 'sentimentr_lnorm_medianiqr'\n",
        "model_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJa85Yx-rkkx"
      },
      "source": [
        "!pip install hdbscan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGA7kXGjrNET"
      },
      "source": [
        "from hdbscan import HDBSCAN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZYo_LR8rF_J"
      },
      "source": [
        "\n",
        "\n",
        "y_ls = [1,2,4,7,9,5,4,7,9,56,57,54,60,200,297,275,243]\n",
        "y = np.reshape(y_ls, (-1, 1))\n",
        "type(y)\n",
        "y.shape\n",
        "\n",
        "clusterer = HDBSCAN(min_cluster_size=3)\n",
        "cluster_labels = clusterer.fit_predict(y)\n",
        "\n",
        "best_cluster = clusterer.exemplars_[cluster_labels[y.argmax()]].ravel()\n",
        "print(best_cluster)\n",
        "cluster_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsvTX-vtz8lq"
      },
      "source": [
        "type(y_ls)\n",
        "y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo2zOaWVtUsm"
      },
      "source": [
        "y = np.reshape(crux_points_x_ls, (-1,1))\n",
        "\n",
        "clusterer = HDBSCAN(min_cluster_size=3)\n",
        "cluster_labels = clusterer.fit_predict(y)\n",
        "\n",
        "best_cluster = clusterer.exemplars_[cluster_labels[y.argmax()]].ravel()\n",
        "print(best_cluster)\n",
        "cluster_labels\n",
        "print(f'HDBSCAN found {clusterer.labels_.max()} clusters.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBXI8l6ywagn"
      },
      "source": [
        "len(color_palette)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB5VL_sV0tAG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRoIWeY1vx8M"
      },
      "source": [
        "clusterer = hdbscan.HDBSCAN(min_cluster_size=3).fit(y)\n",
        "print(f'HDBSCAN found {clusterer.labels_.max()} clusters.')\n",
        "\n",
        "color_palette = sns.color_palette('deep', 9)\n",
        "cluster_colors = [color_palette[x] if x >= 0\n",
        "                  else (0.5, 0.5, 0.5)\n",
        "                  for x in cluster_labels]\n",
        "cluster_member_colors = [sns.desaturate(x, p) for x, p in\n",
        "                         zip(cluster_colors, clusterer.probabilities_)]\n",
        "x = np.zeros_like(y) + 12.5\n",
        "plt.scatter(*y.T, x, s=50, linewidth=0, c=cluster_member_colors, alpha=0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EN7Rpw7B0xu-"
      },
      "source": [
        "print(crux_points_ls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLafViJ2zxrQ"
      },
      "source": [
        "len(crux_points_ls)\n",
        "crux_points_np.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irX4QSEbtTiy"
      },
      "source": [
        "crux_points_np = np.reshape(crux_points_ls, (-1,1))\n",
        "# np.reshape(crux_points_x_ls, (-1,1))\n",
        "clusterer = hdbscan.HDBSCAN(min_cluster_size=3).fit(crux_points_np)\n",
        "print(f'HDBSCAN found {clusterer.labels_.max()} clusters.')\n",
        "\n",
        "color_palette = sns.color_palette('deep', 9)\n",
        "cluster_colors = [color_palette[x] if x >= 0\n",
        "                  else (0.5, 0.5, 0.5)\n",
        "                  for x in cluster_labels]\n",
        "cluster_member_colors = [sns.desaturate(x, p) for x, p in\n",
        "                         zip(cluster_colors, clusterer.probabilities_)]\n",
        "y_np = np.zeros_like(crux_points_np) + 12.5\n",
        "plt.scatter(*crux_points_np.T, y_np, s=50, linewidth=0, c=cluster_member_colors, alpha=0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NRZ0Auka-uG"
      },
      "source": [
        "section_crux_sents_dt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGDccDTMfMT4"
      },
      "source": [
        "# TODO: Convert to input widgets\n",
        "# grid_fracs = [1./3, 1./4, 1./6, 1./10, 1./14, 1./16]\n",
        "# grid_fracs = [1./10, 1./14, 1./16]\n",
        "# grid_fracs = [0.14, 0.16, 0.18, 0.2, 0.25, 0.3, 0.35, 0.4]\n",
        "# grid_fracs = [0.14, 0.16, 0.18, 0.2, 0.25, 0.3, 0.35, 0.4]\n",
        "grid_fracs = [0.1, 0.12, 0.14, 0.16, 0.18, 0.2, 0.3]\n",
        "win_lowess=9\n",
        "\n",
        "\n",
        "# section_sents_df['vader_lnorm_medianiqr'].plot(label=f'Raw Sentence Sentiments with selected Section #{Select_Section_No}')\n",
        "# plt.plot('vader_lnorm_medianiqr', data=section_sents_df)\n",
        "plt.title(f'LOWESS Smoothed Sentence Sentiments with selected Section #{Select_Section_No}')\n",
        "plt.xlabel(f'Sentence No within selected Section #{Select_Section_No}')\n",
        "plt.ylabel(f'Sentiment Value');\n",
        "\n",
        "section_crux_sents_dt = {}\n",
        "\n",
        "for afrac in grid_fracs:\n",
        "  # print(f'type(my_afrac) = {type(my_afrac)}, value = {my_afrac}')\n",
        "  #   _ = get_lowess(section_sents_df, ['vader_lnorm_medianiqr'], plot_subtitle='Naive Raw + MedianIQR Midpoints', alabel=f'LOWESS Smoothed (afrac={my_afrac})', \n",
        "  #                afrac=my_afrac, ait=7, alpha=my_afrac, do_plot=True, save2file=False);\n",
        "\n",
        "  # afrac = 1./7\n",
        "  # model_name = 'vader_lnorm_medianiqr' # model_name\n",
        "  sm_x, sm_y = sm_lowess(endog=section_sents_df[model_name].values, exog=section_sents_df.index.values, frac=afrac, it=3, return_sorted = True).T\n",
        "  col_lowess_frac = f'{model_name}_frac{int((afrac-int(afrac))*100)}_win{win_lowess}'\n",
        "  section_sents_df[col_lowess_frac] = sm_y\n",
        "  # _ = get_lowess(ts_df='section_sents_df', models_ls=[col_roll_str], text_unit='sentence', plot_subtitle='', alabel='', afrac=1./10, ait=5, alpha=0.5, do_plot=True, save2file=False)\n",
        "  section_crux_ls = list(get_lowess_cruxes(section_sents_df, col_series=col_lowess_frac, win_lowess=win_lowess, do_plot=False))\n",
        "  # col_lowess_frac = f'{model_name}_frac{int((afrac-int(afrac))*100)}_win{win_lowess}'\n",
        "  # print(f\"col_lowess_frac: {col_lowess_frac}\")\n",
        "  section_crux_sents_dt[col_lowess_frac] = section_crux_ls # list(zip(sm_x, sm_y))\n",
        "  # x, y = zip(*data)\n",
        "\n",
        "  # Set vertical y-axis magnification\n",
        "  y_mag = 30\n",
        "  plt.plot(sm_x, y_mag*sm_y)\n",
        "  plt.title(f'{CORPUS_FULL} (Model: {model_base})\\nDifferent LOWESS Smoothed SMA Sentence Sentiments and Crux Points within selected Section #{Select_Section_No}')\n",
        "  plt.legend(loc='best')\n",
        "\n",
        "\n",
        "# Plot Crux Points for all LOWESS Curves on the x-axis\n",
        "crux_points_ls = []\n",
        "for key,value in section_crux_sents_dt.items():\n",
        "  model_lowess_name = key\n",
        "  crux_points_ls.extend(value)\n",
        "  plt.scatter(*zip(*value))\n",
        "\n",
        "# Plot Automatic HDBSCAN Clusters of Crux Points\n",
        "crux_points_np = np.reshape(crux_points_ls, (-1, 1))\n",
        "clusterer = hdbscan.HDBSCAN(min_cluster_size=3).fit(crux_points_np)\n",
        "print(f'HDBSCAN found {clusterer.labels_.max()} clusters.')\n",
        "\n",
        "color_palette = sns.color_palette('deep', 9)\n",
        "cluster_colors = [color_palette[x] if x >= 0\n",
        "                  else (0.5, 0.5, 0.5)\n",
        "                  for x in cluster_labels]\n",
        "cluster_member_colors = [sns.desaturate(x, p) for x, p in\n",
        "                         zip(cluster_colors, clusterer.probabilities_)]\n",
        "y_np = np.zeros_like(crux_points_np) + 12.5\n",
        "plt.scatter(*crux_points_np.T, y_np, s=50, linewidth=0, c=cluster_member_colors, alpha=0.25)\n",
        "\n",
        "plt.title(f'{CORPUS_FULL} Sentence Crux Detection within selected Section #{Select_Section_No}\\nLOWESS Smoothed (Model: {model_lowess_name})')\n",
        "plt.xlabel(f'Sentence No within selected Section #{Select_Section_No}')\n",
        "plt.ylabel(f'Sentiment Value')\n",
        "plt.legend(loc='best');\n",
        "\n",
        "\n",
        "# Plot the mean of all SMA MedianIQR Sentiment Time Series\n",
        "# col_meanroll = f'{model_name}_rollmean'\n",
        "# section_sents_df[col_meanroll] = section_sents_df[col_rolls_ls].mean(axis=1)\n",
        "# section_sents_df[col_meanroll].plot(label='mean', color='black', linewidth=3)\n",
        "\n",
        "# Plot corresponding Crux Points\n",
        "# model_name = 'vader_lnorm_medianiqr'\n",
        "section_crux_ls = get_lowess_cruxes(section_sents_df, col_series=model_name, win_lowess=10, do_plot=False) # 'vader_lnorm_medianiqr_0.07_lowess')\n",
        "section_sents_df.shape[0]\n",
        "print('\\n');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDx21JbaeL9s"
      },
      "source": [
        "!pip install kmeans1d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFPbi6WqQVUs"
      },
      "source": [
        "%whos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPcTifCyeUJh"
      },
      "source": [
        "import kmeans1d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN4M4LEAeoCa"
      },
      "source": [
        "crux_points_x_ls = [x[0] for x in crux_points_ls]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Htu7N02odHaU"
      },
      "source": [
        "**Enter how many Clusters of potential Crux Points you see in the Plot above**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBSVG9LXa2FD"
      },
      "source": [
        "Cluster_Count = 5 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "clusters, centroids = kmeans1d.cluster(crux_points_x_ls, Cluster_Count)\n",
        "\n",
        "print(clusters)  \n",
        "print(centroids)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVCq0YUXBpX8"
      },
      "source": [
        "# TODO: Convert to input widgets\n",
        "# grid_fracs = [1./3, 1./4, 1./6, 1./10]\n",
        "# grid_fracs = [0.14, 0.16, 0.18, 0.2, 0.25, 0.3, 0.35, 0.4]\n",
        "grid_fracs = [0.1, 0.12, 0.14, 0.16, 0.18, 0.2]\n",
        "\n",
        "# section_sents_df['vader_lnorm_medianiqr'].plot(label=f'Raw Sentence Sentiments with selected Section #{Select_Section_No}')\n",
        "# plt.plot('vader_lnorm_medianiqr', data=section_sents_df)\n",
        "plt.title(f'{CORPUS_FULL} (Model: {model_base})\\nLOWESS Smoothed Sentence Sentiments with selected Section #{Select_Section_No}')\n",
        "plt.xlabel(f'Sentence No within selected Section #{Select_Section_No}')\n",
        "plt.ylabel(f'Sentiment Value');\n",
        "\n",
        "for my_afrac in grid_fracs:\n",
        "  # print(f'type(my_afrac) = {type(my_afrac)}, value = {my_afrac}')\n",
        "  _ = get_lowess(section_sents_df, [model_name], plot_subtitle='Naive Raw + MedianIQR Midpoints', alabel=f'LOWESS (afrac={my_afrac})', \n",
        "                 afrac=my_afrac, ait=7, alpha=my_afrac, do_plot=True, save2file=False);\n",
        "\n",
        "  # corpus_cruxes_dt['vader_lnorm_medianiqr'] = plot_crux_sections(model_names_ls=['vader_lnorm_medianiqr'], semantic_type='section', label_token_ct=5, title_xpos=0.8, title_ypos=1.05, save2file=False)\n",
        "plt.title(f'{CORPUS_FULL}\\n LOWESS Smoothed Sentence Sentiments with selected Section #{Select_Section_No}')\n",
        "plt.xlabel(f'Sentence No within selected Section #{Select_Section_No}')\n",
        "plt.ylabel(f'Sentiment Value');\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpzOnRqZS3jZ"
      },
      "source": [
        "# TODO: Convert to input widgets\n",
        "# grid_fracs = [1./3, 1./4, 1./6, 1./10]\n",
        "# grid_fracs = [0.14, 0.16, 0.18, 0.2, 0.25, 0.3, 0.35, 0.4]\n",
        "grid_fracs = [0.12, 0.14, 0.16, 0.18, 0.2]\n",
        "\n",
        "# section_sents_df[model_name].plot(label=f'Raw Sentence Sentiments with selected Section #{Select_Section_No}')\n",
        "# plt.plot(model_name, data=section_sents_df)\n",
        "plt.title(f'{CORPUS_FULL} (Model: {model_base})\\nLOWESS Smoothed Paragraph Sentiments with selected Section #{Select_Section_No}')\n",
        "plt.xlabel(f'Paragraph No within selected Section #{Select_Section_No}')\n",
        "plt.ylabel(f'Sentiment Value');\n",
        "\n",
        "for my_afrac in grid_fracs:\n",
        "  # print(f'type(my_afrac) = {type(my_afrac)}, value = {my_afrac}')\n",
        "  _ = get_lowess(section_parags_df, [model_name], plot_subtitle='MedianIQR Midpoints', alabel=f'LOWESS (afrac={my_afrac})', \n",
        "                 afrac=my_afrac, ait=7, alpha=my_afrac, do_plot=True, save2file=False);\n",
        "\n",
        "  # corpus_cruxes_dt[model_name] = plot_crux_sections(model_names_ls=[model_name], semantic_type='section', label_token_ct=5, title_xpos=0.8, title_ypos=1.05, save2file=False)\n",
        "plt.title(f'{CORPUS_FULL}\\n LOWESS Smoothed Paragraph Sentiments with selected Section #{Select_Section_No}')\n",
        "plt.xlabel(f'Paragraph No within selected Section #{Select_Section_No}')\n",
        "plt.ylabel(f'Sentiment Value');\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O85J51__Ka-z"
      },
      "source": [
        "section_sents_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48u_zr6-KkH-"
      },
      "source": [
        "# SMA Sentences\n",
        "\n",
        "# grid_afracs = [0.14, 0.16, 0.18, 0.2, 0.25, 0.3, 0.35, 0.4]\n",
        "grid_fracs = [0.1, 0.12, 0.14, 0.16, 0.18, 0.2, 0.3]\n",
        "# grid_fracs = [1./6, 1./7, 1./8, 1./9, 1./10, 1./15, 1./20]\n",
        "scale_roll = 1.\n",
        "win_lowess_per = 30\n",
        "win_lowess = int(win_lowess/100 * section_sents_df.shape[0])\n",
        "\n",
        "col_meanroll_lowess_ls = []\n",
        "\n",
        "col_meanroll = f'{model_name}_mean_roll050'\n",
        "for afrac in grid_fracs:\n",
        "  lowess_smooth_df = get_lowess(section_sents_df, [col_meanroll], plot_subtitle='SMA Mean of MedianIQR ', alabel=f'LOWESS afrac={afrac:.3f}', \n",
        "                afrac=afrac, ait=7, alpha=0.3, do_plot=True, save2file=False)\n",
        "  # print(f'type: {lowess_smooth_df.columns}')\n",
        "\n",
        "# col_lowess_str = f'{col_mean_roll}_lowess_frac{10*win_lowess}'\n",
        "col_meanroll_lowess_str = f'{col_meanroll}_frac{int((afrac-int(afrac))*100)}_win{win_lowess}'\n",
        "col_meanroll_lowess_ls.append(col_meanroll_lowess_str)\n",
        "section_sents_df[col_meanroll_lowess_str] = section_sents_df[model_name].apply(lambda x: x*scale_roll).rolling(win_lowess, center=True).mean()\n",
        "section_sents_df[col_meanroll_lowess_str].plot(alpha=0.7)\n",
        "get_lowess(section_sents_df, [col_meanroll_lowess_str], plot_subtitle='SMA Mean of MedianIQR ', alabel=f'LOWESS (afrac={my_afrac:.3f})', \n",
        "                afrac=afrac, ait=7, alpha=1.0, do_plot=True, save2file=False);\n",
        "\n",
        "\n",
        "plt.title(f'{CORPUS_FULL} (Model: {model_base})\\nLOWESS Smoothed Sentence Sentiments with selected Section #{Select_Section_No}')\n",
        "plt.xlabel(f'Sentence No within selected Section #{Select_Section_No}')\n",
        "plt.ylabel(f'Sentiment Value')\n",
        "plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KlWvNkcMI-M"
      },
      "source": [
        "**Raw Paragraph Sentiment Plot within selected Section**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhRcTp4ALYUQ"
      },
      "source": [
        "# TODO: Convert to input widgets\n",
        "win_sents_ls = [5,10,15,20,25]\n",
        "scale_roll = 6\n",
        "\n",
        "plt.plot(model_name, data=section_parags_df, alpha=0.3, label=f'Raw Paragraph Sentiment within selected Segment #{Select_Section_No}')\n",
        "\n",
        "plt.title(f'{CORPUS_FULL} (Model: {model_base})\\nRaw Paragraph Sentiments with selected Section #{Select_Section_No}')\n",
        "plt.xlabel(f'Paragraph No within selected Section #{Select_Section_No}')\n",
        "plt.ylabel(f'Sentiment Value');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5TcmNEsMMiE"
      },
      "source": [
        "**Length-Normed Paragraph Sentiment Plot within selected Section**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BemEIw0Tknk"
      },
      "source": [
        "corpus_parags_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyRTfn6HI50X"
      },
      "source": [
        "# Plot and Compare Naive Raw and LOWESS Smoothed Paragraph Sentiment Time Series within selected Section\n",
        "\n",
        "section_parag_lowess_df = pd.DataFrame()\n",
        "section_parag_lowess_df['parag_no'] = section_parags_df['parag_no'].copy()\n",
        "\n",
        "parags_midpoint_sentiment_ls = []\n",
        "for parags_midpoint_idx in parags_midpoint_ls:\n",
        "  parags_midpoint_sentiment_ls.append(float(corpus_parags_df[corpus_parags_df['parag_no'] == parags_midpoint_idx][model_name]))\n",
        "\n",
        "col_midapprox = f'{model_name}_midapprox'\n",
        "section_parag_lowess_df[col_midapprox] = parags_midpoint_sentiment_ls\n",
        "\n",
        "\n",
        "section_parag_lowess_df[col_midapprox].plot(label='Raw Midpoints')\n",
        "plt.xlabel(f'Niave Paragraph No within selected Section #{Select_Section_No}')\n",
        "plt.ylabel(f'Sentiment Value')\n",
        "\n",
        "_ = get_lowess(section_parag_lowess_df, [col_midapprox], plot_subtitle=f'{model_base.capitalize()} Naive Raw + MedianIQR Midpoints', alabel='LOWESS Midpoints', afrac=1./4, ait=7, do_plot=True, save2file=False);\n",
        "\n",
        "# section_lowess_parags_df = get_lowess(section_sents_parags_df, ['vader_lnorm_medianiqr'], plot_subtitle='Approximate Paragraph MedianIQR', afrac=1./4, ait=7, do_plot=True, save2file=False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24M7uauXygFc"
      },
      "source": [
        "**Length-Noramlized Raw and LOWESS Smoothed Paragraph Sentiment plots within selected Section**\n",
        "\n",
        "NOTE: Horizonal x-axis narrative time axis adjusted for variable paragraph lengths - used midpoints of unequal length Paragraphs to more accurately visualize Sentiment Arc and precisely localize Crux Points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOsXfELh-tt_"
      },
      "source": [
        "# Verify details on currently selected Section\n",
        "print(f'Details on Section #{Select_Section_No}')\n",
        "print('------------------------')\n",
        "print(f' Paragraph Count: {section_parags_df.shape[0]}')\n",
        "print(f' Sentence Count:  {section_sents_df.shape[0]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfQS_qAo-Qdh"
      },
      "source": [
        "# %load_ext google.colab.data_table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq2JjzKIHEdO"
      },
      "source": [
        "# Plot Raw and Rolling Sentence Sentiments within selected Section\n",
        "\n",
        "win_per = 5  # Rolling Window size in percentage of total Corpus length\n",
        "\n",
        "section_sents_parags_df.plot(x='sent_no', y='vader_lnorm_medianiqr')\n",
        "\n",
        "plt.title(f'Raw and Rolling Sentence Sentiments within selected Section #{Select_Section_No}')\n",
        "plt.xlabel(f'Sentence No within selected Section #{Select_Section_No} (Length-Normalized in terms of Paragraphs)')\n",
        "plt.ylabel(f'Sentiment Value')\n",
        "\n",
        "section_sents_parags_df['vader_lnorm_medianiqr'].rolling(int((win_per/100)*section_sents_parags_df.shape[0])).mean().plot(label=\"Approx Paragraph VADER SMA (win=5%)\");\n",
        "\n",
        "# section_sents_parags_df.plot(x='sent_no', y='vader_lnorm_medianiqr', label='Sentence VADER MedianIQR')\n",
        "# section_sents_parags_df['vader_lnorm_medianiqr'].rolling(int(0.05*section_sents_parags_df.shape[0])).mean().plot(label=\"Sentence VADER SMA (win=5%)\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laYb3dm101Qa"
      },
      "source": [
        "**Get Crux Points within selected Section**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Select [Get_Peaks] to search for Peaks (unselect to search for Valley)\n",
        "\n",
        "* Pick [Crux_Rank] (1-5) to get the 1st to 5th biggest Peak or Valley Crux Paragraph\n",
        "\n",
        "* Pick [Context_Paragraphs_Each_Side] (0-5) to get n paragraphs before and n paragraphs after the selected Crux Paragraph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyekwnvX4wkj"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "# ARCHIVED\n",
        "\n",
        "def get_sentnocontext(ts_df, model_name='vader', get_peaks=True, crux_rank=1, n_sideparags=1):\n",
        "  # get_cruxparags_section()\n",
        "  '''\n",
        "  Given a Section DataFrame with model_name sentiment column and crux peak/valley, rank and side paragraphs context\n",
        "  Return a list with the appropriate Crux Paragraph within this Section, and context\n",
        "  '''\n",
        "\n",
        "  '''\n",
        "  Given a sentence number in the Corpus\n",
        "  Return the containing paragraph and n-paragraphs on either side\n",
        "  (e.g. if n=2, return 2+1+2=5 paragraphs)\n",
        "  '''\n",
        "\n",
        "  crux_parags_context_ls = []\n",
        "\n",
        "  if get_peaks == True:\n",
        "    sort_asc_flag=False\n",
        "  else:\n",
        "    sort_asc_flag=True\n",
        "\n",
        "  crux_parag_no = ts_df.sort_values(by=[model_name], ascending=sort_asc_flag).iloc[crux_rank-1]['parag_no']\n",
        "\n",
        "  print(f'crux_parag_no: {crux_parag_no}')\n",
        "\n",
        "  if n_sideparags == 0:\n",
        "    crux_parags_context_ls = list(corpus_parags_df[corpus_parags_df['parag_no'] == crux_parag_no]['parag_raw'])\n",
        "\n",
        "  else:\n",
        "    parag_start = crux_parag_no - n_sideparags\n",
        "    parag_end = crux_parag_no + n_sideparags + 1\n",
        "    crux_parags_context_ls = list(corpus_parags_df.iloc[parag_start:parag_end]['parag_raw'])\n",
        "\n",
        "  return crux_parags_context_ls\n",
        "\n",
        "# Test\n",
        "parags_context_ls = get_sentnocontext(ts_df=section_parags_df, model_name='vader_lnorm_medianiqr', get_peaks=True, crux_rank=1, n_sideparags=1)\n",
        "parags_context_ls\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxeabYXf2iqB"
      },
      "source": [
        "# def get_crux_parags_report(ts_df, model_name='vader', get_peaks=True, crux_rank=1, the_n_sideparags=No_Paragraphs_on_Each_Side, the_sent_highlight=Highlight_Crux_Sentence):\n",
        "\n",
        "# def get_sentnocontext_report(ts_df, model_name='vader', get_peaks=True, crux_rank=1, the_n_sideparags=No_Paragraphs_on_Each_Side, the_sent_highlight=Highlight_Crux_Sentence):\n",
        "'''\n",
        "Given a DataFrame with model_name sentiment column and crux peak/valley, rank and side paragraphs context\n",
        "Return a list with the appropriate Crux Paragraph, and context\n",
        "'''\n",
        "\"\"\"\n",
        "\n",
        "def get_sentnocontext_report(the_sent_no=7, the_n_sideparags=1, the_sent_highlight=True):\n",
        "  '''\n",
        "  Wrapper function around  get_sentnocontext()\n",
        "  Prints a nicely formatted context report\n",
        "  '''\n",
        "\n",
        "  context_noparags = the_n_sideparags*2+1\n",
        "\n",
        "  print('-------------------------------------------------------------')\n",
        "  print(f'The {context_noparags} Paragraph(s) Context around the Sentence #{Crux_Sentence_No} Crux Point:')\n",
        "  print('-------------------------------------------------------------')\n",
        "  print(f\"\\nCrux Sentence Raw Text: -------------------------------\\n\\n    {corpus_sents_df[corpus_sents_df['sent_no'] == the_sent_no]['sent_raw']}\") # iloc[the_sent_no]['sent_raw']}\")\n",
        "\n",
        "  print(f\"\\n{context_noparags} Paragraph(s) Context: ------------------------------\")\n",
        "  # context_parags_ls = get_sentnocontext(sent_no=the_sent_no, n_sideparags=the_n_sideparags, sent_highlight=the_sent_highlight)\n",
        "  context_parags_ls = get_sentnocontext(sent_no=the_sent_no, n_sideparags=the_n_sideparags, sent_highlight=the_sent_highlight)\n",
        "  context_len = len(context_parags_ls)\n",
        "  context_mid = context_len//2\n",
        "  for i, aparag in enumerate(context_parags_ls):\n",
        "    if i==context_mid:\n",
        "      # print(f'\\n>>> Paragraph #{i}: <<< Crux Point Sentence CAPITALIZED within this Paragraph\\n\\n    {aparag}')\n",
        "      print(f'\\n<*> {aparag}')\n",
        "    else:\n",
        "      # print(f'\\n    Paragraph #{i}:\\n\\n    {aparag}')\n",
        "      print(f'\\n    {aparag}')\n",
        "\n",
        "  return\n",
        "\n",
        "# Test\n",
        "# get_sentnocontext_report(sent_no=1051, n_sideparags=1, sent_highlight=True)\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxQGzYhgHEUD"
      },
      "source": [
        "# Get_Peaks = True #@param {type:\"boolean\"}\n",
        "Crux_Rank = 2 #@param {type:\"slider\", min:1, max:5, step:1}\n",
        "No_Paragraphs_on_Each_Side = 2 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "Highlight_Crux_Sentence = True #@param {type:\"boolean\"}\n",
        "\n",
        "# try:\n",
        "  \n",
        "# get_sentnocontext_report(ts_df=section_sents_df, model_name=model_name, get_peaks=Get_Peaks, crux_rank=Crux_Rank, the_n_sideparags=No_Paragraphs_on_Each_Side, the_sent_highlight=Highlight_Crux_Sentence)\n",
        "get_sentnocontext_report(corpus_sents_df, the_sent_no=Crux_Rank, the_n_sideparags=No_Paragraphs_on_Each_Side, the_sent_highlight=Highlight_Crux_Sentence)\n",
        "\n",
        "# except:\n",
        "#   print('ERROR')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cPnJ7-QAHBp"
      },
      "source": [
        "section_parags_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ga65SGcg5sM9"
      },
      "source": [
        "print(section_parags_df.sort_values(by=['vader_lnorm_medianiqr'], ascending=False).iloc[0]) # ['parag_no'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGuFadpM8QoB"
      },
      "source": [
        "parags_context_ls = get_cruxparag_context(ts_df=section_sents_parags_df, model_name='vader_lnorm_medianiqr', get_peaks=True, crux_rank=1, n_sideparags=2, sent_highlight=True)\n",
        "parags_context_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPE_ODwK2imT"
      },
      "source": [
        "section_sents_parags_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gz8UImlq5Uy"
      },
      "source": [
        "# **Save Crux Points and Contexts**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NH8ltVX9SvD"
      },
      "source": [
        "## **Section, Chapter Crux DataFrames (summary stats/sentiments only)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ovjd7uvr2hS8"
      },
      "source": [
        "corpus_chaps_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLb7mQgV7_JK"
      },
      "source": [
        "# Create a Chapter Summary DataFrame extracting only key information (no text)\n",
        "\n",
        "corpus_chaps_summary_df = corpus_chaps_df[['chap_no','sent_no_start','sent_no_mid','char_len','token_len',\n",
        "                 'sentimentr','sentimentr_medianiqr','sentimentr_lnorm_medianiqr',\n",
        "                 'syuzhet','sentimentr_medianiqr','sentimentr_lnorm_medianiqr',\n",
        "                 'bing','sentimentr_medianiqr','sentimentr_lnorm_medianiqr',\n",
        "                 'sentiword','sentimentr_medianiqr','sentimentr_lnorm_medianiqr',\n",
        "                 'senticnet','sentimentr_medianiqr','sentimentr_lnorm_medianiqr',\n",
        "                 'nrc','sentimentr_medianiqr','sentimentr_lnorm_medianiqr',\n",
        "                 'afinn','sentimentr_medianiqr','sentimentr_lnorm_medianiqr',\n",
        "                 'vader','sentimentr_medianiqr','sentimentr_lnorm_medianiqr',\n",
        "                 'textblob','sentimentr_medianiqr','sentimentr_lnorm_medianiqr',\n",
        "                 'pattern','sentimentr_medianiqr','sentimentr_lnorm_medianiqr',\n",
        "                 'stanza','sentimentr_medianiqr','sentimentr_lnorm_medianiqr',\n",
        "                 ]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSvXSwp-2ePp"
      },
      "source": [
        "corpus_sects_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5s8R38P81M7"
      },
      "source": [
        "# Create a Section Summary DataFrame extracting only key information (no text)\n",
        "\n",
        "corpus_sects_summary_df = corpus_sects_df[['sect_no','sent_no_start','sent_no_mid','char_len','token_len',\n",
        "                 'sentimentr','sentimentr_medianiqr','sentimentr_lnorm_medianiqr',\n",
        "                 'syuzhet','sentimentr_medianiqr','sentimentr_lnorm_medianiqr',\n",
        "                 'bing','sentimentr_medianiqr','sentimentr_lnorm_medianiqr',\n",
        "                 'sentiword','sentimentr_medianiqr','sentimentr_lnorm_medianiqr',\n",
        "                 'senticnet','sentimentr_medianiqr','sentimentr_lnorm_medianiqr',\n",
        "                 'nrc','sentimentr_medianiqr','sentimentr_lnorm_medianiqr',\n",
        "                 'afinn','sentimentr_medianiqr','sentimentr_lnorm_medianiqr',\n",
        "                 'vader','sentimentr_medianiqr','sentimentr_lnorm_medianiqr',\n",
        "                 'textblob','sentimentr_medianiqr','sentimentr_lnorm_medianiqr',\n",
        "                 'pattern','sentimentr_medianiqr','sentimentr_lnorm_medianiqr',\n",
        "                 'stanza','sentimentr_medianiqr','sentimentr_lnorm_medianiqr',\n",
        "                 ]]\n",
        "\n",
        "corpus_sects_summary_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2Op-IgH9iP2"
      },
      "source": [
        "# Save the original Corpus text at 4 levels of semantic grouping: sentences, paragraphs, sections and chapters\n",
        "\n",
        "# Save Section and Chapter DataFrames Metainformation (e.g. sent_no_start) and Sentiment Values\n",
        "corpus_sects_summary_filename = f'corpus_section_summary_lexrules_{author_abbr_str}_{title_str}.csv' # _{datetime_now}.csv'\n",
        "print(f'Saving Corpus Section Summary to file: {corpus_sects_summary_filename}')\n",
        "corpus_sects_summary_df.to_csv(corpus_sects_summary_filename)\n",
        "\n",
        "corpus_chaps_summary_filename = f'corpus_chapter_summary_lexrules_{author_abbr_str}_{title_str}.csv' # _{datetime_now}.csv'\n",
        "print(f'Saving Corpus Chapters Summary to file: {corpus_chaps_summary_filename}')\n",
        "corpus_chaps_summary_df.to_csv(corpus_chaps_summary_filename)\n",
        "\n",
        "# Save Corpus Cruxes Dictionary is saved to a JSON file\n",
        "corpus_cruxes_summary_filename = f'corpus_cruxes_summary_lexrules_{author_abbr_str}_{title_str}.json' # _{datetime_now}.csv'\n",
        "print(f'Saving Corpus Cruxes Summary to file: {corpus_cruxes_summary_filename}')\n",
        "with open(corpus_cruxes_summary_filename, 'w') as convert_file:\n",
        "  convert_file.write(json.dumps(corpus_cruxes_dt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSO0vT7oXOXO"
      },
      "source": [
        "# Verify exported Section Summary file\n",
        "\n",
        "!head -n 5 $corpus_sects_summary_filename\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3RIJOdsI_Ud"
      },
      "source": [
        "%whos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0A0M6TPu_Ml"
      },
      "source": [
        "## **Compare Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpX60Cld_B7z"
      },
      "source": [
        "def drop_dupcols(df):\n",
        "  '''\n",
        "  Given a DataFrame\n",
        "  Drop repeatitive columns\n",
        "  '''\n",
        "\n",
        "  col_drop_ls = []\n",
        "\n",
        "  col_ls = list(df.columns)\n",
        "  print(f'BEFORE: Columns #{len(df.columns)}')\n",
        "\n",
        "  for i, acol in enumerate(col_ls):\n",
        "    acol_word_ls = acol.split('_')\n",
        "    # print(f'acol_word_ls: {acol_word_ls}')\n",
        "    if (len(acol_word_ls)) == len(set(acol_word_ls)):\n",
        "      continue\n",
        "    else:\n",
        "      col_drop_ls.append(acol)\n",
        "\n",
        "  df.drop(columns=col_drop_ls, inplace=True, axis=1)\n",
        "\n",
        "  print(f'AFTER: Columns #{len(df.columns)}')\n",
        "\n",
        "  return col_drop_ls\n",
        "\n",
        "dropped_cols_ls = drop_dupcols(corpus_parags_df)\n",
        "print(f'dropped: {dropped_cols_ls}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIOFkFzYinfd"
      },
      "source": [
        "corpus_parags_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lpvN8PR9VRk"
      },
      "source": [
        "# List of Tuples (Model, Scaling Factor) to plot together with same size for comparison\n",
        "\n",
        "models_sma_ls = [('vader_lnorm_medianiqr',1),\n",
        "                 ('textblob_lnorm_medianiqr',20),\n",
        "                 ('afinn_lnorm_medianiqr',4),\n",
        "                 ('sentimentr_lnorm_medianiqr',1),\n",
        "                 ('syuzhet_lnorm_medianiqr',1),\n",
        "                 ('bing_lnorm_medianiqr',0.1),\n",
        "                 ('sentiword_lnorm_medianiqr',10),\n",
        "                 ('senticnet_lnorm_medianiqr',.5),\n",
        "                 ('nrc_lnorm_medianiqr',0.2),\n",
        "                 ('pattern_lnorm_medianiqr',20),\n",
        "                 ('stanza_lnorm_medianiqr',0.5),\n",
        "                 ('hfbert_lnorm_medianiqr',5),\n",
        "                 ('nlptown_lnorm_medianiqr',5),\n",
        "                 ('robertalg15_lnorm_medianiqr',5)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1pjqF9nTQg-"
      },
      "source": [
        "# List of Tuples (Model, Scaling Factor) to plot together with same size for comparison\n",
        "\n",
        "models_sma_ls = [('vader',1),\n",
        "                 ('textblob',20),\n",
        "                 ('afinn',4),\n",
        "                 ('sentimentr',1),\n",
        "                 ('syuzhet',1),\n",
        "                 ('bing',0.1),\n",
        "                 ('sentiword',10),\n",
        "                 ('senticnet',.5),\n",
        "                 ('nrc',0.2),\n",
        "                 ('pattern',20),\n",
        "                 ('stanza',0.5),\n",
        "                 ('hfbert',5),\n",
        "                 ('nlptown',5),\n",
        "                 ('robertalg15',5)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RihyT4wZFP5k"
      },
      "source": [
        "corpus_sents_df[['stanza_lnorm_medianiqr','stanza']].rolling(500,center=True).mean().plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaxzZkVlBcNf"
      },
      "source": [
        "def plot_autoscaled_ts(ts_df=corpus_sents_df, ts_ls=['vader_lnorm_medianiqr', 'textblob_lnorm_medianiqr', \n",
        "                                                     'syuzhet_lnorm_medianiqr', 'sentimentr_lnorm_medianiqr',\n",
        "                                                     'bing_lnorm_medianiqr', 'afinn_lnorm_medianiqr',\n",
        "                                                     'pattern_lnorm_medianiqr', 'stanza_lnorm_medianiqr']):\n",
        "  '''\n",
        "  Given a DataFrame and list of Columns/Time Series\n",
        "  Automatically scale all to the same range and plot together\n",
        "  '''\n",
        "\n",
        "  ts_spans_ls = []\n",
        "\n",
        "  current_min = ts_df[ts_ls[0]].min()\n",
        "  current_max = ts_df[ts_ls[0]].max()\n",
        "  ts_spans_ls.append(float(current_max - current_min))\n",
        "\n",
        "  for ats in ts_ls[1:]:\n",
        "    current_min = ts_df[ats].min()\n",
        "    current_max = ts_df[ats].max()\n",
        "    ts_spans_ls.append(float(current_max - current_min))\n",
        "\n",
        "  # find index of maximum span\n",
        "  max_index = ts_spans_ls.index(max(ts_spans_ls))\n",
        "  max_span_value = ts_spans_ls[max_index]\n",
        "  max_span_model = ts_ls[max_index]\n",
        "  print(f'max span is: {max_span_value} from {max_span_model}')\n",
        "\n",
        "  for i, ats in enumerate(ts_ls):\n",
        "    y_scaling_factor = max_span_value/ts_spans_ls[i]\n",
        "    print(f'ats={ats} with scaling={y_scaling_factor}')\n",
        "    ts_y_scaled_ser = ts_df[ats].apply(lambda x: x*y_scaling_factor)\n",
        "    # plt.plot()\n",
        "    plot_df = pd.DataFrame()\n",
        "    plot_df['x_value'] = ts_df.index\n",
        "    plot_df['y_scaled'] = ts_y_scaled_ser\n",
        "    plot_df['y_scaled_roll050'] = plot_df['y_scaled'].rolling(350, center=True).mean()\n",
        "    plot_df['y_scaled_roll050'].plot(label=f'{ats}')\n",
        "    plt.legend(loc='best')\n",
        "    # sns.lineplot(data=plot_df, x='x_value', y='y_scaled', alpha=0.5, label=f'{ats}')\n",
        "\n",
        "  return ts_spans_ls, ts_ls\n",
        "\n",
        "# Test\n",
        "ts_spans_ls, ts_ls = plot_autoscaled_ts()\n",
        "zip_ls = zip(ts_spans_ls, ts_ls)\n",
        "for aspan, amodel in zip_ls:\n",
        "  print(f'model: {amodel} with span: {aspan}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emkaDWvDILDc"
      },
      "source": [
        "ts_df=corpus_sents_df, ts_ls=['vader_lnorm_medianiqr', 'textblob_lnorm_medianiqr', \n",
        "                                                     'syuzhet_lnorm_medianiqr', 'sentimentr_lnorm_medianiqr',\n",
        "                                                     'bing_lnorm_medianiqr', 'afinn_lnorm_medianiqr',\n",
        "                                                     'pattern_lnorm_medianiqr', 'stanza_lnorm_medianiqr']):"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9T8pf6DsIGmq"
      },
      "source": [
        "# Test\n",
        "ts_spans_ls, ts_ls = plot_autoscaled_ts(ts_df=corpus_parags_df)\n",
        "zip_ls = zip(ts_spans_ls, ts_ls)\n",
        "for aspan, amodel in zip_ls:\n",
        "  print(f'model: {amodel} with span: {aspan}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWGdzLS4Ibr-"
      },
      "source": [
        "corpus_sents_df['pattern_lnorm_medianiqr'].hist(bins=100) # rolling(100, center=True).mean().plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42RrUksBOxfo"
      },
      "source": [
        "models_sma_ls = [('vader_lnorm_medianiqr',1),\n",
        "                 ('textblob_lnorm_medianiqr',20),\n",
        "                 ('sentimentr_lnorm_medianiqr',1),\n",
        "                 ('syuzhet_lnorm_medianiqr',1),\n",
        "                 ('stanza_lnorm_medianiqr',0.2)]\n",
        "\n",
        "win_per = 5  # 5=5% of full corpus length\n",
        "win_roll = int(corpus_sents_df.shape[0]* win_per/100)\n",
        "\n",
        "for amodel, amag in models_sma_ls:\n",
        "  corpus_parags_df[amodel].rolling(win_roll, center=True).mean().apply(lambda x: amag*x).plot(linewidth=4, label=amodel)\n",
        "plt.legend(loc='best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuQgdwsJGZN_"
      },
      "source": [
        "# **END OF NOTEBOOK**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpOCp1-88rrF"
      },
      "source": [
        "# **Standardize and Remove Outliers (Auto)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mul5MSZrgKsw"
      },
      "source": [
        "## **Remove Outliers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07hyJuT1c5rJ"
      },
      "source": [
        "### **Before Removing Outliers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKX8f0Q1I53M"
      },
      "source": [
        "for model_name in MODELS_LS:\n",
        "  print(f'Plotting {model_name}')\n",
        "  sns.lineplot(data=corpus_sents_df, x='sent_no', y=model_name, alpha=0.3, legend='brief', label=model_name)\n",
        "      \n",
        "plt.title(f'{CORPUS_FULL} (Model: {model_name}) \\nRaw Sentence Sentiment Plot')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzUoTpEWeyCy"
      },
      "source": [
        "# sns.lineplot(data=corpus_sents_df, x='sent_no', y='y_scaled', legend='brief', label='y_scaled')\n",
        "      \n",
        "# plt.title(f'{CORPUS_FULL} (Model: {model_name}) \\nSMA Smoothed Sentence Sentiment Plot (windows={win_ls})')\n",
        "# plt.legend(loc='best')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr1k-3Rsc5XL"
      },
      "source": [
        "# Plot all Raw Sentence Sentiment Arcs\n",
        "#   Adjust scale_factor and mean_adj by hand to see EDA agreement among plots\n",
        "\n",
        "for model_name in MODELS_LS:\n",
        "  print(f'Plotting {model_name}')\n",
        "  sns.lineplot(data=corpus_sents_df, x='sent_no', y=model_name, alpha=0.3, legend='brief', label=model_name)\n",
        "      \n",
        "plt.title(f'{CORPUS_FULL} (Model: {model_name}) \\nRaw Sentence Sentiment Plot')\n",
        "# plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FrNFec7tNij"
      },
      "source": [
        "### **Remove Outliers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYXa7qoevyuo"
      },
      "source": [
        "# Trim outliers to max of 3*Median Abs Variance in Standardized Sentiment Time Series\n",
        "#   and overwrite results in model_name column\n",
        "\n",
        "# TODO: Add widget to select which models to include\n",
        "\n",
        "# Sentence\n",
        "for amodel_str in MODELS_LS:\n",
        "  col_noouts_str = amodel_str + '_noouts'\n",
        "  print(f'Sentence: {col_noouts_str} --------------------')\n",
        "  corpus_sents_df[col_noouts_str] = clip_outliers(corpus_sents_df[amodel_str])\n",
        "  \n",
        "  print(f'  old Standardized max: {corpus_sents_df[amodel_str].max()}')\n",
        "  print(f'  old Standardized min: {corpus_sents_df[amodel_str].min()}')\n",
        "  print(f'  new max: {corpus_sents_df[col_noouts_str].max()}')\n",
        "  print(f'  new min: {corpus_sents_df[col_noouts_str].min()}')\n",
        "  \n",
        "# col_rename_dt = rename_cols(corpus_sents_df, models_ls) # ERROR: created 1 new col with col_rename_dt dictionary name instead of mapping correctly\n",
        "# col_rename_dt\n",
        "# _ = corpus_sents_df.rename(columns=col_rename_dt, inplace=True, errors='raise');\n",
        "\n",
        "# Paragraph\n",
        "for amodel_str in MODELS_LS:\n",
        "  col_noouts_str = amodel_str + '_noouts'\n",
        "  print(f'Paragraph: {col_noouts_str} --------------------')\n",
        "  corpus_parags_df[col_noouts_str] = clip_outliers(corpus_parags_df[amodel_str])\n",
        "\n",
        "  print(f'  old Standardized max: {corpus_parags_df[amodel_str].max()}')\n",
        "  print(f'  old Standardized min: {corpus_parags_df[amodel_str].min()}')\n",
        "  print(f'  new max: {corpus_parags_df[col_noouts_str].max()}')\n",
        "  print(f'  new min: {corpus_parags_df[col_noouts_str].min()}')\n",
        "\n",
        "# Section\n",
        "for amodel_str in MODELS_LS:\n",
        "  col_noouts_str = amodel_str + '_noouts'\n",
        "  print(f'Section: {col_noouts_str} --------------------')\n",
        "  corpus_sects_df[col_noouts_str] = clip_outliers(corpus_sects_df[amodel_str])\n",
        "\n",
        "  print(f'  old Standardized max: {corpus_sects_df[amodel_str].max()}')\n",
        "  print(f'  old Standardized min: {corpus_sects_df[amodel_str].min()}')\n",
        "  print(f'  new max: {corpus_sects_df[col_noouts_str].max()}')\n",
        "  print(f'  new min: {corpus_sects_df[col_noouts_str].min()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyPsLI9E4tbB"
      },
      "source": [
        "# Trim outliers to max of 3*Median Abs Variance in Standardized Sentiment Time Series\n",
        "#   and overwrite results in model_name column\n",
        "\n",
        "# TODO: Add widget to select which models to include\n",
        "\"\"\"\n",
        "# Sentences\n",
        "for amodel in MODELS_LS:\n",
        "  col_stand = amodel + '_stand'\n",
        "  col_standout = amodel + '_standout'\n",
        "  print(f'Sentences: {col_stand} --------------------')\n",
        "  # corpus_sents_df[amodel] = corpus_sents_df[col_stand]\n",
        "  corpus_sents_df[col_standout] = clip_outliers(corpus_sents_df[col_stand])\n",
        "  \n",
        "  print(f'  old Standardized max: {corpus_sents_df[col_stand].max()}')\n",
        "  print(f'  old Standardized min: {corpus_sents_df[col_stand].min()}')\n",
        "  print(f'  new max: {corpus_sents_df[col_standout].max()}')\n",
        "  print(f'  new min: {corpus_sents_df[col_standout].min()}')\n",
        "  \n",
        "# col_rename_dt = rename_cols(corpus_sents_df, models_ls) # ERROR: created 1 new col with col_rename_dt dictionary name instead of mapping correctly\n",
        "# col_rename_dt\n",
        "# _ = corpus_sents_df.rename(columns=col_rename_dt, inplace=True, errors='raise');\n",
        "\n",
        "# Paragraphs\n",
        "for amodel in MODELS_LS:\n",
        "  col_stand = amodel + '_stand'\n",
        "  col_standout = amodel + '_standout'\n",
        "  print(f'Paragraphs: {col_stand} --------------------')\n",
        "  # corpus_parags_df[amodel] = corpus_parags_df[col_stand]\n",
        "  corpus_parags_df[col_standout] = clip_outliers(corpus_parags_df[col_stand])\n",
        "  print(f'  old Standardized max: {corpus_parags_df[col_stand].max()}')\n",
        "  print(f'  old Standardized min: {corpus_parags_df[col_stand].min()}')\n",
        "  print(f'  new max: {corpus_parags_df[col_standout].max()}')\n",
        "  print(f'  new min: {corpus_parags_df[col_standout].min()}')\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPKABrvstSIo"
      },
      "source": [
        "### **After Removing Outliers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ccxOjqghbgP"
      },
      "source": [
        "# Plot all Raw Sentence Sentiment Arcs\n",
        "#   Adjust scale_factor and mean_adj by hand to see EDA agreement among plots\n",
        "\n",
        "# Exlopre to find which Sentiment Time Series still have outliers after initial 2.5*Median Abs Dev Clipping\n",
        "MODELS_SENTS_EXCLUDE_LS = ['nrc','bing','afinn','stanza']  # Likely these TS are not normal or heavy tailed so 2.5*MedAbsDev did not clip well\n",
        "MODELS_SENTS_CUSTOM_LS = [x for x in MODELS_LS if x not in MODELS_SENTS_EXCLUDE_LS] \n",
        "\n",
        "for model_name in MODELS_SENTS_CUSTOM_LS:\n",
        "  model_noouts = f'{model_name}_noouts'\n",
        "  print(f'Plotting {model_noouts}')\n",
        "  sns.lineplot(data=corpus_sents_df, x='sent_no', y=model_noouts, alpha=0.3, legend='brief', label=model_name)\n",
        "      \n",
        "plt.title(f'{CORPUS_FULL} (Model: {model_name}) \\nRaw Sentence Sentiment w/Trimmed Outliers Plot')\n",
        "# plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJHXLvayIhOC"
      },
      "source": [
        "# Plot all Raw Paragraph Sentiment Arcs\n",
        "#   Adjust scale_factor and mean_adj by hand to see EDA agreement among plots\n",
        "\n",
        "for model_name in MODELS_LS:\n",
        "  model_standout = f'{model_name}_standout'\n",
        "  print(f'Plotting {model_standout}')\n",
        "  sns.lineplot(data=corpus_parags_df, x='parag_no', y=model_standout, alpha=0.3, legend='brief', label=model_name)\n",
        "      \n",
        "plt.title(f'{CORPUS_FULL} (Model: {model_name}) \\nRaw Paragraph Sentiment Plot')\n",
        "# plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNp9zwBfmgpI"
      },
      "source": [
        "## **Standardize Sentiment Time Series**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQ_wcgiyx-NJ"
      },
      "source": [
        "### **Before Standardizing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEUbDF4hx-NN"
      },
      "source": [
        "for model_name in MODELS_LS:\n",
        "  model_noouts_str = f'{model_name}_noouts'\n",
        "  print(f'Plotting {model_noouts_str}')\n",
        "  sns.lineplot(data=corpus_sents_df, x='sent_no', y=model_noouts_str, alpha=0.3, legend='brief', label=model_name)\n",
        "      \n",
        "plt.title(f'{CORPUS_FULL} (Model: {model_noouts_str}) \\nRaw Sentence Sentiment Plot')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IrnbsMByTmX"
      },
      "source": [
        "### **Standardized the NoOutliers Sentiment Time Series**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhkW7faSmPWh"
      },
      "source": [
        "# Standardize Sentence and Paragraphs Sentiment Time Series (Section TS was Standardized above)\n",
        "\n",
        "std_scaler = StandardScaler()\n",
        "\n",
        "# orig_cols_ls = list(set(corpus_all_df.columns) - set(['sent_no','parag_no','sent_raw','sent_clean']))\n",
        "# cols_ls = []\n",
        "\n",
        "# Sentences\n",
        "for acol in MODELS_LS:\n",
        "    acol_new = acol + '_standouts'\n",
        "    temp_np = std_scaler.fit_transform(np.array(corpus_sents_df[acol].values.reshape(-1,1)))\n",
        "    corpus_sents_df[acol_new] = pd.Series(temp_np.squeeze())\n",
        "\n",
        "# Paragraphs\n",
        "for acol in MODELS_LS:\n",
        "    acol_new = acol + '_standouts'\n",
        "    temp_np = std_scaler.fit_transform(np.array(corpus_parags_df[acol].values.reshape(-1,1)))\n",
        "    corpus_parags_df[acol_new] = pd.Series(temp_np.squeeze())\n",
        "\n",
        "# Paragraphs\n",
        "for acol in MODELS_LS:\n",
        "    acol_new = acol + '_standouts'\n",
        "    temp_np = std_scaler.fit_transform(np.array(corpus_sects_df[acol].values.reshape(-1,1)))\n",
        "    corpus_sects_df[acol_new] = pd.Series(temp_np.squeeze())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nn6EWXYaybhj"
      },
      "source": [
        "### **After Standardizing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcGzZNZJO7fd"
      },
      "source": [
        "for model_name in MODELS_LS:\n",
        "  model_standouts_str = f'{model_name}_standouts'\n",
        "  print(f'Plotting {model_standouts_str}')\n",
        "  sns.lineplot(data=corpus_sents_df, x='sent_no', y=model_standouts_str, alpha=0.3, legend='brief', label=model_name)\n",
        "      \n",
        "plt.title(f'{CORPUS_FULL} (Model: {model_standouts_str}) \\nRaw Sentence Sentiment Plot')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37_ztlEpzYHx"
      },
      "source": [
        "MODELS_LS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34Be4bSszK-A"
      },
      "source": [
        "## **Deselect Poorly Behaved Sentiment Time Series Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hY_HdLarzK-D"
      },
      "source": [
        "VADER_Arc = True #@param {type:\"boolean\"}\n",
        "TextBlob_Arc = True #@param {type:\"boolean\"}\n",
        "Stanza_Arc = True #@param {type:\"boolean\"}\n",
        "SentimentR_Arc = True #@param {type:\"boolean\"}\n",
        "Syuzhet_Arc = True #@param {type:\"boolean\"}\n",
        "AFINN_Arc = True #@param {type:\"boolean\"}\n",
        "Bing_Arc = True #@param {type:\"boolean\"}\n",
        "Pattern_Arc = True #@param {type:\"boolean\"}\n",
        "SentiWord_Arc = True #@param {type:\"boolean\"}\n",
        "SenticNet_Arc = True #@param {type:\"boolean\"}\n",
        "NCR_Arc = True #@param {type:\"boolean\"}\n",
        "MPQA_Arc = False #@param {type:\"boolean\"}\n",
        "SentiStrength_Arc = False #@param {type:\"boolean\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6z5qYX3zm9n"
      },
      "source": [
        "# Create and Verify custom list of Models to include\n",
        "\n",
        "MODELS_CUSTOM_LS = []\n",
        "\n",
        "if VADER_Arc:\n",
        "  MODELS_CUSTOM_LS.append('vader')\n",
        "if TextBlob_Arc:\n",
        "  MODELS_CUSTOM_LS.append('textblob')\n",
        "if Stanza_Arc:\n",
        "  MODELS_CUSTOM_LS.append('stanza')\n",
        "if SentimentR_Arc:\n",
        "  MODELS_CUSTOM_LS.append('sentimentr')\n",
        "if Syuzhet_Arc:\n",
        "  MODELS_CUSTOM_LS.append('syuzhet')\n",
        "if AFINN_Arc:\n",
        "  MODELS_CUSTOM_LS.append('afinn')\n",
        "if Bing_Arc:\n",
        "  MODELS_CUSTOM_LS.append('bing')\n",
        "if Pattern_Arc:\n",
        "  MODELS_CUSTOM_LS.append('pattern')\n",
        "if SentiWord_Arc:\n",
        "  MODELS_CUSTOM_LS.append('sentiword')\n",
        "if SenticNet_Arc:\n",
        "  MODELS_CUSTOM_LS.append('senticnet')\n",
        "if NCR_Arc:\n",
        "  MODELS_CUSTOM_LS.append('nrc')\n",
        "\n",
        "print(f'Here are the Models we are using to ensemble and save:\\n   {MODELS_CUSTOM_LS}')\n",
        "\n",
        "models_incl_ls = []\n",
        "for amodel in MODELS_CUSTOM_LS:\n",
        "  models_incl_ls.append(amodel[:2])\n",
        "models_incl_str = ''.join(models_incl_ls)\n",
        "\n",
        "print(f'Here is a custom name abbr: {models_incl_str}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfiyOjMBBraW"
      },
      "source": [
        "## **Calculate Median of All (Trimmed Outliers then Standardized) Sentiment Time Series**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1tX6BmT4U5h"
      },
      "source": [
        "# Create a list of models with Outliers trimmed and Standardized Time Series \n",
        "\n",
        "MODELS_CUSTOM_STANDOUTS_LS = []\n",
        "\n",
        "for amodel in MODELS_CUSTOM_LS:\n",
        "  model_standout_str = f'{amodel}_standouts'\n",
        "  MODELS_CUSTOM_STANDOUTS_LS.append(model_standout_str)\n",
        "\n",
        "print(f'List of NoOutliers/Standardized Models to compute Median on: {MODELS_CUSTOM_STANDOUTS_LS}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx3-Qug9Y6h0"
      },
      "source": [
        "# Disregard poorly behaved time series identified and stored in MODELS_SENTS_EXCLUDE_LS \n",
        "\n",
        "# TODO: Add widget to select which models to include\n",
        "\n",
        "corpus_sents_df['median_standouts_custom_lex'] = corpus_sents_df[MODELS_CUSTOM_STANDOUTS_LS].median(axis=1)\n",
        "# corpus_sents_df.head(2)\n",
        "\n",
        "corpus_sents_df['std_standouts_custom_lex'] = corpus_sents_df[MODELS_CUSTOM_STANDOUTS_LS].std(axis=1)\n",
        "# corpus_sents_df.head(2)\n",
        "\n",
        "corpus_sents_df['mean_standouts_custom_lex'] = corpus_sents_df[MODELS_CUSTOM_STANDOUTS_LS].mean(axis=1)\n",
        "# corpus_sents_df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2qunU4VfJ4J"
      },
      "source": [
        "# (For now) Paragraph Sentiment TS are better behaved and don't require excluding any Model\n",
        "\n",
        "corpus_parags_df['median_standouts_custom_lex'] = corpus_parags_df[MODELS_CUSTOM_STANDOUTS_LS].median(axis=1)\n",
        "# corpus_parags_df.head(2)\n",
        "\n",
        "corpus_parags_df['std_standouts_custom_lex'] = corpus_parags_df[MODELS_CUSTOM_STANDOUTS_LS].std(axis=1)\n",
        "# corpus_parags_df.head(2)\n",
        "\n",
        "corpus_parags_df['mean_standouts_custom_lex'] = corpus_parags_df[MODELS_CUSTOM_STANDOUTS_LS].mean(axis=1)\n",
        "# corpus_parags_df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtTY4t4k1QBc"
      },
      "source": [
        "# (For now) Paragraph Sentiment TS are better behaved and don't require excluding any Model\n",
        "\n",
        "corpus_sects_df['median_standouts_custom_lex'] = corpus_sects_df[MODELS_CUSTOM_STANDOUTS_LS].median(axis=1)\n",
        "# corpus_parags_df.head(2)\n",
        "\n",
        "corpus_sects_df['std_standouts_custom_lex'] = corpus_sects_df[MODELS_CUSTOM_STANDOUTS_LS].std(axis=1)\n",
        "# corpus_parags_df.head(2)\n",
        "\n",
        "corpus_sects_df['mean_standouts_custom_lex'] = corpus_sects_df[MODELS_CUSTOM_STANDOUTS_LS].mean(axis=1)\n",
        "# corpus_parags_df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sp_gYLYbkjxd"
      },
      "source": [
        "## **Save Processed Sentiment Time Series**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmyasWR1kjxh"
      },
      "source": [
        "# Save Preprocessed Corpus Sentences DataFrame\n",
        "\n",
        "# author_str = ''.join(CORPUS_AUTHOR.split()).lower()\n",
        "title_str = ''.join(CORPUS_TITLE.split()).lower()\n",
        "datetime_now = datetime.utcnow().strftime(\"%Y%m%d_%H%M\")\n",
        "\n",
        "corpus_sents_filename = f'corpus_sentences_lexrules_{models_incl_str}_{author_abbr_str}_{title_str}_{datetime_now}.csv'\n",
        "print(f'Saving Corpus Sentences to file: {corpus_sents_filename}')\n",
        "corpus_sents_df.to_csv(corpus_sents_filename)\n",
        "\n",
        "corpus_parags_filename = f'corpus_paragraphs_lexrules_{models_incl_str}_{author_abbr_str}_{title_str}_{datetime_now}.csv'\n",
        "print(f'Saving Corpus Paragraphs to file: {corpus_parags_filename}')\n",
        "corpus_parags_df.to_csv(corpus_parags_filename)\n",
        "\n",
        "corpus_sects_filename = f'corpus_sections_lexrules_{models_incl_str}_{author_abbr_str}_{title_str}_{datetime_now}.csv'\n",
        "print(f'Saving Corpus Sections to file: {corpus_sects_filename}')\n",
        "corpus_sects_df.to_csv(corpus_sects_filename)\n",
        "\n",
        "corpus_cruxes_filename = f'corpus_cruxes_lexrules_{models_incl_str}_{author_abbr_str}_{title_str}_{datetime_now}.csv'\n",
        "print(f'Saving Corpus Cruxes to file: {corpus_cruxes_filename}')\n",
        "with open(corpus_cruxes_filename, 'w') as convert_file:\n",
        "  convert_file.write(json.dumps(corpus_cruxes_dt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUnbmOFckt2t"
      },
      "source": [
        "# **EDA Visualizations and Comparisons**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww1a9l8Lkjxk"
      },
      "source": [
        "# Verify\n",
        "\n",
        "corpus_sents_df.head(2)\n",
        "corpus_sents_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiHul8A1kjxn"
      },
      "source": [
        "# Verify\n",
        "\n",
        "corpus_parags_df.head(2)\n",
        "corpus_parags_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbY7D82jkjxp"
      },
      "source": [
        "# Verify\n",
        "\n",
        "corpus_sects_df.head(2)\n",
        "corpus_sects_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cvvfzj7xkjxp"
      },
      "source": [
        "corpus_cruxes_dt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDiTp97_zlUm"
      },
      "source": [
        "# norm_cols_ls = ['distbertsst_norm', 'nlptown_norm','xlnet_sst5_norm','bert_imdb_norm', 'bertuc_googapps_norm', 'roberta_lg15_norm']\n",
        "\"\"\"\n",
        "\n",
        "# ARCHIVE\n",
        "\n",
        "cols_norm_ls = []\n",
        "cols_stand_ls = []\n",
        "\n",
        "for acol in corpus_all_df.columns:\n",
        "  if acol.endswith('_norm'):\n",
        "    print(f'Adding {acol} to norm_cols_ls')\n",
        "    cols_norm_ls.append(acol)\n",
        "  elif acol.endswith('_stand'):\n",
        "    print(f'Adding {acol} to stand_cols_ls')\n",
        "    cols_stand_ls.append(acol)\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "print(f'\\nNormalized Columns: {cols_norm_ls}')\n",
        "\n",
        "print(f'\\nStandardized Columns: {cols_stand_ls}')\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O3l61be6_GQ"
      },
      "source": [
        "### **LOWESS Smoothed Single Plot**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUjsXyRG81zT"
      },
      "source": [
        "**Normalized Sentiment Smoothed with LOWESS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5MYEwGuZ2vh"
      },
      "source": [
        "MODELS_STAND_LS = []\n",
        "for amodel in MODELS_LS:\n",
        "  MODELS_STAND_LS.append(f'{amodel}_stand')\n",
        "\n",
        "print(f'MODELS_STAND_LS: {MODELS_STAND_LS}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBT-Qd4o8919"
      },
      "source": [
        "**Standardized Sentiment Smoothed with LOWESS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZ-Oe8icVpHn"
      },
      "source": [
        "# Plot and Compare all LOWESS Smoothed *Standardized* Sentiment Time Series\n",
        "\n",
        "corpus_lowess_stand_df = get_lowess(corpus_all_df, cols_stand_ls, plot_subtitle='Standardized', afrac=1./10, ait=5, do_plot=True, save2file=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JizqEQE6X3oQ"
      },
      "source": [
        "### **High Level: Section View**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIwEIY4cd2PB"
      },
      "source": [
        "##### **Raw Sentiment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryWst950gpYx"
      },
      "source": [
        "# Plot Raw Section Sentiments\n",
        "\"\"\"\n",
        "\n",
        "# ARCHIVED\n",
        "\n",
        "for amodel in MODELS_CUSTOM_STANDOUTS_LS:\n",
        "  amodel_stand_str = f'{amodel}'\n",
        "  plot_raw_sentiments(model_name=amodel_stand_str, semantic_type='section', save2file=False)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx4mryQwVz7h"
      },
      "source": [
        "# Raw Standardized Section Sentiment Time Series\n",
        "\n",
        "_ = plot_stand_crux_sections(ts_df=corpus_sects_df, model_names_ls=MODELS_CUSTOM_STANDOUTS_LS, semantic_type='section', label_token_ct=5, title_xpos=0.5, title_ypos=1, save2file=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0HK0lbzjXXF"
      },
      "source": [
        "# Plot the Median of the Customized Set of NoOutliers/Standardized Section Sentiment Time Series\n",
        "\n",
        "corpus_sects_df['median_standouts_custom_lex'].plot()\n",
        "plt.title(f'{CORPUS_FULL}\\n Median of NoOutliers/Standardized Section Sentiment Time Series');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKz34IzZdxIg"
      },
      "source": [
        "##### **SMA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeOWF6frEm0S"
      },
      "source": [
        "Window_Width = 4 #@param {type:\"slider\", min:2, max:20, step:1}\n",
        "\n",
        "# DEFAULT 5-20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1lngzR7XM5l"
      },
      "source": [
        "# SMA of Custom Set of NoOutliers/Standardized Section Sentiment Time Series\n",
        "\n",
        "# NOTE: EDA/Adjust the win_ls to explore different window_size by hand to see EDA agreement among plots\n",
        "\n",
        "for model_name in MODELS_CUSTOM_STANDOUTS_LS:\n",
        "  # print(f'Plotting {acol_name}')\n",
        "  get_smas(corpus_sects_df, model_name, text_unit='section', subtitle_str='(NOTE: different x-scale)', win_ls=[Window_Width])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5Qw6frQdz1C"
      },
      "source": [
        "##### **LOWESS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAuz19B5ntxk"
      },
      "source": [
        "# Standardized Section LOWESS Smoothed Sentiment Time Series\n",
        "\n",
        "_ = get_lowess(corpus_sects_df, models_ls=MODELS_STAND_LS, text_unit='section', afrac=1./4, do_plot=True, save2file=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-u2ScQZD8Lv"
      },
      "source": [
        "LOWESS_fraction = 0.15 #@param {type:\"slider\", min:0.1, max:0.3, step:0.01}\n",
        "\n",
        "# Default: 1./6 (approx 0.17)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L82SbpnkO_3"
      },
      "source": [
        "# Standardized Median Section LOWESS Smoothed Sentiment Time Series\n",
        "\n",
        "_ = get_lowess(corpus_sects_df, models_ls=['median'], text_unit='section', afrac=LOWESS_fraction, do_plot=True, save2file=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6Ipaa-lWVwP"
      },
      "source": [
        "### **Middle Level: Paragraph Views**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDYYpJYRfrZ-"
      },
      "source": [
        "##### **Raw Sentiment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxyJD-fjf4ev"
      },
      "source": [
        "# Plot Custom Set of NoOutliers/Standardized Paragraph Sentiments Time Series \n",
        "\n",
        "for amodel in MODELS_CUSTOM_STANDOUTS_LS:\n",
        "  plot_raw_sentiments(model_name=amodel, semantic_type='paragraph', save2file=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwD9lNuJkCfo"
      },
      "source": [
        "# Plot the Median for the Custom Set of NoOutlier/Standardized Paragraph Sentiment Time Series\n",
        "\n",
        "corpus_parags_df['median_standouts_custom_lex'].plot()\n",
        "plt.title(f'{CORPUS_FULL}\\n Median of Custom Set of NoOutlier/Standardized Paragraph Sentiment Time Series');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jii7hmhleyHo"
      },
      "source": [
        "##### **SMA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJn79SwJDKHt"
      },
      "source": [
        "Window_Width = 10 #@param {type:\"slider\", min:5, max:20, step:1}\n",
        "\n",
        "# DEFAULT 5-20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "490cQGkgIBK2"
      },
      "source": [
        "# SMA Standardized Paragraph Sentiment Arcs\n",
        "\n",
        "# NOTE: EDA/adjust the win_size below by hand to see EDA agreement among plots (5-20 defaults)\n",
        "\n",
        "for model_name in MODELS_CUSTOM_STANDOUTS_LS:\n",
        "  get_smas(corpus_parags_df, model_name, text_unit='paragraph', win_ls=[Window_Width])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDo7OHyHCtUJ"
      },
      "source": [
        "Window_Percentage = 5 #@param {type:\"slider\", min:5, max:20, step:1}\n",
        "\n",
        "# DEFAULT: 5-20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mahzCm5W9-QL"
      },
      "source": [
        "# SMA Plot the Median for the Custom Set of NoOutlier/Standardized Paragraph Sentiment Time Series\n",
        "\n",
        "# NOTE: EDA/adjust the win_size below by hand to see EDA agreement among plots\n",
        "\n",
        "win_percentage = Window_Percentage  # 5 means rolling window size is 5% of corpus length (5-20 default)\n",
        "\n",
        "win_size = int(corpus_parags_df.shape[0]*(win_percentage*0.01))\n",
        "\n",
        "plot_title = f'{CORPUS_FULL}\\n Median of Custom Set of NoOutlier/Standardized Paragraph Sentiment Time Series (win={win_percentage}%)'\n",
        "corpus_parags_df['median_standouts_custom_lex'].rolling(win_size).mean().plot(title=plot_title)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2CIR3U9e4WC"
      },
      "source": [
        "##### **LOWESS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIzHfrCdCC9d"
      },
      "source": [
        "LOWESS_fraction = 0.17 #@param {type:\"slider\", min:0.1, max:0.3, step:0.01}\n",
        "\n",
        "# Default: 1./6 (approx 0.17)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2337wydGe4WC"
      },
      "source": [
        "# Standardized Paragraph LOWESS Smoothed Sentiment Time Series\n",
        "\n",
        "# NOTE: EDA/adjust the win_size below by hand to see EDA agreement among plots (0.10-0.20 default)\n",
        "\n",
        "_ = get_lowess(corpus_parags_df, models_ls=MODELS_CUSTOM_STANDOUTS_LS, text_unit='paragraph', afrac=LOWESS_fraction, do_plot=True, save2file=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0emSLGZCh6-Y"
      },
      "source": [
        "LOWESS_fraction = 0.12 #@param {type:\"slider\", min:0.1, max:0.3, step:0.01}\n",
        "\n",
        "# Default: 1./6 to 1./8 (approx 0.17 to 0.12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vq8s_aShoEJ"
      },
      "source": [
        "# Plot it\n",
        "\n",
        "_ = get_lowess(corpus_parags_df, models_ls=['median_standouts_custom_lex'], text_unit='paragraph', afrac=LOWESS_fraction, do_plot=True, save2file=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzcDX02pZGbr"
      },
      "source": [
        "### **Low Level: Sentence Views**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV6spOW1fSKf"
      },
      "source": [
        "##### **SMA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HE_-_JJ9FeVj"
      },
      "source": [
        "Window_Percentage = 10 #@param {type:\"slider\", min:5, max:20, step:1}\n",
        "\n",
        "# DEFAULT: 5-20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gYKbdptopin"
      },
      "source": [
        "# Plot all Standardized Sentence Sentiment Arcs\n",
        "#   Adjust scale_factor and mean_adj by hand to see EDA agreement among plots\n",
        "\n",
        "models_stand_ls = []\n",
        "for model_name in MODELS_CUSTOM_STANDOUTS_LS:\n",
        "  get_smas(corpus_sents_df, model_name, text_unit='sentence', alpha=0.3, win_ls=[Window_Percentage])\n",
        "\n",
        "# print(f'models_stand_ls: {models_stand_ls}')\n",
        "corpus_sents_df['median_stand'] = corpus_sents_df[models_stand_ls].median()\n",
        "plt.plot(corpus_sents_df.sent_no, corpus_sents_df.median_stand, color='black', label='Median')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0fL5RXKfZG6"
      },
      "source": [
        "##### **LOWESS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-NGw8yEFnJD"
      },
      "source": [
        "LOWESS_fraction = 0.12 #@param {type:\"slider\", min:0.1, max:0.3, step:0.01}\n",
        "\n",
        "# Default: 1./6 to 1./8 (approx 0.17 to 0.12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDlGY9CMfUj9"
      },
      "source": [
        "# Standardized Paragraph LOWESS Smoothed Sentiment Time Series\n",
        "\n",
        "_ = get_lowess(corpus_sents_df, models_ls=MODELS_CUSTOM_STANDOUTS_LS, text_unit='sentence', afrac=LOWESS_fraction, do_plot=True, save2file=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9SQeAvgGFb6"
      },
      "source": [
        "LOWESS_fraction = 0.12 #@param {type:\"slider\", min:0.1, max:0.3, step:0.01}\n",
        "\n",
        "# Default: 1./6 to 1./8 (approx 0.17 to 0.12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-GtGa5mlEhZ"
      },
      "source": [
        "# Median of Custom Set of NoOutlier/Standardized Sentiment Time Series\n",
        "\n",
        "_ = get_lowess(corpus_sents_df, models_ls=['median_standouts_custom_lex'], text_unit='paragraph', afrac=1./8, do_plot=True, save2file=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1VhYgLai3RK"
      },
      "source": [
        "## **Save Standardized-NoOutliers Sentiment Values**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3zmDWROOEvM"
      },
      "source": [
        "# Save all Processed DataFrames\n",
        "\n",
        "# author_str = ''.join(CORPUS_AUTHOR.split()).lower()\n",
        "title_str = ''.join(CORPUS_TITLE.split()).lower()\n",
        "datetime_now = datetime.utcnow().strftime(\"%Y%m%d_%H%M\")\n",
        "\n",
        "\n",
        "# Save Preprocessed Corpus Sentences DataFrame\n",
        "corpus_sents_filename = f'corpus_sentences_only_lexrules_standouts_{author_abbr_str}_{title_str}_{datetime_now}.csv'\n",
        "print(f'Saving to file: {corpus_sents_filename}')\n",
        "corpus_sents_df.to_csv(corpus_sents_filename)\n",
        "\n",
        "\n",
        "# Save Preprocessed Corpus Paragraphs DataFrame\n",
        "corpus_parags_filename = f'corpus_paragraphs_only_lexrules_standouts_{author_abbr_str}_{title_str}_{datetime_now}.csv'\n",
        "print(f'Saving to file: {corpus_parags_filename}')\n",
        "corpus_parags_df.to_csv(corpus_parags_filename)\n",
        "\n",
        "\n",
        "# Save Preprocessed Corpus Section DataFrame\n",
        "corpus_sects_filename = f'corpus_sections_only_lexrules_standouts_{author_abbr_str}_{title_str}_{datetime_now}.csv'\n",
        "print(f'Saving to file: {corpus_sects_filename}')\n",
        "corpus_sects_df.to_csv(corpus_sects_filename)\n",
        "\n",
        "\n",
        "# Save Cruxes\n",
        "corpus_cruxes_filename = f'corpus_cruxes_lexrules_{models_incl_str}_{author_abbr_str}_{title_str}_{datetime_now}.csv'\n",
        "print(f'Saving Corpus Cruxes to file: {corpus_cruxes_filename}')\n",
        "with open(corpus_cruxes_filename, 'w') as convert_file:\n",
        "  convert_file.write(json.dumps(corpus_cruxes_dt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vUzh39HHJXz"
      },
      "source": [
        "# **Metrics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJI_13B0HMnU"
      },
      "source": [
        "## **Sentiment Stability**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R6SMWtSHJLK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9sEH8_IG6Qq"
      },
      "source": [
        "## **Crux Point Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRjKHnQaOTu2"
      },
      "source": [
        "### **Gather (n) Highest/Lowest Sentiment Values for Each Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sG6Y0vPFOkzn"
      },
      "source": [
        "def getn_cruxes(crux_dt, model_name='vader', get_n=6):\n",
        "  '''\n",
        "  Given a Crux Dictionary, a Model item/dict within, and and integer n\n",
        "  Return the n highest and n lowest sentiment values\n",
        "  NOTE: if get_n == 0, return all Crux Points for all Models\n",
        "  '''\n",
        "\n",
        "  cruxes_all_df = pd.DataFrame\n",
        "  cruxes_n_top_df = pd.DataFrame()\n",
        "\n",
        "  cruxes_all_df = pd.DataFrame.from_dict(crux_dt[model_name])\n",
        "\n",
        "  cruxes_all_df = cruxes_all_df.transpose().reset_index().rename(columns={'index':'var'})\n",
        "\n",
        "  cruxes_all_df.rename(columns={'var':'sent_no',0:model_name,1:'sent_raw'}, inplace=True)\n",
        "  cruxes_all_df.drop(columns=['sent_raw'], inplace=True)\n",
        "  cruxes_all_df.rename(columns={model_name:'sentiment'}, inplace=True)\n",
        "  cruxes_all_df['sentiment'] = cruxes_all_df['sentiment'].astype('float')\n",
        "  cruxes_all_df['model_name'] = model_name\n",
        "  cruxes_all_df = cruxes_all_df[['sent_no','model_name','sentiment']]\n",
        "\n",
        "  if get_n > 0:\n",
        "    cruxes_n_top_df = cruxes_all_df.nlargest(get_n, 'sentiment')\n",
        "    cruxes_n_top_df = cruxes_n_top_df.append(cruxes_all_df.nsmallest(get_n, 'sentiment'))\n",
        "  elif get_n ==0:\n",
        "    cruxes_n_top_df = cruxes_all_df\n",
        "  else:\n",
        "    print(f'ERROR: argument get_n must be either 0 (return all Cruxes) or greater than 0')\n",
        "    \n",
        "  return cruxes_n_top_df\n",
        "\n",
        "# Test\n",
        "\n",
        "cruxes_n_top_df = getn_cruxes(corpus_cruxes_dt, model_name='vader', get_n=3)\n",
        "cruxes_n_top_df.head(6)\n",
        "cruxes_n_top_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H67tOfiaSaHB"
      },
      "source": [
        "# Acculumate all the Crux Points from All Models into one cruxes_n_top_all_df DataFrame\n",
        "\n",
        "cruxes_n_top_all_df = pd.DataFrame()\n",
        "\n",
        "for amodel in MODELS_LS:\n",
        "  print(f'Appending Cruxes from {amodel}')\n",
        "  cruxes_n_top_df = getn_cruxes(corpus_cruxes_dt, model_name=amodel, get_n=12)\n",
        "  cruxes_n_top_all_df = cruxes_n_top_all_df.append(cruxes_n_top_df, ignore_index=True)\n",
        "\n",
        "for amodel in MODELS_LS:\n",
        "  crux_ct = len(cruxes_n_top_all_df[cruxes_n_top_all_df['model_name'] == amodel])\n",
        "  print(f'{amodel.capitalize()} has {crux_ct} Cruxes')\n",
        "\n",
        "print(f'There are a total of {cruxes_n_top_all_df.shape[0]} in all Models')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQDWi6YLYVn0"
      },
      "source": [
        "# Plot Crux Points in 2D Space: Scatterplot\n",
        "\n",
        "sns.lmplot('sent_no', 'sentiment', data=cruxes_n_top_all_df, fit_reg=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab2oHmU1Yqcl"
      },
      "source": [
        "# Plot Crux Points in 1D Space: Histogram\n",
        "\n",
        "sns.distplot(cruxes_n_top_all_df.sent_no, bins=2000)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtdL2OjAJm55"
      },
      "source": [
        "sns.clustermap(cruxes_n_top_all_df.sent_no)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiTZC_X4G6EC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EE8EJC1wHCEn"
      },
      "source": [
        "## **Sentiment Arc Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFKeAFHlG-vm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TfBnxjYG5_u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wjBEXGyvU4x"
      },
      "source": [
        "# **END OF NOTEBOOK**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTRo_Tt35VW8"
      },
      "source": [
        "**Bi/Tri-Polarity Lexicons**\n",
        "\n",
        "NRC: \n",
        "* https://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm\n",
        "\n",
        "MPQA (Upitt):\n",
        "* https://mpqa.cs.pitt.edu/lexicons/effect_lexicon/\n",
        "* https://github.com/nlpcl-lab/mpqa2.0-preprocessing\n",
        "* https://github.com/kvangundy/basic-sentiment-analyzer/blob/master/sentimentDict.csv\n",
        "\n",
        "SentimentAnalysis.R (20210217 124s):\n",
        "* QDAP \n",
        "* DictionaryGI: Harvard-IV dictionary asused in the General Inquirer software (2005-/1637+)\n",
        "* DictionaryLM: Loughran-McDonald Financial dictionary (2355-/354+/297?)\n",
        "* DictionaryHE: Henry's Financial Dictionary (85-/105+)\n",
        "\n",
        "Custom Lexicons:\n",
        "* https://nealcaren.org/lessons/wordlists/ \n",
        "\n",
        "Lexicons\n",
        "* https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html#datasets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsOKzM-RYHf5"
      },
      "source": [
        "# Smooth Raw Sentiment Time Series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWKU0OzT_9pe"
      },
      "source": [
        "**Simple Moving Average (SMA) by Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGluyBsFkQ7C"
      },
      "source": [
        "# Line Plots of Sentiment Values\n",
        "\n",
        "# set a grey background (use sns.set_theme() if seaborn version 0.11.0 or above) \n",
        "sns.set(style=\"darkgrid\")\n",
        "# df = sns.load_dataset(\"iris\")\n",
        "\n",
        "fig, axs = plt.subplots(4, 2, figsize=(12, 18))\n",
        "\n",
        "sns.lineplot(data=corpus_sents_df, x=\"sent_no\", y=\"median\", color=\"skyblue\", ax=axs[0, 0])\n",
        "sns.lineplot(data=corpus_sents_df, x=\"sent_no\", y=\"vader_mean_roll050\", color=\"skyblue\", ax=axs[0, 1])\n",
        "sns.lineplot(data=corpus_sents_df, x=\"sent_no\", y=\"sentimentr_mean_roll050\", color=\"olive\", ax=axs[1, 0])\n",
        "sns.lineplot(data=corpus_sents_df, x=\"sent_no\", y=\"syuzhet_mean_roll050\", color=\"olive\", ax=axs[1, 1])\n",
        "sns.lineplot(data=corpus_sents_df, x=\"sent_no\", y=\"bing_mean_roll050\", color=\"gold\", ax=axs[2, 0])\n",
        "sns.lineplot(data=corpus_sents_df, x=\"sent_no\", y=\"textblob_mean_roll050\", color=\"gold\", ax=axs[2, 1])\n",
        "sns.lineplot(data=corpus_sents_df, x=\"sent_no\", y=\"sentiword_mean_roll050\", color=\"teal\", ax=axs[3, 0])\n",
        "sns.lineplot(data=corpus_sents_df, x=\"sent_no\", y=\"senticnet_mean_roll050\", color=\"teal\", ax=axs[3, 1])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySuYAv2YxCO0"
      },
      "source": [
        "corpus_sents_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iX1nCK6ljY8"
      },
      "source": [
        "%whos dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC3r9eWywyXB"
      },
      "source": [
        "\n",
        "# g=sns.pointplot(x=0, y=1, data=df, dodge=True,plot_kws=dict(alpha=0.3))\n",
        "# plt.setp(g.collections, alpha=.3) #for the markers\n",
        "# plt.setp(g.lines, alpha=.3)       #for the lines\n",
        "\n",
        "for i, sa_model in enumerate(corpus_sents_df.columns):\n",
        "  if (sa_model.endswith('_roll050')):\n",
        "    # if (sa_model != 'sent_no'):\n",
        "    if (sa_model == 'median'):\n",
        "      sns.lineplot(data=corpus_sents_df, x='sent_no', y=sa_model, color='black')\n",
        "    else:\n",
        "      sns.lineplot(data=corpus_sents_df, x='sent_no', y=sa_model, alpha=0.3)\n",
        "\n",
        "# print(f'{i}: {sa_model}')\n",
        "\n",
        "'''\n",
        "sns.lineplot(data=corpus_sentiments_df, x='sent_no', y='median')\n",
        "sns.lineplot(data=corpus_sentiments_df, x='sent_no', y='vader_roll500')\n",
        "sns.lineplot(data=corpus_sentiments_df, x='sent_no', y='textb')\n",
        "sns.lineplot(data=corpus_sentiments_df, x='sent_no', y='vader_roll500')\n",
        "sns.lineplot(data=corpus_sentiments_df, x='sent_no', y='vader_roll500')\n",
        "sns.lineplot(data=corpus_sentiments_df, x='sent_no', y='vader_roll500')\n",
        "sns.lineplot(data=corpus_sentiments_df, x='sent_no', y='vader_roll500')\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTKI4Fu2ACKP"
      },
      "source": [
        "**Exponential Moving Average**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvVMrD58AL97"
      },
      "source": [
        "# Not Necessary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wEab5F8_3Wl"
      },
      "source": [
        "**LOWESS and LOESS Smoothing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPOo6VAMmWh_"
      },
      "source": [
        "sa_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlPwfjS8mKpY"
      },
      "source": [
        "def plot_lowess(df, df_cols_ls, aplot=True, afrac=1./10, ait=5):\n",
        "  '''\n",
        "  Given a DataFrame, list of column to plot, LOWESS params fraction and iterations,\n",
        "  Return a DataFrame with LOWESS values\n",
        "  If 'plot=True', also output plot\n",
        "  '''\n",
        "\n",
        "  # global corpus_sents_norm_df\n",
        "\n",
        "  lowess_df = pd.DataFrame()\n",
        "\n",
        "  for i,acol in enumerate(df_cols_ls):\n",
        "    sm_x, sm_y = sm_lowess(endog=df[acol].values, exog=df.index.values,  frac=afrac, it=ait, return_sorted = True).T\n",
        "    col_new = f'{acol}_lowess'\n",
        "    lowess_df[col_new] = pd.Series(sm_x)\n",
        "    if aplot:\n",
        "      plt.plot(sm_x, sm_y, label=acol, alpha=0.5, linewidth=2)\n",
        "\n",
        "      frac_str = str(round(100*afrac))\n",
        "      plt.title(f'{CORPUS_FULL} \\n LOWESS (frac={frac_str} Sentence Sentiment (Model: {sa_model})')\n",
        "      plt.legend(title='Sentiment Series')\n",
        "\n",
        "  return lowess_df\n",
        "\n",
        "# Test\n",
        "new_lowess_col = f'{sa_model}_lowess'\n",
        "my_frac = 1./10\n",
        "my_frac_per = round(100*my_frac)\n",
        "new_lowess_col = f'{sa_model}_lowess_{my_frac_per}'\n",
        "corpus_sents_df[new_lowess_col] = plot_lowess(corpus_sents_df, [sa_model], afrac=my_frac)\n",
        "corpus_sents_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qRUhRfmmyUA"
      },
      "source": [
        "corpus_sents_norm_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxbZdPVbnL6w"
      },
      "source": [
        "corpus_sents_norm_df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25CDCoDJmTcI"
      },
      "source": [
        "norm_cols_ls = []\n",
        "for acol in corpus_sents_norm_df.columns:\n",
        "  if acol.endswith('_2norm'):\n",
        "    norm_cols_ls.append(acol)\n",
        "\n",
        "print(f'All norm_cols_ls')\n",
        "\n",
        "temp_cols_ls = list(set(norm_cols_ls) - set(['stanza_2norm','afinn_2norm']))\n",
        "\n",
        "print(f'Trimmed temp_cols_ls:')\n",
        "print(temp_cols_ls)\n",
        "\n",
        "\n",
        "plot_lowess(corpus_sents_norm_df, temp_cols_ls, 'Normed')\n",
        "\n",
        "'''\n",
        "for i, sa_model in enumerate(corpus_sents_df.columns):\n",
        "  if (sa_model.endswith('_roll050')):\n",
        "    # if (sa_model != 'sent_no'):\n",
        "    if (sa_model == 'median'):\n",
        "      sns.lineplot(data=corpus_sents_df, x='sent_no', y=sa_model, color='black')\n",
        "    else:\n",
        "      sns.lineplot(data=corpus_sents_df, x='sent_no', y=sa_model, alpha=0.3)\n",
        "''';"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7hs9FIxpugn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq8fWCKCpuaW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvKW23iwAGnk"
      },
      "source": [
        "%time\n",
        "\n",
        "plt.title(f'{BOOK_TITLE_FULL} \\n {sa_model} with statsmodels LOWESS (frac=0.1/iter=5)')\n",
        "\n",
        "sm_x, sm_y = sm_lowess(endog=corpus_sentiments_df['median'].values, exog=corpus_sentiments_df.index.values,  frac=1./10., \n",
        "                       it=5, return_sorted = True).T\n",
        "plt.plot(sm_x, sm_y, label='Median', color='black', linewidth=3)\n",
        "\n",
        "sm_x, sm_y = sm_lowess(endog=corpus_sentiments_df['vader_roll500'].values, exog=corpus_sentiments_df.index.values,  frac=1./10., \n",
        "                       it=5, return_sorted = True).T\n",
        "sns.lineplot(sm_x, sm_y, label='VADER', color='royalblue', alpha=0.5)\n",
        "\n",
        "sm_x, sm_y = sm_lowess(endog=corpus_sentiments_df['jockers_rinker_roll500'].values, exog=corpus_sentiments_df.index.values,  frac=1./10., \n",
        "                       it=5, return_sorted = True).T\n",
        "sns.lineplot(sm_x, sm_y, label='Jockers-Rinker', color='red', alpha=0.5)\n",
        "\n",
        "sm_x, sm_y = sm_lowess(endog=corpus_sentiments_df['syuzhet_roll500'].values, exog=corpus_sentiments_df.index.values,  frac=1./10., \n",
        "                       it=5, return_sorted = True).T\n",
        "sns.lineplot(sm_x, sm_y, label='Syuzhet', color='tomato', alpha=0.5)\n",
        "\n",
        "sm_x, sm_y = sm_lowess(endog=corpus_sentiments_df['huliu_roll500'].values, exog=corpus_sentiments_df.index.values,  frac=1./10., \n",
        "                       it=5, return_sorted = True).T\n",
        "sns.lineplot(sm_x, sm_y, label='HuLiu', color='teal', alpha=0.5)\n",
        "\n",
        "sm_x, sm_y = sm_lowess(endog=corpus_sentiments_df['textblob_roll500'].values, exog=corpus_sentiments_df.index.values,  frac=1./10., \n",
        "                       it=5, return_sorted = True).T\n",
        "sns.lineplot(sm_x, sm_y, label='TextBlob', color='lime', alpha=0.5)\n",
        "\n",
        "sm_x, sm_y = sm_lowess(endog=corpus_sentiments_df['sentiword_roll500'].values, exog=corpus_sentiments_df.index.values,  frac=1./10., \n",
        "                       it=5, return_sorted = True).T\n",
        "sns.lineplot(sm_x, sm_y, label='SentiWord', color='goldenrod', alpha=0.5)\n",
        "\n",
        "sm_x, sm_y = sm_lowess(endog=corpus_sentiments_df['senticnet_roll500'].values, exog=corpus_sentiments_df.index.values,  frac=1./10., \n",
        "                       it=5, return_sorted = True).T\n",
        "sns.lineplot(sm_x, sm_y, label='SenticNet', color='forestgreen', alpha=0.5)\n",
        "\n",
        "# y_upper = corpus_sentiments_df['norm_score'].max() + 0.01\n",
        "# y_lower = corpus_sentiments_df['norm_score'].min() - 0.01\n",
        "# y_range = y_upper - y_lower + 0.02\n",
        "# plt.ylim([0.71, 0.74])\n",
        "# plt.ylim([y_lower, y_upper])\n",
        "# plt.plot(x, y, 'k.');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iORvQhmNFrw"
      },
      "source": [
        "**Discrete Cosine Transform (DCT)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "917t5E9t_Pez"
      },
      "source": [
        "Libraries:\n",
        "\n",
        "* https://docs.scipy.org/doc/scipy/reference/generated/scipy.fft.dct.html#scipy.fft.dct\n",
        "* https://github.com/search?q=discrete+cosine \n",
        "\n",
        "Tutorial\n",
        "\n",
        "* https://realpython.com/python-scipy-fft/#the-discrete-cosine-and-sine-transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI-UtGpXwsJ6"
      },
      "source": [
        "from sktime.transformations.series.cos import CosineTransformer\n",
        "from sktime.datasets import load_airline\n",
        "y = load_airline()\n",
        "transformer = CosineTransformer()\n",
        "y_hat = transformer.fit_transform(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HUsqY_c3wsGA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YfHqTtxwsC4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKYGvaNxwr_m"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noayFmY5v6Wc"
      },
      "source": [
        "!pip install pyts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-DLnLsjVWB-"
      },
      "source": [
        "**Stanford ASAP: Automatic Smoothing for Attention Prioritization in Time Series**\n",
        "\n",
        "* https://github.com/stanford-futuredata/ASAP/blob/master/ASAP.ipynb (Python)\n",
        "* https://github.com/stanford-futuredata/ASAP/blob/master/ASAP-simple.js\n",
        "* http://futuredata.stanford.edu/asap/ \n",
        "* https://www.datadoghq.com/blog/auto-smoother-asap/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsz35wSyWlvA"
      },
      "source": [
        "import scipy.stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLFb9ZitVV3E"
      },
      "source": [
        "# ASAP Simple (Brute Force)\n",
        "def moving_average(data, _range):\n",
        "    ret = np.cumsum(data, dtype=float)\n",
        "    ret[_range:] = ret[_range:] - ret[:-_range]\n",
        "    return ret[_range - 1:] / _range\n",
        "\n",
        "def SMA(data, _range, slide):\n",
        "    ret = moving_average(data, _range)[::slide]\n",
        "    return list(ret)\n",
        "\n",
        "def kurtosis(values):\n",
        "    return scipy.stats.kurtosis(values)\n",
        "\n",
        "def roughness(vals):\n",
        "    return np.std(np.diff(vals))\n",
        "\n",
        "def smooth_simple(data, max_window=5, resolution=None):\n",
        "    data = np.array(data)\n",
        "    # Preaggregate according to resolution\n",
        "    window_size = 1\n",
        "    slide_size = 1\n",
        "    if resolution:\n",
        "        slide_size = int(len(data) / resolution)\n",
        "        if slide_size > 1:\n",
        "            data = SMA(data, slide_size, slide_size)\n",
        "    orig_kurt   = kurtosis(data)\n",
        "    min_obj     = roughness(data)\n",
        "    for w in range(2, int(len(data) / max_window + 1)):\n",
        "        smoothed = SMA(data, w, 1)\n",
        "        if kurtosis(smoothed) >= orig_kurt:\n",
        "            r = roughness(smoothed)\n",
        "            if r < min_obj:\n",
        "                min_obj = r\n",
        "                window_size = w\n",
        "    return window_size, slide_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHdCbShgVVrR"
      },
      "source": [
        "# Plot time series before and after smoothing\n",
        "def plot(data, window_size, slide_size, plot_title):\n",
        "    plt.clf()\n",
        "    plt.figure()\n",
        "    data = SMA(data, slide_size, slide_size)\n",
        "    method_names = [\"Original\", \"ASAP Smoothed\"]\n",
        "    fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
        "    smoothed = SMA(data, window_size, 1)\n",
        "    smoothed_range = range(int(window_size/2), int(window_size/2) + len(smoothed))\n",
        "    ax1.set_xlim(0, len(data))\n",
        "    ax1.plot(data, linestyle='-', linewidth=1.5)\n",
        "    ax2.plot(smoothed_range, smoothed, linestyle='-', linewidth=1.5)\n",
        "    axes = [ax1, ax2]\n",
        "    for i in range(2):\n",
        "        axes[i].get_xaxis().set_visible(False)\n",
        "        axes[i].text(0.02, 0.8, \"%s\" %(method_names[i]),\n",
        "            verticalalignment='center', horizontalalignment='left',\n",
        "            transform=axes[i].transAxes, fontsize=25)\n",
        "\n",
        "    fig.set_size_inches(16, 12)\n",
        "    plt.tight_layout(w_pad=1)\n",
        "    plt.title(plot_title)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpSktA4gWV3J"
      },
      "source": [
        "corpus_sentiments_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "710ghW5qVVoF"
      },
      "source": [
        "# Taxi\n",
        "# raw_data = load_csv('Taxi.csv')\n",
        "# window_size, slide_size = smooth_ASAP(raw_data, resolution=1000)\n",
        "# window_size, slide_size = smooth_ASAP(raw_data, resolution=1000)\n",
        "window_size, slide_size = smooth_simple(list(corpus_sentiments_df['median']), resolution=1000)\n",
        "print(\"Window Size: \", window_size)\n",
        "plot_title = f'{BOOK_TITLE_FULL} \\n Median Sentiment Smoothed with ASAP from Stanford (res=1000)'\n",
        "plot(list(corpus_sentiments_df['median']), window_size, slide_size, plot_title)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wkkx80YYLCg"
      },
      "source": [
        "# Calculate Error Metrics based on Distance from Median"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0K9P4jA_bDj"
      },
      "source": [
        "Libraries:\n",
        "\n",
        "* https://github.com/wannesm/dtaidistance\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmSSemdcLQ9x"
      },
      "source": [
        "# sentiment_lowess_df['median']\n",
        "sentiment_lowess_df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Tvyv-LtJiqJ"
      },
      "source": [
        "# Rank each Sentiment Model by Error/Distance Metrics from Median\n",
        "\n",
        "sentiment_lowess_df['min'] = sentiment_lowess_df[['vader','jockers-rinker','syuzhet','huliu','textblob','sentiword','senticnet']].min(axis=1)\n",
        "sentiment_lowess_df['max'] = sentiment_lowess_df[['vader','jockers-rinker','syuzhet','huliu','textblob','sentiword','senticnet']].max(axis=1)\n",
        "sentiment_lowess_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18y52tS9JTeO"
      },
      "source": [
        "# LOWESS Smoothed Median Curve with Min/Max Confidence Intervals\n",
        "\n",
        "plt.title(f'{BOOK_TITLE_FULL} \\n LOWESS Smoothed Median Sentiment Curve with Min/Max Confidence Intervals')\n",
        "\n",
        "sns.lineplot(data=sentiment_lowess_df, x='x_value', y='median', linewidth=3, color='black')\n",
        "plt.fill_between(sentiment_lowess_df['x_value'], sentiment_lowess_df['min'], sentiment_lowess_df['max'], alpha=.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cQqCyABTkzT"
      },
      "source": [
        "# Error Metrics of each Model relative to the Median"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BBTjp7nTkhK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHVeb7Jy9zaa"
      },
      "source": [
        "# Group and Classify Sentiment Arcs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xeV-709-_M2"
      },
      "source": [
        "Libraries\n",
        "\n",
        "* https://github.com/alan-turing-institute/sktime\n",
        "\n",
        "* https://github.com/johannfaouzi/pyts \n",
        "\n",
        "Code\n",
        "\n",
        "* https://colab.research.google.com/drive/1oEFfK5KTJyFQGs2xunc1cDW2OcbkZKCY\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFEtVAt29zMP"
      },
      "source": [
        "# https://colab.research.google.com/drive/1oEFfK5KTJyFQGs2xunc1cDW2OcbkZKCY\n",
        "\n",
        "# https://github.com/johannfaouzi/pyts \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "804w9PYAYP_p"
      },
      "source": [
        "# Export Manual and Automatic Sentiment Polarities and Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wnHGCQnO9aA"
      },
      "source": [
        "%whos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwmMgQILMYba"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}