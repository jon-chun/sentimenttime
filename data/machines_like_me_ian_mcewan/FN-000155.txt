Ian M cE w an
92
Early the following morning, for the first time in years, I
tipped into my coffee a heaped spoon of sugar. I watched the
confined, nut-brown disc of fluid turn, then slow, in its clock-
wise motion, then lose all purpose in a chaotic swirl. Tempting,
but I resisted a metaphor for my own existence. 1 was trying to
think and it was barely seven thirty. Soon Adam or Miranda
or both would appear at my door. I wanted my thoughts and
attitude in coherent form. After a night of broken sleep, I was
depressed as well as angry with myself, and determined not
to appear so. Miranda had kept her distance from me and so,
by contemporary standards, a night with someone else, even
something else, was not quite a betrayal. As for the ethical
dimensions of Adam's behaviour, here was a history with a
curious beginning. It was during the miners' strike of twelve
years before that self-driving cars first appeared on experi-
mental sites, mostly disused airfields, where movie set design-
ers had constructed imitation streets, motorway junctions and
various hazards.
"Autonomous" was never the right word, for the new cars
were as dependent as newborn babies on mighty networks of
computers linked to satellites and on-board radar. If artificial
intelligence was to guide these vehicles safely home, what
set of values or priorities should be assumed in the software?
Fortunately, in moral philosophy there already existed a well-
explored set of dilemmas known in the business as "the trolley
problem." Adapted easily to cars, the sort of problem manu-
facturers and their software engineers now posed was this:
you, or rather, your car is driving at the maximum legal speed
along a narrow suburban road. The traffic is flowing nicely.