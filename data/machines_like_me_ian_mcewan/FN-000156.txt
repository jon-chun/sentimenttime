Machines Like Me
93
On the pavement on your side of the road is a group of chil-
dren. Suddenly one of them, a child of eight, runs out across
the road, right into your path. There's a fraction of a second to
make a decision—either mow the child down or swerve onto
the crowded pavement or into the oncoming traffic and collide
head on with a truck at a closing speed of eighty miles an hour.
You're alone, so that's fine, sacrifice or save yourself. What if
your spouse and your two children are in the car? Too easy?
What if it's your only daughter, or your grandparents, or your
pregnant daughter and your son-in-law, both in their mid-
twenties? Now take into account the occupants of the truck. A
fraction of a second is more than enough time for a computer
to give thorough consideration to all the issues. The decision
will depend on the priorities ordered by the software.
While mounted policemen charged at miners, and man-
ufacturing towns across the country began their long, sad
descent in the cause of free markets, the subject of robot eth-
ics was born. The international automobile industry consulted
philosophers, judges, specialists in medical ethics, game theo-
rists and parliamentary committees. Then, in universities and
research institutes, the subject expanded on its own. Long
before the hardware was available, professors and their post-
docs devised software that conjured our best selves—tolerant,
open-minded, considerate, free of all taint of scheming, malice
or prejudice. Theorists anticipated a refined artificial intelli-
gence, guided by well-designed principles, that would learn by
roaming over thousands, millions, of moral dilemmas. Such
intelligence could teach us how to be, how to be good. Humans
were ethically flawed—inconsistent, emotionally labile, prone